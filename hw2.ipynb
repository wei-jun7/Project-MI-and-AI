{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wei-jun7/Project-MI-and-AI/blob/main/hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXXF36nmBNFF"
      },
      "source": [
        "Homework 2: Ensemble Learning\n",
        "\n",
        "\n",
        "Task 1 (30 points): Implement a Decision Tree Classifier for your classification problem. You\n",
        "may use a built-in package to implement your classifier. Try modifying one or more of the input\n",
        "parameters and describe what changes you notice in your results. Clearly describe how these\n",
        "factors are affecting your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDJZAQbNBNFL",
        "outputId": "76d53871-4829-403e-e1da-8cbfa0b78062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TreeModel_1 Trian Score: \n",
            "  0.939375\n",
            "TreeModel_1 Test Score: \n",
            "  0.81\n",
            "Accuracy_score : \n",
            " 0.81\n",
            "Confusion_matrix :\n",
            "  [[304  78]\n",
            " [ 74 344]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       382\n",
            "           1       0.82      0.82      0.82       418\n",
            "\n",
            "    accuracy                           0.81       800\n",
            "   macro avg       0.81      0.81      0.81       800\n",
            "weighted avg       0.81      0.81      0.81       800\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TreeModel_2 Trian Score: \n",
            "  0.9246875\n",
            "TreeModel_2 Test Score: \n",
            "  0.78875\n",
            "Accuracy_score : \n",
            " 0.78875\n",
            "Confusion_matrix :\n",
            "  [[313  69]\n",
            " [100 318]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       382\n",
            "           1       0.82      0.76      0.79       418\n",
            "\n",
            "    accuracy                           0.79       800\n",
            "   macro avg       0.79      0.79      0.79       800\n",
            "weighted avg       0.79      0.79      0.79       800\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "TreeModel_3 Trian Score: \n",
            "  1.0\n",
            "TreeModel_3 Test Score: \n",
            "  0.82125\n",
            "Accuracy_score : \n",
            " 0.82125\n",
            "Confusion_matrix :\n",
            "  [[311  71]\n",
            " [ 72 346]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81       382\n",
            "           1       0.83      0.83      0.83       418\n",
            "\n",
            "    accuracy                           0.82       800\n",
            "   macro avg       0.82      0.82      0.82       800\n",
            "weighted avg       0.82      0.82      0.82       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "#data load from csv file\n",
        "data = pd.read_csv('apple_quality.csv')\n",
        "\n",
        "#data clean up\n",
        "data = data.iloc[:4000]\n",
        "data = data.drop(labels='A_id',axis=1)\n",
        "data['Quality'] = np.where(data['Quality'] == 'good',1,0)\n",
        "\n",
        "#split the data into train and test\n",
        "X = data.iloc[:,:-1]\n",
        "Y = data.iloc[:,-1]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=100)\n",
        "\n",
        "#run the classifier for the descison tree\n",
        "TreeModel_1= DecisionTreeClassifier(criterion='entropy',max_depth=10, random_state=100)\n",
        "TreeModel_1.fit(X_train, Y_train)\n",
        "Y_pred_1 = TreeModel_1.predict(X_test)\n",
        "\n",
        "TreeModel_2= DecisionTreeClassifier(criterion = 'gini', max_depth=10, random_state=100)\n",
        "TreeModel_2.fit(X_train, Y_train)\n",
        "Y_pred_2 = TreeModel_2.predict(X_test)\n",
        "\n",
        "TreeModel_3= DecisionTreeClassifier(criterion = 'entropy', max_depth=100, random_state=100)\n",
        "TreeModel_3.fit(X_train, Y_train)\n",
        "Y_pred_3 = TreeModel_3.predict(X_test)\n",
        "\n",
        "\n",
        "Accuracy_score = accuracy_score(Y_test,Y_pred_1)\n",
        "Confusion_matrix = confusion_matrix(Y_test,Y_pred_1)\n",
        "Classification_report = classification_report(Y_test,Y_pred_1)\n",
        "\n",
        "\n",
        "print(\"TreeModel_1 Trian Score: \\n \", TreeModel_1.score(X_train, Y_train))\n",
        "print(\"TreeModel_1 Test Score: \\n \", TreeModel_1.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n',Accuracy_score)\n",
        "print('Confusion_matrix :\\n ',Confusion_matrix)\n",
        "print('Classification_report : \\n',Classification_report)\n",
        "\n",
        "Accuracy_score_2 = accuracy_score(Y_test,Y_pred_2)\n",
        "Confusion_matrix_2 = confusion_matrix(Y_test,Y_pred_2)\n",
        "Classification_report_2 = classification_report(Y_test,Y_pred_2)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"TreeModel_2 Trian Score: \\n \", TreeModel_2.score(X_train, Y_train))\n",
        "print(\"TreeModel_2 Test Score: \\n \", TreeModel_2.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n',Accuracy_score_2)\n",
        "print('Confusion_matrix :\\n ',Confusion_matrix_2)\n",
        "print('Classification_report : \\n',Classification_report_2)\n",
        "\n",
        "Accuracy_score_3 = Accuracy_score = accuracy_score(Y_test,Y_pred_3)\n",
        "Confusion_matrix_3 = confusion_matrix(Y_test,Y_pred_3)\n",
        "Classification_report_3 = classification_report(Y_test,Y_pred_3)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"TreeModel_3 Trian Score: \\n \", TreeModel_3.score(X_train, Y_train))\n",
        "print(\"TreeModel_3 Test Score: \\n \", TreeModel_3.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n',Accuracy_score_3)\n",
        "print('Confusion_matrix :\\n ',Confusion_matrix_3)\n",
        "print('Classification_report : \\n',Classification_report_3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I developed three different decision tree models, varying the parameters criterion and min_samples_split. The results demonstrate distinct characteristics for each model. TreeModel_1, which uses entropy as its criterion and limits the tree's maximum depth to 10, appears to achieve a balance in mitigating overfitting. However, this might come at the cost of not fully grasping the data's complexity, as suggested by its test accuracy of 0.81. On the other hand, TreeModel_2 employs the Gini coefficient for splitting with the same depth limitation. Although the Gini coefficient is known for its computational efficiency, in this particular dataset, it slightly underperformed compared to TreeModel_1, achieving a test accuracy of 0.78875. This outcome might indicate that, for this dataset, entropy is a superior criterion for splitting.\n",
        "\n",
        "TreeModel_3 differs in its approach by maintaining the entropy criterion but significantly elevating the maximum depth to 100. This adjustment resulted in an impeccable fit on the training data, but the depth increase raises concerns about overfitting. This is when a model, too attuned to the training data, may not perform as well with new, unseen data. Despite TreeModel_3 achieving the highest test accuracy of 0.82125 among the three, its perfect score in training suggests overfitting.\n",
        "\n",
        "In summary, while entropy usually leads to more balanced trees, the Gini coefficient offers speed in computation. Furthermore, the maximum depth is a crucial factor in regulating a model's complexity. Excessive depth can trigger overfitting, where a model excels with training data but fails with new data. Conversely, a less deep tree might not capture all the nuances and complexities of the dataset.\n"
      ],
      "metadata": {
        "id": "cgURUeSXbjM9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVD49BG8BNFP"
      },
      "source": [
        "Task 2 (30 points): From the Bagging and Boosting ensemble methods pick any one algorithm\n",
        "from each category. Implement both the algorithms using the same data. Use k-fold cross\n",
        "validation to find the effectiveness of both the models. Comment on the difference/similarity of\n",
        "the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYgnyoM7BNFP",
        "outputId": "0abfd247-6e18-4834-fec4-0ea4826b2ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging with TreeModel_1: \n",
            " [0.86   0.8575 0.9    0.865  0.8825 0.9    0.89   0.8625 0.87   0.8725]\n",
            "Bagging with TreeModel_2: \n",
            " [0.855  0.8725 0.9    0.87   0.875  0.885  0.8825 0.8575 0.87   0.88  ]\n",
            "Boosting with TreeModel_1: \n",
            " [0.8825 0.885  0.92   0.905  0.8875 0.9175 0.915  0.885  0.9025 0.8925]\n",
            "Boosting with TreeModel_2: \n",
            " [0.89   0.8875 0.91   0.8975 0.89   0.9125 0.9175 0.8875 0.905  0.8975]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# create k fold object\n",
        "cv = KFold(n_splits=10, random_state=100, shuffle=True)\n",
        "\n",
        "# Bagging\n",
        "BaggingModel1 = BaggingClassifier(estimator=TreeModel_1, n_estimators=100, random_state=100)\n",
        "BaggingModel2 = BaggingClassifier(estimator=TreeModel_2, n_estimators=100, random_state=100)\n",
        "\n",
        "# Boosting\n",
        "BoostingModel1 = AdaBoostClassifier(estimator=TreeModel_1, n_estimators=100, random_state=100)\n",
        "BoostingModel2 = AdaBoostClassifier(estimator=TreeModel_2, n_estimators=100, random_state=100)\n",
        "\n",
        "# k fold croos validation\n",
        "cv_results_bagging1 = cross_val_score(BaggingModel1, X, Y, cv=cv)\n",
        "cv_results_bagging2 = cross_val_score(BaggingModel2, X, Y, cv=cv)\n",
        "cv_results_boosting1 = cross_val_score(BoostingModel1, X, Y, cv=cv)\n",
        "cv_results_boosting2 = cross_val_score(BoostingModel2, X, Y, cv=cv)\n",
        "\n",
        "# print the resutlt\n",
        "print('Bagging with TreeModel_1: \\n', cv_results_bagging1)\n",
        "print('Bagging with TreeModel_2: \\n', cv_results_bagging2)\n",
        "print('Boosting with TreeModel_1: \\n', cv_results_boosting1)\n",
        "print('Boosting with TreeModel_2: \\n', cv_results_boosting2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bagging method I choose is the Bootstrap Aggregating method which can direct work with my model. With Bagging, TreeModel_1 achieved scores between 0.86 and 0.9, averaging approximately 0.87575, indicating a robust improvement. TreeModel_2, while also improved by Bagging, showed a slightly lesser enhancement, with scores from 0.855 to 0.9 and an average score around 0.87475. This pattern suggests that while Bagging generally benefits both models, its impact is more pronounced on TreeModel_1.\n",
        "\n",
        "Turning to Boosting, the boosting method I chose to use was the adaboost classifier a similar trend emerged. TreeModel_1 demonstrated superior performance under Boosting, with scores ranging from 0.8825 to 0.92 and an average of about 0.89875. TreeModel_2 also showed improvement with Boosting, though to a slightly lesser extent than TreeModel_1, scoring between 0.89 and 0.9175, with an average near 0.89875. These results underscore Boosting's capability to significantly elevate the performance of both models, particularly TreeModel_1.\n",
        "\n",
        "When comparing the effects of these two ensemble methods, it's clear that both Bagging and Boosting effectively elevate the performance of decision tree models. They both excel in enhancing model accuracy, reducing the risk of overfitting, and ensuring better generalization on new data. However, the extent of improvement varies between the methods. Bagging shows a subtle preference in enhancing TreeModel_1 more than TreeModel_2, whereas Boosting considerably amplifies the performance of both models, especially TreeModel_1. This difference likely stems from the intrinsic mechanisms of these methods; Boosting focuses on correcting the errors of previous iterations, while Bagging improves performance by reducing variance across the model ensemble"
      ],
      "metadata": {
        "id": "oqDmgjnQpPyN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV7Yv8s4BNFQ"
      },
      "source": [
        "Task 3 (40 points): Compare the effectiveness of the three models implemented above. Clearly\n",
        "describe the metric you are using for comparison. Describe (with examples) Why is this\n",
        "metric(metrics) suited/appropriate for the problem at hand? How would a choice of a different\n",
        "metric impact your results? Can you demonstrate that?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKZFcIhaBNFR",
        "outputId": "61630f2a-9878-4525-ea68-97f92103f0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TreeModel_1 Test Score: \n",
            "  0.81\n",
            "Accuracy_score : \n",
            " 0.81\n",
            "Confusion_matrix :\n",
            " [[304  78]\n",
            " [ 74 344]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       382\n",
            "           1       0.82      0.82      0.82       418\n",
            "\n",
            "    accuracy                           0.81       800\n",
            "   macro avg       0.81      0.81      0.81       800\n",
            "weighted avg       0.81      0.81      0.81       800\n",
            "\n",
            "\n",
            "BaggingModel Test Score: \n",
            "  0.86875\n",
            "Accuracy_score : \n",
            " 0.86875\n",
            "Confusion_matrix :\n",
            " [[325  57]\n",
            " [ 48 370]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86       382\n",
            "           1       0.87      0.89      0.88       418\n",
            "\n",
            "    accuracy                           0.87       800\n",
            "   macro avg       0.87      0.87      0.87       800\n",
            "weighted avg       0.87      0.87      0.87       800\n",
            "\n",
            "\n",
            "BoostingModel Test Score: \n",
            "  0.8825\n",
            "Accuracy_score : \n",
            " 0.8825\n",
            "Confusion_matrix :\n",
            " [[335  47]\n",
            " [ 47 371]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       382\n",
            "           1       0.89      0.89      0.89       418\n",
            "\n",
            "    accuracy                           0.88       800\n",
            "   macro avg       0.88      0.88      0.88       800\n",
            "weighted avg       0.88      0.88      0.88       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# use TreeModel_1 predicate\n",
        "Y_pred_1 = TreeModel_1.predict(X_test)\n",
        "\n",
        "# train BaggingModel\n",
        "BaggingModel1.fit(X_train, Y_train)\n",
        "# train BaggingModel\n",
        "Y_pred_bagging = BaggingModel1.predict(X_test)\n",
        "\n",
        "# Train BoostingModel\n",
        "BoostingModel1.fit(X_train, Y_train)\n",
        "# use BoostingModel to predict\n",
        "Y_pred_boosting = BoostingModel1.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# show TreeModel_1 result\n",
        "Accuracy_score_1 = accuracy_score(Y_test, Y_pred_1)\n",
        "Confusion_matrix_1 = confusion_matrix(Y_test, Y_pred_1)\n",
        "Classification_report_1 = classification_report(Y_test, Y_pred_1)\n",
        "\n",
        "print(\"TreeModel_1 Test Score: \\n \", TreeModel_1.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n', Accuracy_score_1)\n",
        "print('Confusion_matrix :\\n', Confusion_matrix_1)\n",
        "print('Classification_report : \\n', Classification_report_1)\n",
        "\n",
        "# BaggingModel result\n",
        "Accuracy_score_bagging = accuracy_score(Y_test, Y_pred_bagging)\n",
        "Confusion_matrix_bagging = confusion_matrix(Y_test, Y_pred_bagging)\n",
        "Classification_report_bagging = classification_report(Y_test, Y_pred_bagging)\n",
        "\n",
        "print(\"\\nBaggingModel Test Score: \\n \", BaggingModel1.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n', Accuracy_score_bagging)\n",
        "print('Confusion_matrix :\\n', Confusion_matrix_bagging)\n",
        "print('Classification_report : \\n', Classification_report_bagging)\n",
        "\n",
        "# BoostingModel result\n",
        "Accuracy_score_boosting = accuracy_score(Y_test, Y_pred_boosting)\n",
        "Confusion_matrix_boosting = confusion_matrix(Y_test, Y_pred_boosting)\n",
        "Classification_report_boosting = classification_report(Y_test, Y_pred_boosting)\n",
        "\n",
        "print(\"\\nBoostingModel Test Score: \\n \", BoostingModel1.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n', Accuracy_score_boosting)\n",
        "print('Confusion_matrix :\\n', Confusion_matrix_boosting)\n",
        "print('Classification_report : \\n', Classification_report_boosting)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our study, we compared three models for a classification task: a basic decision tree (TreeModel_1), a bagging ensemble (BaggingModel), and a boosting ensemble (BoostingModel), using key metrics like Accuracy, Precision, Recall, and F1-Score. Each metric provides a unique perspective on the models' performance. Accuracy gives a general idea of overall performance, while Precision and Recall focus on the model's ability to correctly predict positive cases and F1-Score balances these two aspects.\n",
        "\n",
        "The results showed that the BoostingModel outperformed the others across all metrics, indicating its superior ability to correctly classify cases while maintaining a balance between reducing false positives and false negatives. The BaggingModel also improved upon the basic TreeModel_1, particularly in terms of Precision and Recall.\n",
        "\n",
        "This comparison highlights the effectiveness of ensemble methods in enhancing the performance of a basic model. Boosting, in particular, demonstrated its strength in not only improving overall accuracy but also in achieving a well-balanced trade-off between Precision and Recall, crucial for many real-world applications. The study underscores the importance of considering multiple metrics to gain a comprehensive understanding of a model's performance, guiding the selection of the most appropriate model for specific classification tasks."
      ],
      "metadata": {
        "id": "oD-xU_962GpY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDepHcJ4BNFR",
        "outputId": "1a1c891c-2ef2-40f9-b325-0477204ff217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TreeModel_2 Test Score: \n",
            "  0.78875\n",
            "Accuracy_score : \n",
            " 0.78875\n",
            "Confusion_matrix :\n",
            " [[313  69]\n",
            " [100 318]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.82      0.79       382\n",
            "           1       0.82      0.76      0.79       418\n",
            "\n",
            "    accuracy                           0.79       800\n",
            "   macro avg       0.79      0.79      0.79       800\n",
            "weighted avg       0.79      0.79      0.79       800\n",
            "\n",
            "\n",
            "BaggingModel2 Test Score: \n",
            "  0.86875\n",
            "Accuracy_score : \n",
            " 0.86875\n",
            "Confusion_matrix :\n",
            " [[326  56]\n",
            " [ 49 369]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86       382\n",
            "           1       0.87      0.88      0.88       418\n",
            "\n",
            "    accuracy                           0.87       800\n",
            "   macro avg       0.87      0.87      0.87       800\n",
            "weighted avg       0.87      0.87      0.87       800\n",
            "\n",
            "\n",
            "BoostingModel2 Test Score: \n",
            "  0.8875\n",
            "Accuracy_score : \n",
            " 0.8875\n",
            "Confusion_matrix :\n",
            " [[339  43]\n",
            " [ 47 371]]\n",
            "Classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       382\n",
            "           1       0.90      0.89      0.89       418\n",
            "\n",
            "    accuracy                           0.89       800\n",
            "   macro avg       0.89      0.89      0.89       800\n",
            "weighted avg       0.89      0.89      0.89       800\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# train on the test data\n",
        "TreeModel_2.fit(X_train, Y_train)\n",
        "BaggingModel2.fit(X_train, Y_train)\n",
        "BoostingModel2.fit(X_train, Y_train)\n",
        "\n",
        "# use TreeModel_2 predict\n",
        "Y_pred_2 = TreeModel_2.predict(X_test)\n",
        "\n",
        "# use BaggingModel2 predict\n",
        "Y_pred_bagging2 = BaggingModel2.predict(X_test)\n",
        "\n",
        "# use BoostingModel2 predict\n",
        "Y_pred_boosting2 = BoostingModel2.predict(X_test)\n",
        "\n",
        "# print TreeModel_2 result\n",
        "Accuracy_score_2 = accuracy_score(Y_test, Y_pred_2)\n",
        "Confusion_matrix_2 = confusion_matrix(Y_test, Y_pred_2)\n",
        "Classification_report_2 = classification_report(Y_test, Y_pred_2)\n",
        "\n",
        "print(\"TreeModel_2 Test Score: \\n \", TreeModel_2.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n', Accuracy_score_2)\n",
        "print('Confusion_matrix :\\n', Confusion_matrix_2)\n",
        "print('Classification_report : \\n', Classification_report_2)\n",
        "\n",
        "# BaggingModel2 result\n",
        "Accuracy_score_bagging2 = accuracy_score(Y_test, Y_pred_bagging2)\n",
        "Confusion_matrix_bagging2 = confusion_matrix(Y_test, Y_pred_bagging2)\n",
        "Classification_report_bagging2 = classification_report(Y_test, Y_pred_bagging2)\n",
        "\n",
        "print(\"\\nBaggingModel2 Test Score: \\n \", BaggingModel2.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n', Accuracy_score_bagging2)\n",
        "print('Confusion_matrix :\\n', Confusion_matrix_bagging2)\n",
        "print('Classification_report : \\n', Classification_report_bagging2)\n",
        "\n",
        "# BoostingModel2 result\n",
        "Accuracy_score_boosting2 = accuracy_score(Y_test, Y_pred_boosting2)\n",
        "Confusion_matrix_boosting2 = confusion_matrix(Y_test, Y_pred_boosting2)\n",
        "Classification_report_boosting2 = classification_report(Y_test, Y_pred_boosting2)\n",
        "\n",
        "print(\"\\nBoostingModel2 Test Score: \\n \", BoostingModel2.score(X_test, Y_test))\n",
        "print('Accuracy_score : \\n', Accuracy_score_boosting2)\n",
        "print('Confusion_matrix :\\n', Confusion_matrix_boosting2)\n",
        "print('Classification_report : \\n', Classification_report_boosting2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this revised analysis of TreeModel_2, BaggingModel2, and BoostingModel2, the effectiveness of each model is distinctly evident through the updated metrics. The data presents a clear trajectory of improvement from the basic decision tree model to the more sophisticated ensemble methods.\n",
        "\n",
        "TreeModel_2, as the basic decision tree, shows an accuracy of 0.78875, indicating a fair performance. Its precision and recall scores, 0.76 for class 0 and 0.82 for class 1, along with a uniform F1-Score of 0.79, reflect a moderate balance in classifying both classes. However, this balance leans slightly more towards class 1, considering the precision and recall values.\n",
        "\n",
        "In contrast, BaggingModel2, the bagging ensemble model, demonstrates a noticeable jump in accuracy to 0.86875. This model not only improves in overall prediction accuracy but also shows enhanced precision and recall, particularly for class 1. The F1-Scores, 0.86 for class 0 and 0.88 for class 1, signify a better balance between precision and recall compared to TreeModel_2, making it more reliable for classifying both classes.\n",
        "\n",
        "The most notable improvement is seen in BoostingModel2. This boosting ensemble model achieves the highest accuracy of 0.8875. Its precision scores of 0.88 for class 0 and 0.90 for class 1, coupled with an equal recall of 0.89 for both classes, indicate a strong ability to correctly identify and classify both classes with minimal error. The F1-Scores, closely matched at 0.88 for class 0 and 0.89 for class 1, underscore a superior balance in handling both false positives and negatives.\n",
        "\n",
        "From this analysis, it’s clear that the ensemble methods, particularly boosting, significantly enhance the model's performance. BoostingModel2 stands out as the most effective model, not just in terms of accuracy but also in achieving an optimal balance between precision and recall, essential for robust classification tasks."
      ],
      "metadata": {
        "id": "Xw_uznyg2dBe"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}