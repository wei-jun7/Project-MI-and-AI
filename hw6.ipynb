{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wei-jun7/Project-MI-and-AI/blob/main/hw6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9AeP38BtY9E"
      },
      "source": [
        "Task 1 (50 points): In this task you should work with the Facebook BART model\n",
        "(https://huggingface.co/docs/transformers/en/model_doc/bart) to provide text summarization\n",
        "of news articles. Text summarization in Natural Language Processing (NLP) is a technique that\n",
        "breaks down long texts into sentences or paragraphs, while retaining the text's meaning and\n",
        "extracting important information. Pick any one dataset of your choice from\n",
        "https://data.world/datasets/news-dataset.\n",
        "You may have to perform data cleaning, preprocessing etc. Next, perform the following tasks:\n",
        "1. Provide a description of the dataset you selected. Split your data into train-test set with\n",
        "a (90-10) split.\n",
        "2. Load the model from Hugging Face’s Transformers library and write its training script.\n",
        "3. Fine tune the pre-trained model with your data and report results on your test set. You\n",
        "must report the BLEU and ROUGE Scores. (See the code provided in class for more\n",
        "details)\n",
        "4. Analyze your results and discuss the impact of hyperparameters. Are your results\n",
        "impacted by the choice of the LLM here? How?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSvUu0CdtY9J"
      },
      "source": [
        "The dataset I select is the cnbc_new_dataset which have 11 feature, title,url,published_at,author,publisher,short_description,keywords,header_image,raw_description,description,scraped_at. The link for the dataset is https://data.world/crawlfeeds/cnbc-news-dataset  As the BART model is to provide the summary of the new articles which I choose to select the title and the description as the input which contain the major summary of each articles. The next step is drop the NA value for the data we selection and split it 90% for train and 10% for test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQALxPZTtY9K"
      },
      "source": [
        "**1.EDA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Buku9ostY9K",
        "outputId": "106280ec-806b-4fab-ce40-f7882eda6cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  Santoli’s Wednesday market notes: Could Septem...   \n",
            "1     My take on the early Brexit winners and losers   \n",
            "2  Europe&#039;s recovery depends on Renzi&#039;s...   \n",
            "3  US Moves Closer to Becoming A Major Shareholde...   \n",
            "4  Trump: 'Mission accomplished' on 'perfectly ex...   \n",
            "\n",
            "                                                 url  \\\n",
            "0  https://www.cnbc.com/2021/09/29/santolis-wedne...   \n",
            "1  https://www.cnbc.com/2016/06/24/ian-bremmers-t...   \n",
            "2  https://www.cnbc.com/2014/03/25/europes-recove...   \n",
            "3  https://www.cnbc.com/2009/04/22/us-moves-close...   \n",
            "4  https://www.cnbc.com/2018/04/14/trump-mission-...   \n",
            "\n",
            "               published_at                   author publisher  \\\n",
            "0  2021-09-29T17:09:39+0000          Michael Santoli      CNBC   \n",
            "1  2016-06-24T13:50:48-0400                      NaN      CNBC   \n",
            "2  2014-03-25T13:29:45-0400                      NaN      CNBC   \n",
            "3  2009-04-22T19:49:03+0000  Michelle Caruso-Cabrera      CNBC   \n",
            "4  2018-04-14T14:59:04+0000          Javier E. David      CNBC   \n",
            "\n",
            "                                   short_description  \\\n",
            "0  This is the daily notebook of Mike Santoli, CN...   \n",
            "1  This commentary originally ran on Facebook. Bo...   \n",
            "2  In spring, ambitious reforms began in Italy. U...   \n",
            "3  The US government is increasingly likely to co...   \n",
            "4                                                NaN   \n",
            "\n",
            "                                            keywords  \\\n",
            "0  cnbc, Premium, Articles, Investment strategy, ...   \n",
            "1  Articles, Politics, Europe News, European Cent...   \n",
            "2  Articles, Business News, Economy, Europe Econo...   \n",
            "3  cnbc, Articles, General Motors Co, Business Ne...   \n",
            "4  cnbc, Articles, George W. Bush, Vladimir Putin...   \n",
            "\n",
            "                                        header_image  \\\n",
            "0  https://image.cnbcfm.com/api/v1/image/10694960...   \n",
            "1  https://fm.cnbc.com/applications/cnbc.com/reso...   \n",
            "2  https://fm.cnbc.com/applications/cnbc.com/reso...   \n",
            "3  https://image.cnbcfm.com/api/v1/image/24947979...   \n",
            "4  https://image.cnbcfm.com/api/v1/image/10513177...   \n",
            "\n",
            "                                     raw_description  \\\n",
            "0  <div class=\"group\"><p><em>This is the daily no...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3  <div class=\"group\"><p>The US government is inc...   \n",
            "4  <div class=\"group\"></div>,<div class=\"group\"><...   \n",
            "\n",
            "                                         description  \\\n",
            "0  This is the daily notebook of Mike Santoli, CN...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3  The US government is increasingly likely to co...   \n",
            "4  President Donald Trump hailed the U.S.-led int...   \n",
            "\n",
            "                   scraped_at  \n",
            "0  2021-10-30 14:11:23.709372  \n",
            "1  2021-10-30 14:11:23.820139  \n",
            "2  2021-10-30 14:11:23.854710  \n",
            "3  2021-10-30 14:11:24.261143  \n",
            "4  2021-10-30 14:11:24.489490  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('cnbc_news_datase.csv')\n",
        "\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdbf7B0utY9M",
        "outputId": "eee7ce0b-2852-43dc-c769-6f7c0d76e460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         description  \\\n",
            "0  This is the daily notebook of Mike Santoli, CN...   \n",
            "3  The US government is increasingly likely to co...   \n",
            "4  President Donald Trump hailed the U.S.-led int...   \n",
            "5  Chevron Chief Executive John Watson told CNBC ...   \n",
            "7  LONDON — European stocks closed higher on Thur...   \n",
            "\n",
            "                                               title  \n",
            "0  Santoli’s Wednesday market notes: Could Septem...  \n",
            "3  US Moves Closer to Becoming A Major Shareholde...  \n",
            "4  Trump: 'Mission accomplished' on 'perfectly ex...  \n",
            "5  Chevron CEO Watson says he supports Trump on t...  \n",
            "7  European stocks close higher on supportive Fed...  \n",
            "Shape after clean:  (593, 2)\n",
            "Average length of title: 58.88195615514334\n",
            "Average length of description: 3119.4114671163575\n",
            "description    False\n",
            "title          False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "df_ = df[['description', 'title']]\n",
        "df_ = df_.dropna()\n",
        "\n",
        "# print first 5line of data\n",
        "print(df_.head())\n",
        "\n",
        "# print the data shape\n",
        "print(\"Shape after clean: \", df_.shape)\n",
        "title_avg_length = df_['title'].str.len().mean()\n",
        "description_avg_length = df_['description'].str.len().mean()\n",
        "\n",
        "print(\"Average length of title:\", title_avg_length)\n",
        "print(\"Average length of description:\", description_avg_length)\n",
        "\n",
        "is_NaN = df_.isnull()\n",
        "print(is_NaN.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSmp0jHWwR4i",
        "outputId": "4f59c8de-44d5-4372-fc78-b7eca54e5f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.38.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2023.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m730.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
            "Successfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install bert-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3hhhSYC0V4y",
        "outputId": "700032c8-5d4c-4325-9636-ac03600467ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.1\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.38.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2023.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=45bfaa0de5f2e8f312912d978813b445d3bafd88e2ad778c7d1b070067ce0e56\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install sacrebleu\n",
        "!pip install bert-score\n",
        "!pip install rouge_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d5571c1a5b74244bd5c9cd8e61e1d45",
            "f42ccfa78b934d4f9b22114d4772290c",
            "6905d89e1d6d4c639ad43889165d21fd",
            "27f0208ff9e04086b50a2996fb80beee",
            "13b5325aac9e4efe8027059fbd4e41e8",
            "4209cbb3a9484b73a932d16513f4bc1d",
            "420a3b9ac2844284b6eab56f79cd2883",
            "b4a1645acbde4297a3b604d90b7114ba",
            "c5c0c1329e3144cbbbb81dcd65b4166e",
            "ec7f4754175f43f1a2f1ff78b572e873",
            "bfda78e5a645489180c83372a0c05618",
            "9f282da7eaec4173ae73402b4b0cc45e",
            "89b9db604403487c9e4ebfb5cf34cc53",
            "255dec4026044f79a0414312f7386f1d",
            "5d55c76ebeea4f45b7eb714d3b7139bc",
            "dcf35ac15a6b46389a4b903b6315b6f5",
            "a3d2ce238b514bd8a19ab1a95f645701",
            "675c9412034f48d08f9ee8a91b22f762",
            "0ff85cce77de4f9ab8c752db3a5b7bf1",
            "5afaf1fee82f4b2e93fac9b4c1cbaf4a",
            "466b8a79ad5d4e0880f060d1f6d09d97",
            "f3ddce3a16654b3b9e34fd5af7e367a6",
            "90f3ae43aceb4c469d3ccb966c7283ad",
            "9c30cba11ec84ec0acb2b1cb2a887df7",
            "d3f2b8685c5f4363b8fd5c74ce8f2646",
            "ea2ec47016c747c6b2726a9adc98aa92",
            "7ae128a67cb5463abc5eefc168b683b9",
            "46cd5ccd38fb46c8927b426353b17480",
            "2a041e80df6d4cca8b91b251ee6812dc",
            "81e473e9393a4a17869c6e4933277afe",
            "59e2fa3f40ee4ba390e8eb4f100c9cab",
            "f8ef84df751a4e3686da921802173277",
            "36b2c718b8444e3aaf79bc1f2945996f",
            "6d4be8c214f84ed09d19361014bdf439",
            "0901aceece914e6bb5504fcfd8c71ca8",
            "9e0fdd3d05314a28bad407a686743a85",
            "3a03ba6607dd4af190302524959c6984",
            "fcf1f9a729b740e7a0a2928e43851c34",
            "d500b6d7be994c398809081baef2d796",
            "4906e9f45c00401d8037548f28263d6a",
            "bcaba1f9f80444f08d08f97b7a82e0f3",
            "99f9b55777e54417a0b74e32660b0442",
            "ed392d18abfd40218cbef0f19ad864dd",
            "7f173cda6a454f7db9d39b0920a4b2ba",
            "c75c5009c66440b59cdd114c7ef5c245",
            "e8f47945cc1f4bea9a92b2ea41ad18e5",
            "6327918043e04981964f0331f48ea9fa",
            "0ebb5c97174f433bb98f3f80c6c6ac9e",
            "f4105e6d8ab14e7d82f03bee62d97830",
            "6605c3cdd0d0484d85416aeb87d05b9a",
            "2a8414e056cf4278b2a4ab96efca30c3",
            "4be99ecd87ec4cceba009e1124014156",
            "6b47d808947947d7bb7f18f40f2f9f50",
            "76d35e8e5c5f434393d7da63cb52f49a",
            "e24389a6deb5423882a8e359a95584d9",
            "f386af9e27d24825b2124598ce435c7f",
            "1318db18841d40e78f16ef5272f74ab3",
            "a5df2aa0305c4e6bbb137aca36b86076",
            "6efd99a468c84187ad27eb00ec9c6975",
            "3fb298b84d604131897294cbac1ecfee",
            "8411d9374bd34b0a969d87b9ba6d693d",
            "71e86dc35bc64eb6974fd96140182ac0",
            "32902515ee3946729b21db776dc1e400",
            "4858df6f73a8415fa1a670162d74692f",
            "805abcb4fd334c439c4b55c39e8410f9",
            "00a7364f13dc407aa6911da5cdfbb13c"
          ]
        },
        "id": "n2WCjfBqtY9O",
        "outputId": "b31b964f-9913-4067-ba5f-067413ee6c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d5571c1a5b74244bd5c9cd8e61e1d45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f282da7eaec4173ae73402b4b0cc45e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90f3ae43aceb4c469d3ccb966c7283ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d4be8c214f84ed09d19361014bdf439"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75c5009c66440b59cdd114c7ef5c245"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f386af9e27d24825b2124598ce435c7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch 0, Batch 1, Training Loss: 1.3675076166788738\n",
            "Epoch 0, Batch 2, Training Loss: 1.0409948031107585\n",
            "Epoch 0, Batch 3, Training Loss: 0.9100576241811117\n",
            "Epoch 0, Batch 4, Training Loss: 1.2014739513397217\n",
            "Epoch 0, Batch 5, Training Loss: 0.9916725158691406\n",
            "Epoch 0, Batch 6, Training Loss: 0.8699528376261393\n",
            "Epoch 0, Batch 7, Training Loss: 1.2351099650065105\n",
            "Epoch 0, Batch 8, Training Loss: 1.0571552117665608\n",
            "Epoch 0, Batch 9, Training Loss: 1.0708688894907634\n",
            "Epoch 0, Batch 10, Training Loss: 0.8900733788808187\n",
            "Epoch 0, Batch 11, Training Loss: 0.9391778310139974\n",
            "Epoch 0, Batch 12, Training Loss: 0.8773345947265625\n",
            "Epoch 0, Batch 13, Training Loss: 0.7662510871887207\n",
            "Epoch 0, Batch 14, Training Loss: 0.8390767574310303\n",
            "Epoch 0, Batch 15, Training Loss: 1.0224010944366455\n",
            "Epoch 0, Batch 16, Training Loss: 1.2033623854319255\n",
            "Epoch 0, Batch 17, Training Loss: 1.3833284378051758\n",
            "Epoch 0, Batch 18, Training Loss: 1.0682709217071533\n",
            "Epoch 0, Batch 19, Training Loss: 0.6961899598439535\n",
            "Epoch 0, Batch 20, Training Loss: 0.991364320119222\n",
            "Epoch 0, Batch 21, Training Loss: 0.9806608359018961\n",
            "Epoch 0, Batch 22, Training Loss: 1.0359571774800618\n",
            "Epoch 0, Batch 23, Training Loss: 1.0642850399017334\n",
            "Epoch 0, Batch 24, Training Loss: 0.6524608929951986\n",
            "Epoch 0, Batch 25, Training Loss: 0.791558583577474\n",
            "Epoch 0, Batch 26, Training Loss: 0.7986384232838949\n",
            "Epoch 0, Batch 27, Training Loss: 0.9482731024424235\n",
            "Epoch 0, Batch 28, Training Loss: 0.8684359391530355\n",
            "Epoch 0, Batch 29, Training Loss: 0.808383067448934\n",
            "Epoch 0, Batch 30, Training Loss: 0.8194530804951986\n",
            "Epoch 0, Batch 31, Training Loss: 0.8208386103312174\n",
            "Epoch 0, Batch 32, Training Loss: 1.0490846633911133\n",
            "Epoch 0, Batch 33, Training Loss: 1.3101479212443035\n",
            "Epoch 0, Batch 34, Training Loss: 0.716666062672933\n",
            "Epoch 0, Batch 35, Training Loss: 0.7713579336802164\n",
            "Epoch 0, Batch 36, Training Loss: 0.8870886961619059\n",
            "Epoch 0, Batch 37, Training Loss: 0.7471201419830322\n",
            "Epoch 0, Batch 38, Training Loss: 0.8243651390075684\n",
            "Epoch 0, Batch 39, Training Loss: 0.7180615266164144\n",
            "Epoch 0, Batch 40, Training Loss: 1.2387146949768066\n",
            "Epoch 0, Batch 41, Training Loss: 1.0142268339792888\n",
            "Epoch 0, Batch 42, Training Loss: 0.8339536190032959\n",
            "Epoch 0, Batch 43, Training Loss: 0.9766898155212402\n",
            "Epoch 0, Batch 44, Training Loss: 1.0245397090911865\n",
            "Epoch 0, Batch 45, Training Loss: 1.1439117590586345\n",
            "Epoch 0, Batch 46, Training Loss: 1.0748822689056396\n",
            "Epoch 0, Batch 47, Training Loss: 0.8942011992136637\n",
            "Epoch 0, Batch 48, Training Loss: 0.98223876953125\n",
            "Epoch 0, Batch 49, Training Loss: 0.7846136887868246\n",
            "Epoch 0, Batch 50, Training Loss: 1.0248947938283284\n",
            "Epoch 0, Batch 51, Training Loss: 0.9240415096282959\n",
            "Epoch 0, Batch 52, Training Loss: 1.0316177209218342\n",
            "Epoch 0, Batch 53, Training Loss: 0.8913606802622477\n",
            "Epoch 0, Batch 54, Training Loss: 0.8735195795694987\n",
            "Epoch 0, Batch 55, Training Loss: 1.1999249458312988\n",
            "Epoch 0, Batch 56, Training Loss: 0.8452619711558024\n",
            "Epoch 0, Batch 57, Training Loss: 1.0205254554748535\n",
            "Epoch 0, Batch 58, Training Loss: 0.803022305170695\n",
            "Epoch 0, Batch 59, Training Loss: 0.9353318214416504\n",
            "Epoch 0, Batch 60, Training Loss: 0.6894444624582926\n",
            "Epoch 0, Batch 61, Training Loss: 0.8479084968566895\n",
            "Epoch 0, Batch 62, Training Loss: 1.0509796937306721\n",
            "Epoch 0, Batch 63, Training Loss: 0.9117708206176758\n",
            "Epoch 0, Batch 64, Training Loss: 0.9709962209065756\n",
            "Epoch 0, Batch 65, Training Loss: 0.7655529975891113\n",
            "Epoch 0, Batch 66, Training Loss: 0.6526087522506714\n",
            "Epoch 0, Batch 67, Training Loss: 0.9775337378184\n",
            "Epoch 0, Batch 68, Training Loss: 1.1531685988108318\n",
            "Epoch 0, Batch 69, Training Loss: 1.0959633986155193\n",
            "Epoch 0, Batch 70, Training Loss: 1.0578043460845947\n",
            "Epoch 0, Batch 71, Training Loss: 0.9121517340342203\n",
            "Epoch 0, Batch 72, Training Loss: 0.9341906706492106\n",
            "Epoch 0, Batch 73, Training Loss: 1.024614969889323\n",
            "Epoch 0, Batch 74, Training Loss: 0.7634380658467611\n",
            "Epoch 0, Batch 75, Training Loss: 0.883928378423055\n",
            "Epoch 0, Batch 76, Training Loss: 1.5369054476420085\n",
            "Epoch 0, Batch 77, Training Loss: 1.0394963423411052\n",
            "Epoch 0, Batch 78, Training Loss: 0.8695086638132731\n",
            "Epoch 0, Batch 79, Training Loss: 0.8419049580891927\n",
            "Epoch 0, Batch 80, Training Loss: 0.8705739974975586\n",
            "Epoch 0, Batch 81, Training Loss: 1.679001808166504\n",
            "Epoch 0, Batch 82, Training Loss: 1.0343092282613118\n",
            "Epoch 0, Batch 83, Training Loss: 0.988152027130127\n",
            "Epoch 0, Batch 84, Training Loss: 1.0010141531626384\n",
            "Epoch 0, Batch 85, Training Loss: 0.9608500798543295\n",
            "Epoch 0, Batch 86, Training Loss: 0.8231277465820312\n",
            "Epoch 0, Batch 87, Training Loss: 0.9991283416748047\n",
            "Epoch 0, Batch 88, Training Loss: 0.8378479480743408\n",
            "Epoch 0, Batch 89, Training Loss: 1.0368722279866536\n",
            "Epoch 0, Batch 90, Training Loss: 0.9611220359802246\n",
            "Epoch 0, Batch 91, Training Loss: 0.9460419019063314\n",
            "Epoch 0, Batch 92, Training Loss: 0.6907353401184082\n",
            "Epoch 0, Batch 93, Training Loss: 0.9489416281382242\n",
            "Epoch 0, Batch 94, Training Loss: 1.3034780025482178\n",
            "Epoch 0, Batch 95, Training Loss: 1.230049689610799\n",
            "Epoch 0, Batch 96, Training Loss: 0.5513622760772705\n",
            "Epoch 0, Batch 97, Training Loss: 1.0992032686869304\n",
            "Epoch 0, Batch 98, Training Loss: 1.1716996033986409\n",
            "Epoch 0, Batch 99, Training Loss: 0.906295379002889\n",
            "Epoch 0, Batch 100, Training Loss: 1.1046059131622314\n",
            "Epoch 0, Batch 101, Training Loss: 0.9373528957366943\n",
            "Epoch 0, Batch 102, Training Loss: 0.8936274846394857\n",
            "Epoch 0, Batch 103, Training Loss: 0.9351363182067871\n",
            "Epoch 0, Batch 104, Training Loss: 0.8218406041463217\n",
            "Epoch 0, Batch 105, Training Loss: 0.7422832647959391\n",
            "Epoch 0, Batch 106, Training Loss: 0.8209253152211508\n",
            "Epoch 0, Batch 107, Training Loss: 1.5860090255737305\n",
            "Epoch 0, Batch 108, Training Loss: 0.8760630289713541\n",
            "Epoch 0, Batch 109, Training Loss: 1.2097140153249104\n",
            "Epoch 0, Batch 110, Training Loss: 0.838926633199056\n",
            "Epoch 0, Batch 111, Training Loss: 0.8254590829213461\n",
            "Epoch 0, Batch 112, Training Loss: 0.9430619875590006\n",
            "Epoch 0, Batch 113, Training Loss: 0.7328437169392904\n",
            "Epoch 0, Batch 114, Training Loss: 1.0201427141825359\n",
            "Epoch 0, Batch 115, Training Loss: 0.8913555145263672\n",
            "Epoch 0, Batch 116, Training Loss: 0.8710327943166097\n",
            "Epoch 0, Batch 117, Training Loss: 0.9650825659434\n",
            "Epoch 0, Batch 118, Training Loss: 0.676232655843099\n",
            "Epoch 0, Batch 119, Training Loss: 0.8248188495635986\n",
            "Epoch 0, Batch 120, Training Loss: 0.7420262495676676\n",
            "Epoch 0, Batch 121, Training Loss: 1.0623986721038818\n",
            "Epoch 0, Batch 122, Training Loss: 0.8151573340098063\n",
            "Epoch 0, Batch 123, Training Loss: 0.8302416801452637\n",
            "Epoch 0, Batch 124, Training Loss: 1.0436360836029053\n",
            "Epoch 0, Batch 125, Training Loss: 0.8794023990631104\n",
            "Epoch 0, Batch 126, Training Loss: 1.210011879603068\n",
            "Epoch 0, Batch 127, Training Loss: 0.906788190205892\n",
            "Epoch 0, Batch 128, Training Loss: 1.0305294195810955\n",
            "Epoch 0, Batch 129, Training Loss: 0.8786449432373047\n",
            "Epoch 0, Batch 130, Training Loss: 1.3022579352060955\n",
            "Epoch 0, Batch 131, Training Loss: 0.9820067882537842\n",
            "Epoch 0, Batch 132, Training Loss: 1.4509189923604329\n",
            "Epoch 0, Batch 133, Training Loss: 0.7319901784261068\n",
            "Epoch 0, Batch 134, Training Loss: 1.0560615062713623\n",
            "Epoch 0 finished. Average Training Loss: 2.8882880201980248\n",
            "Epoch 1, Batch 1, Training Loss: 0.9030709266662598\n",
            "Epoch 1, Batch 2, Training Loss: 0.874087413152059\n",
            "Epoch 1, Batch 3, Training Loss: 1.0544548829396565\n",
            "Epoch 1, Batch 4, Training Loss: 0.958342711130778\n",
            "Epoch 1, Batch 5, Training Loss: 0.7917845249176025\n",
            "Epoch 1, Batch 6, Training Loss: 1.127612829208374\n",
            "Epoch 1, Batch 7, Training Loss: 0.7678168614705404\n",
            "Epoch 1, Batch 8, Training Loss: 0.7144749164581299\n",
            "Epoch 1, Batch 9, Training Loss: 1.0083406766255696\n",
            "Epoch 1, Batch 10, Training Loss: 0.9473652044932047\n",
            "Epoch 1, Batch 11, Training Loss: 0.9381396770477295\n",
            "Epoch 1, Batch 12, Training Loss: 0.744704008102417\n",
            "Epoch 1, Batch 13, Training Loss: 1.0839927991231282\n",
            "Epoch 1, Batch 14, Training Loss: 0.9899848302205404\n",
            "Epoch 1, Batch 15, Training Loss: 0.6646964152654012\n",
            "Epoch 1, Batch 16, Training Loss: 0.7172927061716715\n",
            "Epoch 1, Batch 17, Training Loss: 1.2628391583760579\n",
            "Epoch 1, Batch 18, Training Loss: 1.0040099620819092\n",
            "Epoch 1, Batch 19, Training Loss: 1.6285743713378906\n",
            "Epoch 1, Batch 20, Training Loss: 0.8721356391906738\n",
            "Epoch 1, Batch 21, Training Loss: 0.8788736661275228\n",
            "Epoch 1, Batch 22, Training Loss: 0.6533418496449789\n",
            "Epoch 1, Batch 23, Training Loss: 0.9908434549967448\n",
            "Epoch 1, Batch 24, Training Loss: 0.7055911223093668\n",
            "Epoch 1, Batch 25, Training Loss: 1.0596089363098145\n",
            "Epoch 1, Batch 26, Training Loss: 1.1031447251637776\n",
            "Epoch 1, Batch 27, Training Loss: 1.1744719346364338\n",
            "Epoch 1, Batch 28, Training Loss: 1.0007432301839192\n",
            "Epoch 1, Batch 29, Training Loss: 0.8948724269866943\n",
            "Epoch 1, Batch 30, Training Loss: 2.083016872406006\n",
            "Epoch 1, Batch 31, Training Loss: 0.7760461171468099\n",
            "Epoch 1, Batch 32, Training Loss: 0.8472172419230143\n",
            "Epoch 1, Batch 33, Training Loss: 1.1582427024841309\n",
            "Epoch 1, Batch 34, Training Loss: 0.7636760075887045\n",
            "Epoch 1, Batch 35, Training Loss: 0.7416536808013916\n",
            "Epoch 1, Batch 36, Training Loss: 1.2755494117736816\n",
            "Epoch 1, Batch 37, Training Loss: 0.9888452688852946\n",
            "Epoch 1, Batch 38, Training Loss: 0.736422618230184\n",
            "Epoch 1, Batch 39, Training Loss: 1.1290500958760579\n",
            "Epoch 1, Batch 40, Training Loss: 0.88258163134257\n",
            "Epoch 1, Batch 41, Training Loss: 1.0787738958994548\n",
            "Epoch 1, Batch 42, Training Loss: 0.7062860329945883\n",
            "Epoch 1, Batch 43, Training Loss: 0.875053326288859\n",
            "Epoch 1, Batch 44, Training Loss: 1.7287487983703613\n",
            "Epoch 1, Batch 45, Training Loss: 0.983159065246582\n",
            "Epoch 1, Batch 46, Training Loss: 0.8786813418070475\n",
            "Epoch 1, Batch 47, Training Loss: 1.1778411070505779\n",
            "Epoch 1, Batch 48, Training Loss: 1.1419915358225505\n",
            "Epoch 1, Batch 49, Training Loss: 1.0307925542195637\n",
            "Epoch 1, Batch 50, Training Loss: 1.2835597197214763\n",
            "Epoch 1, Batch 51, Training Loss: 0.9231023788452148\n",
            "Epoch 1, Batch 52, Training Loss: 0.9092657566070557\n",
            "Epoch 1, Batch 53, Training Loss: 0.8381245136260986\n",
            "Epoch 1, Batch 54, Training Loss: 0.6907108624776205\n",
            "Epoch 1, Batch 55, Training Loss: 0.9538678328196207\n",
            "Epoch 1, Batch 56, Training Loss: 1.048816442489624\n",
            "Epoch 1, Batch 57, Training Loss: 0.7461122671763102\n",
            "Epoch 1, Batch 58, Training Loss: 0.9908541838328043\n",
            "Epoch 1, Batch 59, Training Loss: 1.1172274748484294\n",
            "Epoch 1, Batch 60, Training Loss: 0.7549833456675211\n",
            "Epoch 1, Batch 61, Training Loss: 0.7913598219553629\n",
            "Epoch 1, Batch 62, Training Loss: 0.7822277545928955\n",
            "Epoch 1, Batch 63, Training Loss: 1.0362655321757\n",
            "Epoch 1, Batch 64, Training Loss: 0.9127287069956461\n",
            "Epoch 1, Batch 65, Training Loss: 1.1739379564921062\n",
            "Epoch 1, Batch 66, Training Loss: 0.7836140791575114\n",
            "Epoch 1, Batch 67, Training Loss: 0.7658565839131674\n",
            "Epoch 1, Batch 68, Training Loss: 0.9010908603668213\n",
            "Epoch 1, Batch 69, Training Loss: 0.7862358093261719\n",
            "Epoch 1, Batch 70, Training Loss: 0.8170135021209717\n",
            "Epoch 1, Batch 71, Training Loss: 1.0146928628285725\n",
            "Epoch 1, Batch 72, Training Loss: 1.2508103052775066\n",
            "Epoch 1, Batch 73, Training Loss: 1.0587228139241536\n",
            "Epoch 1, Batch 74, Training Loss: 0.8535660107930502\n",
            "Epoch 1, Batch 75, Training Loss: 0.911236047744751\n",
            "Epoch 1, Batch 76, Training Loss: 0.8337173461914062\n",
            "Epoch 1, Batch 77, Training Loss: 1.1998393535614014\n",
            "Epoch 1, Batch 78, Training Loss: 1.1317317485809326\n",
            "Epoch 1, Batch 79, Training Loss: 0.8683807849884033\n",
            "Epoch 1, Batch 80, Training Loss: 1.1274181207021077\n",
            "Epoch 1, Batch 81, Training Loss: 1.2804055213928223\n",
            "Epoch 1, Batch 82, Training Loss: 0.8782411416371664\n",
            "Epoch 1, Batch 83, Training Loss: 0.8456767400105795\n",
            "Epoch 1, Batch 84, Training Loss: 1.1671493848164876\n",
            "Epoch 1, Batch 85, Training Loss: 0.8072362740834554\n",
            "Epoch 1, Batch 86, Training Loss: 1.3205739657084148\n",
            "Epoch 1, Batch 87, Training Loss: 0.842247486114502\n",
            "Epoch 1, Batch 88, Training Loss: 1.1773938337961833\n",
            "Epoch 1, Batch 89, Training Loss: 0.8036712805430094\n",
            "Epoch 1, Batch 90, Training Loss: 0.8750946521759033\n",
            "Epoch 1, Batch 91, Training Loss: 0.9174408912658691\n",
            "Epoch 1, Batch 92, Training Loss: 0.89692489306132\n",
            "Epoch 1, Batch 93, Training Loss: 0.8494342962900797\n",
            "Epoch 1, Batch 94, Training Loss: 1.1119999885559082\n",
            "Epoch 1, Batch 95, Training Loss: 0.6369756460189819\n",
            "Epoch 1, Batch 96, Training Loss: 0.734842856725057\n",
            "Epoch 1, Batch 97, Training Loss: 1.2374927202860515\n",
            "Epoch 1, Batch 98, Training Loss: 1.2758869330088298\n",
            "Epoch 1, Batch 99, Training Loss: 1.0014753341674805\n",
            "Epoch 1, Batch 100, Training Loss: 1.0721663633982341\n",
            "Epoch 1, Batch 101, Training Loss: 1.0302886962890625\n",
            "Epoch 1, Batch 102, Training Loss: 0.6258546908696493\n",
            "Epoch 1, Batch 103, Training Loss: 0.9909188747406006\n",
            "Epoch 1, Batch 104, Training Loss: 0.75517471631368\n",
            "Epoch 1, Batch 105, Training Loss: 0.8368224302927653\n",
            "Epoch 1, Batch 106, Training Loss: 0.9651610056559244\n",
            "Epoch 1, Batch 107, Training Loss: 1.3823858896891277\n",
            "Epoch 1, Batch 108, Training Loss: 1.19119660059611\n",
            "Epoch 1, Batch 109, Training Loss: 0.8061761061350504\n",
            "Epoch 1, Batch 110, Training Loss: 0.8513279755910238\n",
            "Epoch 1, Batch 111, Training Loss: 0.5498059988021851\n",
            "Epoch 1, Batch 112, Training Loss: 0.8552322387695312\n",
            "Epoch 1, Batch 113, Training Loss: 1.0609536170959473\n",
            "Epoch 1, Batch 114, Training Loss: 0.9961387316385905\n",
            "Epoch 1, Batch 115, Training Loss: 0.9944482644399008\n",
            "Epoch 1, Batch 116, Training Loss: 1.164300759633382\n",
            "Epoch 1, Batch 117, Training Loss: 1.0043932596842449\n",
            "Epoch 1, Batch 118, Training Loss: 0.984456459681193\n",
            "Epoch 1, Batch 119, Training Loss: 0.8600152333577474\n",
            "Epoch 1, Batch 120, Training Loss: 1.00886066754659\n",
            "Epoch 1, Batch 121, Training Loss: 1.127323309580485\n",
            "Epoch 1, Batch 122, Training Loss: 0.9393134117126465\n",
            "Epoch 1, Batch 123, Training Loss: 1.1220766703287761\n",
            "Epoch 1, Batch 124, Training Loss: 0.9293495814005533\n",
            "Epoch 1, Batch 125, Training Loss: 0.7964669863382975\n",
            "Epoch 1, Batch 126, Training Loss: 1.0484778881072998\n",
            "Epoch 1, Batch 127, Training Loss: 0.8972342014312744\n",
            "Epoch 1, Batch 128, Training Loss: 0.9109656016031901\n",
            "Epoch 1, Batch 129, Training Loss: 1.3840516408284504\n",
            "Epoch 1, Batch 130, Training Loss: 0.8868891398111979\n",
            "Epoch 1, Batch 131, Training Loss: 1.1362041632334392\n",
            "Epoch 1, Batch 132, Training Loss: 1.22783358891805\n",
            "Epoch 1, Batch 133, Training Loss: 0.7936469713846842\n",
            "Epoch 1, Batch 134, Training Loss: 1.028086264928182\n",
            "Epoch 1 finished. Average Training Loss: 2.9245538907264597\n",
            "Epoch 2, Batch 1, Training Loss: 1.2748591899871826\n",
            "Epoch 2, Batch 2, Training Loss: 0.6673766771952311\n",
            "Epoch 2, Batch 3, Training Loss: 0.9296607176462809\n",
            "Epoch 2, Batch 4, Training Loss: 1.2212598323822021\n",
            "Epoch 2, Batch 5, Training Loss: 1.079649845759074\n",
            "Epoch 2, Batch 6, Training Loss: 0.8010422388712565\n",
            "Epoch 2, Batch 7, Training Loss: 1.1877540747324626\n",
            "Epoch 2, Batch 8, Training Loss: 1.0371522903442383\n",
            "Epoch 2, Batch 9, Training Loss: 0.8893661499023438\n",
            "Epoch 2, Batch 10, Training Loss: 0.779990037282308\n",
            "Epoch 2, Batch 11, Training Loss: 1.163749138514201\n",
            "Epoch 2, Batch 12, Training Loss: 0.8349926471710205\n",
            "Epoch 2, Batch 13, Training Loss: 1.026856501897176\n",
            "Epoch 2, Batch 14, Training Loss: 1.0692384243011475\n",
            "Epoch 2, Batch 15, Training Loss: 0.8019294738769531\n",
            "Epoch 2, Batch 16, Training Loss: 0.6351421276728312\n",
            "Epoch 2, Batch 17, Training Loss: 0.9731706778208414\n",
            "Epoch 2, Batch 18, Training Loss: 0.8599006334940592\n",
            "Epoch 2, Batch 19, Training Loss: 1.3067447344462078\n",
            "Epoch 2, Batch 20, Training Loss: 0.8965798219045004\n",
            "Epoch 2, Batch 21, Training Loss: 0.9182207584381104\n",
            "Epoch 2, Batch 22, Training Loss: 1.0297338167826335\n",
            "Epoch 2, Batch 23, Training Loss: 1.0395111242930095\n",
            "Epoch 2, Batch 24, Training Loss: 1.0079696973164876\n",
            "Epoch 2, Batch 25, Training Loss: 0.8086699644724528\n",
            "Epoch 2, Batch 26, Training Loss: 0.9799963633219401\n",
            "Epoch 2, Batch 27, Training Loss: 0.9627166589101156\n",
            "Epoch 2, Batch 28, Training Loss: 0.7572546799977621\n",
            "Epoch 2, Batch 29, Training Loss: 0.8486553827921549\n",
            "Epoch 2, Batch 30, Training Loss: 0.8079246679941813\n",
            "Epoch 2, Batch 31, Training Loss: 0.7596096197764078\n",
            "Epoch 2, Batch 32, Training Loss: 1.0824828147888184\n",
            "Epoch 2, Batch 33, Training Loss: 1.1130900382995605\n",
            "Epoch 2, Batch 34, Training Loss: 0.9913060665130615\n",
            "Epoch 2, Batch 35, Training Loss: 1.1133636633555095\n",
            "Epoch 2, Batch 36, Training Loss: 1.3061742782592773\n",
            "Epoch 2, Batch 37, Training Loss: 1.0522967179616292\n",
            "Epoch 2, Batch 38, Training Loss: 0.7241912682851156\n",
            "Epoch 2, Batch 39, Training Loss: 0.9588689009348551\n",
            "Epoch 2, Batch 40, Training Loss: 1.0462008317311604\n",
            "Epoch 2, Batch 41, Training Loss: 1.0883833567301433\n",
            "Epoch 2, Batch 42, Training Loss: 1.1257575352986653\n",
            "Epoch 2, Batch 43, Training Loss: 0.822762648264567\n",
            "Epoch 2, Batch 44, Training Loss: 0.9867456754048666\n",
            "Epoch 2, Batch 45, Training Loss: 0.846739927927653\n",
            "Epoch 2, Batch 46, Training Loss: 0.9202466805775961\n",
            "Epoch 2, Batch 47, Training Loss: 1.0740210215250652\n",
            "Epoch 2, Batch 48, Training Loss: 1.2703805764516194\n",
            "Epoch 2, Batch 49, Training Loss: 1.3945686022440593\n",
            "Epoch 2, Batch 50, Training Loss: 0.8450698057810465\n",
            "Epoch 2, Batch 51, Training Loss: 1.1876998742421467\n",
            "Epoch 2, Batch 52, Training Loss: 0.9129431247711182\n",
            "Epoch 2, Batch 53, Training Loss: 0.8363376458485922\n",
            "Epoch 2, Batch 54, Training Loss: 0.8773638407389323\n",
            "Epoch 2, Batch 55, Training Loss: 0.8996544679005941\n",
            "Epoch 2, Batch 56, Training Loss: 0.9962712128957113\n",
            "Epoch 2, Batch 57, Training Loss: 1.1368285814921062\n",
            "Epoch 2, Batch 58, Training Loss: 0.9383512338002523\n",
            "Epoch 2, Batch 59, Training Loss: 1.003800868988037\n",
            "Epoch 2, Batch 60, Training Loss: 1.0461725393931072\n",
            "Epoch 2, Batch 61, Training Loss: 1.410643736521403\n",
            "Epoch 2, Batch 62, Training Loss: 1.2131070295969646\n",
            "Epoch 2, Batch 63, Training Loss: 0.8453475634256998\n",
            "Epoch 2, Batch 64, Training Loss: 0.7076128323872884\n",
            "Epoch 2, Batch 65, Training Loss: 0.794209877649943\n",
            "Epoch 2, Batch 66, Training Loss: 1.0476906299591064\n",
            "Epoch 2, Batch 67, Training Loss: 0.8941040833791097\n",
            "Epoch 2, Batch 68, Training Loss: 0.9265871047973633\n",
            "Epoch 2, Batch 69, Training Loss: 1.3682858149210613\n",
            "Epoch 2, Batch 70, Training Loss: 0.732285737991333\n",
            "Epoch 2, Batch 71, Training Loss: 0.994208017985026\n",
            "Epoch 2, Batch 72, Training Loss: 1.2667548656463623\n",
            "Epoch 2, Batch 73, Training Loss: 0.7708493868509928\n",
            "Epoch 2, Batch 74, Training Loss: 1.0560541152954102\n",
            "Epoch 2, Batch 75, Training Loss: 0.8987851937611898\n",
            "Epoch 2, Batch 76, Training Loss: 1.0586002667744954\n",
            "Epoch 2, Batch 77, Training Loss: 0.998370885848999\n",
            "Epoch 2, Batch 78, Training Loss: 1.1689630349477131\n",
            "Epoch 2, Batch 79, Training Loss: 0.6842749913533529\n",
            "Epoch 2, Batch 80, Training Loss: 0.9694720904032389\n",
            "Epoch 2, Batch 81, Training Loss: 1.033816893895467\n",
            "Epoch 2, Batch 82, Training Loss: 1.0072401364644368\n",
            "Epoch 2, Batch 83, Training Loss: 0.9028667608896891\n",
            "Epoch 2, Batch 84, Training Loss: 0.9064280986785889\n",
            "Epoch 2, Batch 85, Training Loss: 0.7847083409627279\n",
            "Epoch 2, Batch 86, Training Loss: 0.9023023446400961\n",
            "Epoch 2, Batch 87, Training Loss: 1.266572634379069\n",
            "Epoch 2, Batch 88, Training Loss: 0.8165900707244873\n",
            "Epoch 2, Batch 89, Training Loss: 1.010484218597412\n",
            "Epoch 2, Batch 90, Training Loss: 1.194856325785319\n",
            "Epoch 2, Batch 91, Training Loss: 0.9204350312550863\n",
            "Epoch 2, Batch 92, Training Loss: 0.8865411281585693\n",
            "Epoch 2, Batch 93, Training Loss: 1.0150206089019775\n",
            "Epoch 2, Batch 94, Training Loss: 0.9318467775980631\n",
            "Epoch 2, Batch 95, Training Loss: 1.1273001829783122\n",
            "Epoch 2, Batch 96, Training Loss: 0.8261352380116781\n",
            "Epoch 2, Batch 97, Training Loss: 0.9095009167989095\n",
            "Epoch 2, Batch 98, Training Loss: 0.6575878461201986\n",
            "Epoch 2, Batch 99, Training Loss: 0.8604352474212646\n",
            "Epoch 2, Batch 100, Training Loss: 0.8008687496185303\n",
            "Epoch 2, Batch 101, Training Loss: 0.7939780553181967\n",
            "Epoch 2, Batch 102, Training Loss: 0.8935937086741129\n",
            "Epoch 2, Batch 103, Training Loss: 0.6379913091659546\n",
            "Epoch 2, Batch 104, Training Loss: 1.0132765769958496\n",
            "Epoch 2, Batch 105, Training Loss: 0.8213273684183756\n",
            "Epoch 2, Batch 106, Training Loss: 1.1897338231404622\n",
            "Epoch 2, Batch 107, Training Loss: 0.7819618384043375\n",
            "Epoch 2, Batch 108, Training Loss: 0.941638708114624\n",
            "Epoch 2, Batch 109, Training Loss: 1.132196029027303\n",
            "Epoch 2, Batch 110, Training Loss: 0.7507224082946777\n",
            "Epoch 2, Batch 111, Training Loss: 1.0263638496398926\n",
            "Epoch 2, Batch 112, Training Loss: 0.915539026260376\n",
            "Epoch 2, Batch 113, Training Loss: 0.7584746678670248\n",
            "Epoch 2, Batch 114, Training Loss: 0.6953386465708414\n",
            "Epoch 2, Batch 115, Training Loss: 0.7709253629048666\n",
            "Epoch 2, Batch 116, Training Loss: 0.6940413316090902\n",
            "Epoch 2, Batch 117, Training Loss: 0.9344402154286703\n",
            "Epoch 2, Batch 118, Training Loss: 1.2393945852915447\n",
            "Epoch 2, Batch 119, Training Loss: 0.8305761814117432\n",
            "Epoch 2, Batch 120, Training Loss: 0.7450907230377197\n",
            "Epoch 2, Batch 121, Training Loss: 1.0669504006703694\n",
            "Epoch 2, Batch 122, Training Loss: 0.6252851088841757\n",
            "Epoch 2, Batch 123, Training Loss: 1.0446404616038005\n",
            "Epoch 2, Batch 124, Training Loss: 1.3079439798990886\n",
            "Epoch 2, Batch 125, Training Loss: 0.9750860532124838\n",
            "Epoch 2, Batch 126, Training Loss: 0.9801592826843262\n",
            "Epoch 2, Batch 127, Training Loss: 0.686598539352417\n",
            "Epoch 2, Batch 128, Training Loss: 0.782896359761556\n",
            "Epoch 2, Batch 129, Training Loss: 0.7884064515431722\n",
            "Epoch 2, Batch 130, Training Loss: 1.0151840051015217\n",
            "Epoch 2, Batch 131, Training Loss: 1.0577761332194011\n",
            "Epoch 2, Batch 132, Training Loss: 0.8338945706685384\n",
            "Epoch 2, Batch 133, Training Loss: 1.0821142196655273\n",
            "Epoch 2, Batch 134, Training Loss: 0.8576943079630533\n",
            "Epoch 2 finished. Average Training Loss: 2.8700089000943882\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# load the dataset\n",
        "df = pd.read_csv('cnbc_news_datase.csv')\n",
        "df_clean = df.dropna(subset=['description', 'title'])\n",
        "train_df, test_df = train_test_split(df_clean, test_size=0.1, random_state=42)#90% for train and 10% for test\n",
        "\n",
        "class CNBCNewsDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text = row['description']\n",
        "        summary = row['title']\n",
        "\n",
        "        inputs = self.tokenizer(text, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        outputs = self.tokenizer(summary, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].squeeze()\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
        "        labels = outputs[\"input_ids\"].squeeze()\n",
        "        labels[labels==self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "# load the BartTokenizer and BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "\n",
        "# load the data\n",
        "train_dataset = CNBCNewsDataset(train_df, tokenizer)\n",
        "test_dataset = CNBCNewsDataset(test_df, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)# I believe the smaller the batch size have better train effect by link in https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "\n",
        "# set to cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "# get teh optimizer and the change the learn during the\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)  # The learning rate is multiplied by 0.1 every 1 epoch\n",
        "# train the model\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # print each loss\n",
        "        print(f\"Epoch {epoch}, Batch {batch_idx+1}, Training Loss: {loss.item() / len(batch)}\")\n",
        "\n",
        "    #print ave loss\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} finished. Average Training Loss: {avg_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "b47863077d9744a4a6def859deceb68d",
            "fb8af65579f545bf8311b6adfcdd2b85",
            "727542793c854715971017ab5ba9318d",
            "b881797553e44228b38716481032e1de",
            "2db4ed3871864293900efbd3a5f075f4",
            "31901f9e18f145cd946569d804ff2548",
            "a7e5f69d99034b76b1dc6676cb079d80",
            "12589c527ad94ab398297a2ea51fd92b",
            "a43a7721d8cb431384ea90b6e606c151",
            "01e8d5551f1a4ad1a32b8d8bb94adfa2",
            "c1dd7feea9224c4da45112de85c230b7",
            "3f38084c246c4950ac7baab0ddf5ae2e",
            "090f8a3a091c4615b8c4a4bbc52c79b9",
            "521527ed5bc84dce98bcfc9acab3fa7f",
            "80f5a5e318f4422f8568d49398852d3a",
            "ddf723287f4d4a6e9c24ac61e931c1eb",
            "360a0d9b30f842ab92d7c53d96f6dcc3",
            "48425595079542b6b2ae3f4bb5bbdf70",
            "0afb488ed6e4423dbd4d145c3bd4e665",
            "5768d4c219f3414aa53c0c9d88f975bd",
            "089e890676b540b4b1fae936bd9af1ac",
            "3918b2690be944979fdf6d6fcbb7dd47"
          ]
        },
        "id": "Um-OhkxOtY9P",
        "outputId": "21538dbe-885e-478d-88ba-835ffd952e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-bafe1c4c78f2>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b47863077d9744a4a6def859deceb68d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f38084c246c4950ac7baab0ddf5ae2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 2.4949599098782937\n",
            "Average ROUGE Score: {'rouge1': 21.385897198582523, 'rouge2': 7.227082723779985, 'rougeL': 17.165153712348268, 'rougeLsum': 17.09662630138388}\n"
          ]
        }
      ],
      "source": [
        "# load the bleu and rouge\n",
        "bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n",
        "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n",
        "\n",
        "\n",
        "# model eval and get the bleu and rouge\n",
        "bleu_scores = []\n",
        "rouge_scores = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    with torch.no_grad():\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "\n",
        "\n",
        "        preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in outputs]\n",
        "        labels = []\n",
        "        for l in batch['labels'].cpu().numpy():\n",
        "            # Filter out tag IDs with value -100 and then decode\n",
        "            filtered_l = [token for token in l if token != -100]\n",
        "            decoded_label = tokenizer.decode(filtered_l, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "            labels.append([decoded_label])\n",
        "\n",
        "        bleu_scores.append(bleu_metric.compute(predictions=preds, references=labels)['score'])\n",
        "        rouge_output = rouge_metric.compute(predictions=preds, references=[label[0] for label in labels])\n",
        "        rouge_scores.append({key: value.mid.fmeasure * 100 for key, value in rouge_output.items()})#this value is time 100 which in the range of the 0 to 1.\n",
        "\n",
        "avg_bleu = np.mean(bleu_scores)\n",
        "avg_rouge = {key: np.mean([dic[key] for dic in rouge_scores]) for key in rouge_scores[0]}\n",
        "\n",
        "print(\"Average BLEU Score:\", avg_bleu)\n",
        "print(\"Average ROUGE Score:\", avg_rouge)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDlEbxB5tY9N",
        "outputId": "9867d7af-ff29-4c7f-f9cf-9e5e25b7c04d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Epoch 0, Batch 1, Training Loss: 1.0614100297292073\n",
            "Epoch 0, Batch 2, Training Loss: 1.3663509686787922\n",
            "Epoch 0, Batch 3, Training Loss: 0.9069466590881348\n",
            "Epoch 0, Batch 4, Training Loss: 1.1119468212127686\n",
            "Epoch 0, Batch 5, Training Loss: 0.9895305633544922\n",
            "Epoch 0, Batch 6, Training Loss: 1.5514216423034668\n",
            "Epoch 0, Batch 7, Training Loss: 1.746489683787028\n",
            "Epoch 0, Batch 8, Training Loss: 1.984822432200114\n",
            "Epoch 0, Batch 9, Training Loss: 0.7477731704711914\n",
            "Epoch 0, Batch 10, Training Loss: 1.2870992024739583\n",
            "Epoch 0, Batch 11, Training Loss: 1.0155613422393799\n",
            "Epoch 0, Batch 12, Training Loss: 0.9966142177581787\n",
            "Epoch 0, Batch 13, Training Loss: 1.0816644032796223\n",
            "Epoch 0, Batch 14, Training Loss: 1.2090423901875813\n",
            "Epoch 0, Batch 15, Training Loss: 1.506505807240804\n",
            "Epoch 0, Batch 16, Training Loss: 0.9170370101928711\n",
            "Epoch 0, Batch 17, Training Loss: 0.7885950406392416\n",
            "Epoch 0, Batch 18, Training Loss: 0.9237208366394043\n",
            "Epoch 0, Batch 19, Training Loss: 1.2486549218495686\n",
            "Epoch 0, Batch 20, Training Loss: 1.3407549858093262\n",
            "Epoch 0, Batch 21, Training Loss: 1.0789040724436443\n",
            "Epoch 0, Batch 22, Training Loss: 1.272078275680542\n",
            "Epoch 0, Batch 23, Training Loss: 0.8559449513753256\n",
            "Epoch 0, Batch 24, Training Loss: 1.016744057337443\n",
            "Epoch 0, Batch 25, Training Loss: 1.3542416890462239\n",
            "Epoch 0, Batch 26, Training Loss: 1.4549061457316081\n",
            "Epoch 0, Batch 27, Training Loss: 0.8771751721700033\n",
            "Epoch 0, Batch 28, Training Loss: 1.3121308485666912\n",
            "Epoch 0, Batch 29, Training Loss: 1.0997446378072102\n",
            "Epoch 0, Batch 30, Training Loss: 1.0133798122406006\n",
            "Epoch 0, Batch 31, Training Loss: 1.048024574915568\n",
            "Epoch 0, Batch 32, Training Loss: 1.3610130945841472\n",
            "Epoch 0, Batch 33, Training Loss: 0.7022337913513184\n",
            "Epoch 0, Batch 34, Training Loss: 1.0997703075408936\n",
            "Epoch 0, Batch 35, Training Loss: 0.6035575071970621\n",
            "Epoch 0, Batch 36, Training Loss: 0.9771766662597656\n",
            "Epoch 0, Batch 37, Training Loss: 1.1800533135732014\n",
            "Epoch 0, Batch 38, Training Loss: 0.7883749008178711\n",
            "Epoch 0, Batch 39, Training Loss: 1.7208080291748047\n",
            "Epoch 0, Batch 40, Training Loss: 1.0068989594777424\n",
            "Epoch 0, Batch 41, Training Loss: 0.9894933700561523\n",
            "Epoch 0, Batch 42, Training Loss: 1.6254679361979167\n",
            "Epoch 0, Batch 43, Training Loss: 0.9004329840342203\n",
            "Epoch 0, Batch 44, Training Loss: 0.840702215830485\n",
            "Epoch 0, Batch 45, Training Loss: 0.899982770284017\n",
            "Epoch 0, Batch 46, Training Loss: 0.8920478026072184\n",
            "Epoch 0, Batch 47, Training Loss: 0.7060361703236898\n",
            "Epoch 0, Batch 48, Training Loss: 1.0389540195465088\n",
            "Epoch 0, Batch 49, Training Loss: 0.9306966463724772\n",
            "Epoch 0, Batch 50, Training Loss: 1.3622336387634277\n",
            "Epoch 0, Batch 51, Training Loss: 0.6294951438903809\n",
            "Epoch 0, Batch 52, Training Loss: 0.965156634648641\n",
            "Epoch 0, Batch 53, Training Loss: 0.9334867000579834\n",
            "Epoch 0, Batch 54, Training Loss: 1.199121316274007\n",
            "Epoch 0, Batch 55, Training Loss: 0.8831778367360433\n",
            "Epoch 0, Batch 56, Training Loss: 0.9929158687591553\n",
            "Epoch 0, Batch 57, Training Loss: 0.8774651686350504\n",
            "Epoch 0, Batch 58, Training Loss: 1.4153761863708496\n",
            "Epoch 0, Batch 59, Training Loss: 0.8016313711802164\n",
            "Epoch 0, Batch 60, Training Loss: 1.0348858833312988\n",
            "Epoch 0, Batch 61, Training Loss: 1.2664791742960613\n",
            "Epoch 0, Batch 62, Training Loss: 0.9791677792867025\n",
            "Epoch 0, Batch 63, Training Loss: 0.9080682595570883\n",
            "Epoch 0, Batch 64, Training Loss: 0.8033603032430013\n",
            "Epoch 0, Batch 65, Training Loss: 1.4084692001342773\n",
            "Epoch 0, Batch 66, Training Loss: 0.9982049465179443\n",
            "Epoch 0, Batch 67, Training Loss: 0.920998732248942\n",
            "Epoch 0, Batch 68, Training Loss: 1.6474253336588542\n",
            "Epoch 0, Batch 69, Training Loss: 0.8862036069234213\n",
            "Epoch 0, Batch 70, Training Loss: 0.9143659273783366\n",
            "Epoch 0, Batch 71, Training Loss: 1.1548497676849365\n",
            "Epoch 0, Batch 72, Training Loss: 1.1839721202850342\n",
            "Epoch 0, Batch 73, Training Loss: 1.103808879852295\n",
            "Epoch 0, Batch 74, Training Loss: 1.2367510000864665\n",
            "Epoch 0, Batch 75, Training Loss: 1.1781437397003174\n",
            "Epoch 0, Batch 76, Training Loss: 0.7939984798431396\n",
            "Epoch 0, Batch 77, Training Loss: 0.9436171849568685\n",
            "Epoch 0, Batch 78, Training Loss: 0.7001144886016846\n",
            "Epoch 0, Batch 79, Training Loss: 1.0801801681518555\n",
            "Epoch 0, Batch 80, Training Loss: 0.8567517598470052\n",
            "Epoch 0, Batch 81, Training Loss: 1.11870543162028\n",
            "Epoch 0, Batch 82, Training Loss: 1.1205678780873616\n",
            "Epoch 0, Batch 83, Training Loss: 0.762253204981486\n",
            "Epoch 0, Batch 84, Training Loss: 1.1441168785095215\n",
            "Epoch 0, Batch 85, Training Loss: 1.3358205159505208\n",
            "Epoch 0, Batch 86, Training Loss: 1.1867666244506836\n",
            "Epoch 0, Batch 87, Training Loss: 1.0168065230051677\n",
            "Epoch 0, Batch 88, Training Loss: 1.0970211029052734\n",
            "Epoch 0, Batch 89, Training Loss: 1.1698933442433674\n",
            "Epoch 0, Batch 90, Training Loss: 0.8060378233591715\n",
            "Epoch 0, Batch 91, Training Loss: 1.322332541147868\n",
            "Epoch 0, Batch 92, Training Loss: 1.017212947209676\n",
            "Epoch 0, Batch 93, Training Loss: 1.141908327738444\n",
            "Epoch 0, Batch 94, Training Loss: 1.0768905480702717\n",
            "Epoch 0, Batch 95, Training Loss: 0.8901944955190023\n",
            "Epoch 0, Batch 96, Training Loss: 0.6334924300511678\n",
            "Epoch 0, Batch 97, Training Loss: 1.0713895161946614\n",
            "Epoch 0, Batch 98, Training Loss: 1.1983669598897297\n",
            "Epoch 0, Batch 99, Training Loss: 0.7355350653330485\n",
            "Epoch 0, Batch 100, Training Loss: 1.22622815767924\n",
            "Epoch 0, Batch 101, Training Loss: 0.6920819282531738\n",
            "Epoch 0, Batch 102, Training Loss: 0.9204647541046143\n",
            "Epoch 0, Batch 103, Training Loss: 1.1453608671824138\n",
            "Epoch 0, Batch 104, Training Loss: 0.8772408962249756\n",
            "Epoch 0, Batch 105, Training Loss: 1.1101198196411133\n",
            "Epoch 0, Batch 106, Training Loss: 0.8782684803009033\n",
            "Epoch 0, Batch 107, Training Loss: 1.1343838373819988\n",
            "Epoch 0, Batch 108, Training Loss: 1.0786964893341064\n",
            "Epoch 0, Batch 109, Training Loss: 0.9066879749298096\n",
            "Epoch 0, Batch 110, Training Loss: 1.2479310035705566\n",
            "Epoch 0, Batch 111, Training Loss: 0.9274393717447916\n",
            "Epoch 0, Batch 112, Training Loss: 0.7018622557322184\n",
            "Epoch 0, Batch 113, Training Loss: 0.8727864424387614\n",
            "Epoch 0, Batch 114, Training Loss: 1.0914653937021892\n",
            "Epoch 0, Batch 115, Training Loss: 1.006987492243449\n",
            "Epoch 0, Batch 116, Training Loss: 0.8854864438374838\n",
            "Epoch 0, Batch 117, Training Loss: 1.240546703338623\n",
            "Epoch 0, Batch 118, Training Loss: 0.9458557764689127\n",
            "Epoch 0, Batch 119, Training Loss: 0.7416348457336426\n",
            "Epoch 0, Batch 120, Training Loss: 1.463078498840332\n",
            "Epoch 0, Batch 121, Training Loss: 1.4465856552124023\n",
            "Epoch 0, Batch 122, Training Loss: 0.9387761751810709\n",
            "Epoch 0, Batch 123, Training Loss: 0.8808588186899821\n",
            "Epoch 0, Batch 124, Training Loss: 1.335417111714681\n",
            "Epoch 0, Batch 125, Training Loss: 0.9358088970184326\n",
            "Epoch 0, Batch 126, Training Loss: 1.1131961345672607\n",
            "Epoch 0, Batch 127, Training Loss: 1.1267345746358235\n",
            "Epoch 0, Batch 128, Training Loss: 1.230212132136027\n",
            "Epoch 0, Batch 129, Training Loss: 0.9272309144337972\n",
            "Epoch 0, Batch 130, Training Loss: 0.936302105585734\n",
            "Epoch 0, Batch 131, Training Loss: 1.0614330768585205\n",
            "Epoch 0, Batch 132, Training Loss: 0.7238368988037109\n",
            "Epoch 0, Batch 133, Training Loss: 1.1645371119181316\n",
            "Epoch 0, Batch 134, Training Loss: 0.6973674297332764\n",
            "Epoch 0, Batch 135, Training Loss: 0.8441364765167236\n",
            "Epoch 0, Batch 136, Training Loss: 0.8953733444213867\n",
            "Epoch 0, Batch 137, Training Loss: 0.7276183764139811\n",
            "Epoch 0, Batch 138, Training Loss: 1.1807097593943279\n",
            "Epoch 0, Batch 139, Training Loss: 0.8360579013824463\n",
            "Epoch 0, Batch 140, Training Loss: 1.1125311851501465\n",
            "Epoch 0, Batch 141, Training Loss: 1.4681722323099773\n",
            "Epoch 0, Batch 142, Training Loss: 1.3064053058624268\n",
            "Epoch 0, Batch 143, Training Loss: 0.8120981057484945\n",
            "Epoch 0, Batch 144, Training Loss: 0.9084770679473877\n",
            "Epoch 0, Batch 145, Training Loss: 1.7837204933166504\n",
            "Epoch 0, Batch 146, Training Loss: 0.7042492230733236\n",
            "Epoch 0, Batch 147, Training Loss: 1.1535720825195312\n",
            "Epoch 0, Batch 148, Training Loss: 0.843005100886027\n",
            "Epoch 0, Batch 149, Training Loss: 0.7442041238149008\n",
            "Epoch 0, Batch 150, Training Loss: 0.5264588594436646\n",
            "Epoch 0, Batch 151, Training Loss: 0.7175358136494955\n",
            "Epoch 0, Batch 152, Training Loss: 1.2574910322825115\n",
            "Epoch 0, Batch 153, Training Loss: 0.7569662729899088\n",
            "Epoch 0, Batch 154, Training Loss: 0.6742603778839111\n",
            "Epoch 0, Batch 155, Training Loss: 0.9650054772694906\n",
            "Epoch 0, Batch 156, Training Loss: 0.9409279823303223\n",
            "Epoch 0, Batch 157, Training Loss: 0.7299893697102865\n",
            "Epoch 0, Batch 158, Training Loss: 0.6601539055506388\n",
            "Epoch 0, Batch 159, Training Loss: 0.9288830757141113\n",
            "Epoch 0, Batch 160, Training Loss: 1.133174975713094\n",
            "Epoch 0, Batch 161, Training Loss: 1.11821182568868\n",
            "Epoch 0, Batch 162, Training Loss: 0.6582945982615153\n",
            "Epoch 0, Batch 163, Training Loss: 0.9765114784240723\n",
            "Epoch 0, Batch 164, Training Loss: 1.9321357409159343\n",
            "Epoch 0, Batch 165, Training Loss: 0.7975826263427734\n",
            "Epoch 0, Batch 166, Training Loss: 1.1255488395690918\n",
            "Epoch 0, Batch 167, Training Loss: 0.9411515394846598\n",
            "Epoch 0, Batch 168, Training Loss: 1.0695269107818604\n",
            "Epoch 0, Batch 169, Training Loss: 0.976355791091919\n",
            "Epoch 0, Batch 170, Training Loss: 0.8050111929575602\n",
            "Epoch 0, Batch 171, Training Loss: 1.0479352474212646\n",
            "Epoch 0, Batch 172, Training Loss: 1.0963008403778076\n",
            "Epoch 0, Batch 173, Training Loss: 1.0258948802947998\n",
            "Epoch 0, Batch 174, Training Loss: 0.9864885012308756\n",
            "Epoch 0, Batch 175, Training Loss: 0.8598127365112305\n",
            "Epoch 0, Batch 176, Training Loss: 1.090884764989217\n",
            "Epoch 0, Batch 177, Training Loss: 1.4706048965454102\n",
            "Epoch 0, Batch 178, Training Loss: 1.2885758876800537\n",
            "Epoch 0, Batch 179, Training Loss: 0.9096464316050211\n",
            "Epoch 0, Batch 180, Training Loss: 0.8165405591328939\n",
            "Epoch 0, Batch 181, Training Loss: 0.8542212645212809\n",
            "Epoch 0, Batch 182, Training Loss: 0.6950412591298422\n",
            "Epoch 0, Batch 183, Training Loss: 0.9207211335500082\n",
            "Epoch 0, Batch 184, Training Loss: 1.012467384338379\n",
            "Epoch 0, Batch 185, Training Loss: 1.1554382642110188\n",
            "Epoch 0, Batch 186, Training Loss: 1.2665212949117024\n",
            "Epoch 0, Batch 187, Training Loss: 0.8030467828114828\n",
            "Epoch 0, Batch 188, Training Loss: 0.6552222569783529\n",
            "Epoch 0, Batch 189, Training Loss: 1.2177892525990803\n",
            "Epoch 0, Batch 190, Training Loss: 1.0773624579111736\n",
            "Epoch 0, Batch 191, Training Loss: 0.9744927883148193\n",
            "Epoch 0, Batch 192, Training Loss: 1.2653694152832031\n",
            "Epoch 0, Batch 193, Training Loss: 0.6029299894968668\n",
            "Epoch 0, Batch 194, Training Loss: 1.2850573062896729\n",
            "Epoch 0, Batch 195, Training Loss: 0.7369558016459147\n",
            "Epoch 0, Batch 196, Training Loss: 1.0218230883280437\n",
            "Epoch 0, Batch 197, Training Loss: 1.147924264272054\n",
            "Epoch 0, Batch 198, Training Loss: 1.2263277371724446\n",
            "Epoch 0, Batch 199, Training Loss: 0.9621600310007731\n",
            "Epoch 0, Batch 200, Training Loss: 0.9101072947184244\n",
            "Epoch 0, Batch 201, Training Loss: 0.923940102259318\n",
            "Epoch 0, Batch 202, Training Loss: 1.1515161196390789\n",
            "Epoch 0, Batch 203, Training Loss: 1.3389369646708171\n",
            "Epoch 0, Batch 204, Training Loss: 0.8981184959411621\n",
            "Epoch 0, Batch 205, Training Loss: 0.784061590830485\n",
            "Epoch 0, Batch 206, Training Loss: 0.9741621017456055\n",
            "Epoch 0, Batch 207, Training Loss: 0.7864140669504801\n",
            "Epoch 0, Batch 208, Training Loss: 0.8689552942911783\n",
            "Epoch 0, Batch 209, Training Loss: 0.9225912888844808\n",
            "Epoch 0, Batch 210, Training Loss: 1.0702869097391765\n",
            "Epoch 0, Batch 211, Training Loss: 0.7065213521321615\n",
            "Epoch 0, Batch 212, Training Loss: 1.246073802312215\n",
            "Epoch 0, Batch 213, Training Loss: 1.1052878697713215\n",
            "Epoch 0, Batch 214, Training Loss: 0.8862241903940836\n",
            "Epoch 0, Batch 215, Training Loss: 0.8509651819864908\n",
            "Epoch 0, Batch 216, Training Loss: 1.033660888671875\n",
            "Epoch 0, Batch 217, Training Loss: 0.8185129165649414\n",
            "Epoch 0, Batch 218, Training Loss: 0.9542026519775391\n",
            "Epoch 0, Batch 219, Training Loss: 0.9330039819081625\n",
            "Epoch 0, Batch 220, Training Loss: 0.834327220916748\n",
            "Epoch 0, Batch 221, Training Loss: 0.951095978418986\n",
            "Epoch 0, Batch 222, Training Loss: 0.5447507301966349\n",
            "Epoch 0, Batch 223, Training Loss: 1.0780079364776611\n",
            "Epoch 0, Batch 224, Training Loss: 0.8714001973470052\n",
            "Epoch 0, Batch 225, Training Loss: 0.9417774677276611\n",
            "Epoch 0, Batch 226, Training Loss: 1.1962216695149739\n",
            "Epoch 0, Batch 227, Training Loss: 1.10023029645284\n",
            "Epoch 0, Batch 228, Training Loss: 0.7552957534790039\n",
            "Epoch 0, Batch 229, Training Loss: 1.0977696577707927\n",
            "Epoch 0, Batch 230, Training Loss: 1.079799969991048\n",
            "Epoch 0, Batch 231, Training Loss: 1.1403826872507732\n",
            "Epoch 0, Batch 232, Training Loss: 1.036680777867635\n",
            "Epoch 0, Batch 233, Training Loss: 1.1151665846506755\n",
            "Epoch 0, Batch 234, Training Loss: 1.6413510640462239\n",
            "Epoch 0, Batch 235, Training Loss: 0.9409265518188477\n",
            "Epoch 0, Batch 236, Training Loss: 1.2924821376800537\n",
            "Epoch 0, Batch 237, Training Loss: 0.674608071645101\n",
            "Epoch 0, Batch 238, Training Loss: 0.9947254657745361\n",
            "Epoch 0, Batch 239, Training Loss: 0.8954779307047526\n",
            "Epoch 0, Batch 240, Training Loss: 0.9925731817881266\n",
            "Epoch 0, Batch 241, Training Loss: 0.8224231402079264\n",
            "Epoch 0, Batch 242, Training Loss: 0.9592635631561279\n",
            "Epoch 0, Batch 243, Training Loss: 1.0985567569732666\n",
            "Epoch 0, Batch 244, Training Loss: 0.9381755193074545\n",
            "Epoch 0, Batch 245, Training Loss: 1.2467439969380696\n",
            "Epoch 0, Batch 246, Training Loss: 0.6113235553105673\n",
            "Epoch 0, Batch 247, Training Loss: 0.822708527247111\n",
            "Epoch 0, Batch 248, Training Loss: 1.1913314660390217\n",
            "Epoch 0, Batch 249, Training Loss: 0.9520779450734457\n",
            "Epoch 0, Batch 250, Training Loss: 1.190729061762492\n",
            "Epoch 0, Batch 251, Training Loss: 1.1315927505493164\n",
            "Epoch 0, Batch 252, Training Loss: 1.4820367495218914\n",
            "Epoch 0, Batch 253, Training Loss: 0.5400426387786865\n",
            "Epoch 0, Batch 254, Training Loss: 0.8780014514923096\n",
            "Epoch 0, Batch 255, Training Loss: 0.932028611501058\n",
            "Epoch 0, Batch 256, Training Loss: 1.0363560517628987\n",
            "Epoch 0, Batch 257, Training Loss: 0.6836992899576823\n",
            "Epoch 0, Batch 258, Training Loss: 0.9861625035603842\n",
            "Epoch 0, Batch 259, Training Loss: 0.7401773929595947\n",
            "Epoch 0, Batch 260, Training Loss: 1.159710963567098\n",
            "Epoch 0, Batch 261, Training Loss: 1.129157304763794\n",
            "Epoch 0, Batch 262, Training Loss: 0.47620880603790283\n",
            "Epoch 0, Batch 263, Training Loss: 1.066151221593221\n",
            "Epoch 0, Batch 264, Training Loss: 1.0285045305887859\n",
            "Epoch 0, Batch 265, Training Loss: 1.1619642575581868\n",
            "Epoch 0, Batch 266, Training Loss: 0.40963172912597656\n",
            "Epoch 0, Batch 267, Training Loss: 0.9618656635284424\n",
            "Epoch 0 finished. Average Training Loss: 3.060756122574824\n",
            "Epoch 1, Batch 1, Training Loss: 0.6040318806966146\n",
            "Epoch 1, Batch 2, Training Loss: 0.4956932067871094\n",
            "Epoch 1, Batch 3, Training Loss: 0.6787870724995931\n",
            "Epoch 1, Batch 4, Training Loss: 0.6102123260498047\n",
            "Epoch 1, Batch 5, Training Loss: 0.5770041545232137\n",
            "Epoch 1, Batch 6, Training Loss: 0.36232654253641766\n",
            "Epoch 1, Batch 7, Training Loss: 0.6242485046386719\n",
            "Epoch 1, Batch 8, Training Loss: 0.3865634600321452\n",
            "Epoch 1, Batch 9, Training Loss: 0.8456699848175049\n",
            "Epoch 1, Batch 10, Training Loss: 0.5225826501846313\n",
            "Epoch 1, Batch 11, Training Loss: 0.368034561475118\n",
            "Epoch 1, Batch 12, Training Loss: 0.46290767192840576\n",
            "Epoch 1, Batch 13, Training Loss: 0.9634291330973307\n",
            "Epoch 1, Batch 14, Training Loss: 0.5225900014241537\n",
            "Epoch 1, Batch 15, Training Loss: 0.6689527829488119\n",
            "Epoch 1, Batch 16, Training Loss: 0.9622534116109213\n",
            "Epoch 1, Batch 17, Training Loss: 0.41354119777679443\n",
            "Epoch 1, Batch 18, Training Loss: 1.0185680389404297\n",
            "Epoch 1, Batch 19, Training Loss: 0.47955799102783203\n",
            "Epoch 1, Batch 20, Training Loss: 0.609380046526591\n",
            "Epoch 1, Batch 21, Training Loss: 0.5636997620264689\n",
            "Epoch 1, Batch 22, Training Loss: 0.5391069253285726\n",
            "Epoch 1, Batch 23, Training Loss: 0.4211483399073283\n",
            "Epoch 1, Batch 24, Training Loss: 0.22223110993703207\n",
            "Epoch 1, Batch 25, Training Loss: 0.518372654914856\n",
            "Epoch 1, Batch 26, Training Loss: 0.7338748772939047\n",
            "Epoch 1, Batch 27, Training Loss: 0.638115644454956\n",
            "Epoch 1, Batch 28, Training Loss: 0.5198738972345988\n",
            "Epoch 1, Batch 29, Training Loss: 0.7952621777852377\n",
            "Epoch 1, Batch 30, Training Loss: 0.49684810638427734\n",
            "Epoch 1, Batch 31, Training Loss: 0.7677265803019205\n",
            "Epoch 1, Batch 32, Training Loss: 0.42243051528930664\n",
            "Epoch 1, Batch 33, Training Loss: 0.5597863594690958\n",
            "Epoch 1, Batch 34, Training Loss: 0.6635180314381918\n",
            "Epoch 1, Batch 35, Training Loss: 0.8494305610656738\n",
            "Epoch 1, Batch 36, Training Loss: 0.5932464202245077\n",
            "Epoch 1, Batch 37, Training Loss: 0.4660502274831136\n",
            "Epoch 1, Batch 38, Training Loss: 0.6339526176452637\n",
            "Epoch 1, Batch 39, Training Loss: 0.42026305198669434\n",
            "Epoch 1, Batch 40, Training Loss: 0.5029643376668295\n",
            "Epoch 1, Batch 41, Training Loss: 0.4456497033437093\n",
            "Epoch 1, Batch 42, Training Loss: 0.9415034453074137\n",
            "Epoch 1, Batch 43, Training Loss: 0.4654005765914917\n",
            "Epoch 1, Batch 44, Training Loss: 0.37352216243743896\n",
            "Epoch 1, Batch 45, Training Loss: 0.7154565652211508\n",
            "Epoch 1, Batch 46, Training Loss: 0.5670704046885172\n",
            "Epoch 1, Batch 47, Training Loss: 1.2645853360493977\n",
            "Epoch 1, Batch 48, Training Loss: 0.8030316034952799\n",
            "Epoch 1, Batch 49, Training Loss: 0.31619662046432495\n",
            "Epoch 1, Batch 50, Training Loss: 0.7298049926757812\n",
            "Epoch 1, Batch 51, Training Loss: 0.33151431878407794\n",
            "Epoch 1, Batch 52, Training Loss: 0.5397562185923258\n",
            "Epoch 1, Batch 53, Training Loss: 0.43983447551727295\n",
            "Epoch 1, Batch 54, Training Loss: 0.3263649145762126\n",
            "Epoch 1, Batch 55, Training Loss: 0.4874461491902669\n",
            "Epoch 1, Batch 56, Training Loss: 0.6341030995051066\n",
            "Epoch 1, Batch 57, Training Loss: 0.3279149532318115\n",
            "Epoch 1, Batch 58, Training Loss: 0.31064977248509723\n",
            "Epoch 1, Batch 59, Training Loss: 0.522446076075236\n",
            "Epoch 1, Batch 60, Training Loss: 0.8620165983835856\n",
            "Epoch 1, Batch 61, Training Loss: 0.8860816955566406\n",
            "Epoch 1, Batch 62, Training Loss: 0.6749374866485596\n",
            "Epoch 1, Batch 63, Training Loss: 0.4793739318847656\n",
            "Epoch 1, Batch 64, Training Loss: 0.43297866980234784\n",
            "Epoch 1, Batch 65, Training Loss: 0.5918859243392944\n",
            "Epoch 1, Batch 66, Training Loss: 0.9056522846221924\n",
            "Epoch 1, Batch 67, Training Loss: 0.5615442196528116\n",
            "Epoch 1, Batch 68, Training Loss: 0.8138363361358643\n",
            "Epoch 1, Batch 69, Training Loss: 0.4486311674118042\n",
            "Epoch 1, Batch 70, Training Loss: 0.9321708679199219\n",
            "Epoch 1, Batch 71, Training Loss: 0.570944627126058\n",
            "Epoch 1, Batch 72, Training Loss: 0.49265793959299725\n",
            "Epoch 1, Batch 73, Training Loss: 0.3413612445195516\n",
            "Epoch 1, Batch 74, Training Loss: 0.5800365606943766\n",
            "Epoch 1, Batch 75, Training Loss: 0.5164159933725992\n",
            "Epoch 1, Batch 76, Training Loss: 0.4688158432642619\n",
            "Epoch 1, Batch 77, Training Loss: 0.5863858858744303\n",
            "Epoch 1, Batch 78, Training Loss: 0.74073592821757\n",
            "Epoch 1, Batch 79, Training Loss: 0.6267831325531006\n",
            "Epoch 1, Batch 80, Training Loss: 0.5942991177241007\n",
            "Epoch 1, Batch 81, Training Loss: 0.41029632091522217\n",
            "Epoch 1, Batch 82, Training Loss: 0.6752418677012125\n",
            "Epoch 1, Batch 83, Training Loss: 0.6992888450622559\n",
            "Epoch 1, Batch 84, Training Loss: 0.495468537012736\n",
            "Epoch 1, Batch 85, Training Loss: 0.7479154268900553\n",
            "Epoch 1, Batch 86, Training Loss: 0.4767078955968221\n",
            "Epoch 1, Batch 87, Training Loss: 0.8075691858927408\n",
            "Epoch 1, Batch 88, Training Loss: 0.4450821876525879\n",
            "Epoch 1, Batch 89, Training Loss: 0.925771951675415\n",
            "Epoch 1, Batch 90, Training Loss: 0.7829507986704508\n",
            "Epoch 1, Batch 91, Training Loss: 0.6144371430079142\n",
            "Epoch 1, Batch 92, Training Loss: 0.7502299149831136\n",
            "Epoch 1, Batch 93, Training Loss: 0.5917612711588541\n",
            "Epoch 1, Batch 94, Training Loss: 0.3138214151064555\n",
            "Epoch 1, Batch 95, Training Loss: 1.1036974589029949\n",
            "Epoch 1, Batch 96, Training Loss: 0.6808038552602133\n",
            "Epoch 1, Batch 97, Training Loss: 0.725309689839681\n",
            "Epoch 1, Batch 98, Training Loss: 0.7959005037943522\n",
            "Epoch 1, Batch 99, Training Loss: 0.886030356089274\n",
            "Epoch 1, Batch 100, Training Loss: 0.5557206074396769\n",
            "Epoch 1, Batch 101, Training Loss: 0.44727110862731934\n",
            "Epoch 1, Batch 102, Training Loss: 0.5478687683741251\n",
            "Epoch 1, Batch 103, Training Loss: 1.5521259307861328\n",
            "Epoch 1, Batch 104, Training Loss: 0.7373513380686442\n",
            "Epoch 1, Batch 105, Training Loss: 0.41214386622111004\n",
            "Epoch 1, Batch 106, Training Loss: 1.0030981699625652\n",
            "Epoch 1, Batch 107, Training Loss: 0.5591877698898315\n",
            "Epoch 1, Batch 108, Training Loss: 0.889055093129476\n",
            "Epoch 1, Batch 109, Training Loss: 0.5789226690928141\n",
            "Epoch 1, Batch 110, Training Loss: 0.5716514587402344\n",
            "Epoch 1, Batch 111, Training Loss: 0.6026319265365601\n",
            "Epoch 1, Batch 112, Training Loss: 0.5373698472976685\n",
            "Epoch 1, Batch 113, Training Loss: 0.8904039859771729\n",
            "Epoch 1, Batch 114, Training Loss: 0.32998337348302204\n",
            "Epoch 1, Batch 115, Training Loss: 0.43354642391204834\n",
            "Epoch 1, Batch 116, Training Loss: 0.9200635751088461\n",
            "Epoch 1, Batch 117, Training Loss: 0.6436045169830322\n",
            "Epoch 1, Batch 118, Training Loss: 0.6551665862401327\n",
            "Epoch 1, Batch 119, Training Loss: 0.6081976095835367\n",
            "Epoch 1, Batch 120, Training Loss: 0.7789554595947266\n",
            "Epoch 1, Batch 121, Training Loss: 0.5587641398111979\n",
            "Epoch 1, Batch 122, Training Loss: 0.3378230333328247\n",
            "Epoch 1, Batch 123, Training Loss: 0.7318418025970459\n",
            "Epoch 1, Batch 124, Training Loss: 0.31722694635391235\n",
            "Epoch 1, Batch 125, Training Loss: 0.3222230275472005\n",
            "Epoch 1, Batch 126, Training Loss: 0.8148900667826334\n",
            "Epoch 1, Batch 127, Training Loss: 0.18254886070887247\n",
            "Epoch 1, Batch 128, Training Loss: 0.6982189814249674\n",
            "Epoch 1, Batch 129, Training Loss: 0.6056631008783976\n",
            "Epoch 1, Batch 130, Training Loss: 0.6300455729166666\n",
            "Epoch 1, Batch 131, Training Loss: 0.6044491132100424\n",
            "Epoch 1, Batch 132, Training Loss: 0.815152088801066\n",
            "Epoch 1, Batch 133, Training Loss: 0.6876370906829834\n",
            "Epoch 1, Batch 134, Training Loss: 0.6217018763224283\n",
            "Epoch 1, Batch 135, Training Loss: 0.7713814576466879\n",
            "Epoch 1, Batch 136, Training Loss: 0.541735569636027\n",
            "Epoch 1, Batch 137, Training Loss: 0.3769065936406453\n",
            "Epoch 1, Batch 138, Training Loss: 0.6676197052001953\n",
            "Epoch 1, Batch 139, Training Loss: 0.5926186243693033\n",
            "Epoch 1, Batch 140, Training Loss: 0.5987880229949951\n",
            "Epoch 1, Batch 141, Training Loss: 0.5694460074106852\n",
            "Epoch 1, Batch 142, Training Loss: 0.42299195130666095\n",
            "Epoch 1, Batch 143, Training Loss: 0.4464010000228882\n",
            "Epoch 1, Batch 144, Training Loss: 0.997978687286377\n",
            "Epoch 1, Batch 145, Training Loss: 0.7480364640553793\n",
            "Epoch 1, Batch 146, Training Loss: 0.7556779384613037\n",
            "Epoch 1, Batch 147, Training Loss: 0.5550603071848551\n",
            "Epoch 1, Batch 148, Training Loss: 0.5907788276672363\n",
            "Epoch 1, Batch 149, Training Loss: 0.9577542940775553\n",
            "Epoch 1, Batch 150, Training Loss: 0.7691388130187988\n",
            "Epoch 1, Batch 151, Training Loss: 0.7191375096638998\n",
            "Epoch 1, Batch 152, Training Loss: 0.5993316570917765\n",
            "Epoch 1, Batch 153, Training Loss: 0.7977610429128011\n",
            "Epoch 1, Batch 154, Training Loss: 0.43906474113464355\n",
            "Epoch 1, Batch 155, Training Loss: 0.6731825669606527\n",
            "Epoch 1, Batch 156, Training Loss: 0.7364535331726074\n",
            "Epoch 1, Batch 157, Training Loss: 0.6329283316930135\n",
            "Epoch 1, Batch 158, Training Loss: 0.777192751566569\n",
            "Epoch 1, Batch 159, Training Loss: 0.44446349143981934\n",
            "Epoch 1, Batch 160, Training Loss: 0.5920209487279257\n",
            "Epoch 1, Batch 161, Training Loss: 0.7738027572631836\n",
            "Epoch 1, Batch 162, Training Loss: 0.7047225634256998\n",
            "Epoch 1, Batch 163, Training Loss: 0.7769677639007568\n",
            "Epoch 1, Batch 164, Training Loss: 0.6263662576675415\n",
            "Epoch 1, Batch 165, Training Loss: 0.36195075511932373\n",
            "Epoch 1, Batch 166, Training Loss: 0.6807065804799398\n",
            "Epoch 1, Batch 167, Training Loss: 0.7442086537679037\n",
            "Epoch 1, Batch 168, Training Loss: 0.8248959382375082\n",
            "Epoch 1, Batch 169, Training Loss: 0.37162427107493085\n",
            "Epoch 1, Batch 170, Training Loss: 0.9106555779774984\n",
            "Epoch 1, Batch 171, Training Loss: 0.42370371023813885\n",
            "Epoch 1, Batch 172, Training Loss: 0.46958720684051514\n",
            "Epoch 1, Batch 173, Training Loss: 0.6625051895777384\n",
            "Epoch 1, Batch 174, Training Loss: 0.5301900704701742\n",
            "Epoch 1, Batch 175, Training Loss: 0.4618724187215169\n",
            "Epoch 1, Batch 176, Training Loss: 0.746749480565389\n",
            "Epoch 1, Batch 177, Training Loss: 0.7565173308054606\n",
            "Epoch 1, Batch 178, Training Loss: 0.9318176110585531\n",
            "Epoch 1, Batch 179, Training Loss: 0.628778338432312\n",
            "Epoch 1, Batch 180, Training Loss: 0.6043670177459717\n",
            "Epoch 1, Batch 181, Training Loss: 0.7524582544962565\n",
            "Epoch 1, Batch 182, Training Loss: 0.7882239818572998\n",
            "Epoch 1, Batch 183, Training Loss: 0.5244822899500529\n",
            "Epoch 1, Batch 184, Training Loss: 0.6164006392161051\n",
            "Epoch 1, Batch 185, Training Loss: 0.6698969999949137\n",
            "Epoch 1, Batch 186, Training Loss: 0.6826152801513672\n",
            "Epoch 1, Batch 187, Training Loss: 0.9615199565887451\n",
            "Epoch 1, Batch 188, Training Loss: 0.5279022852579752\n",
            "Epoch 1, Batch 189, Training Loss: 0.746334950129191\n",
            "Epoch 1, Batch 190, Training Loss: 0.6112666924794515\n",
            "Epoch 1, Batch 191, Training Loss: 1.0226146380106609\n",
            "Epoch 1, Batch 192, Training Loss: 0.6628015041351318\n",
            "Epoch 1, Batch 193, Training Loss: 0.35745811462402344\n",
            "Epoch 1, Batch 194, Training Loss: 0.6996432145436605\n",
            "Epoch 1, Batch 195, Training Loss: 0.6487074693044027\n",
            "Epoch 1, Batch 196, Training Loss: 0.9156941572825114\n",
            "Epoch 1, Batch 197, Training Loss: 0.7494863669077555\n",
            "Epoch 1, Batch 198, Training Loss: 0.8270529905954996\n",
            "Epoch 1, Batch 199, Training Loss: 0.5161628325780233\n",
            "Epoch 1, Batch 200, Training Loss: 0.3353649377822876\n",
            "Epoch 1, Batch 201, Training Loss: 0.6728533903757731\n",
            "Epoch 1, Batch 202, Training Loss: 0.531873861948649\n",
            "Epoch 1, Batch 203, Training Loss: 0.7205722332000732\n",
            "Epoch 1, Batch 204, Training Loss: 0.5385120709737142\n",
            "Epoch 1, Batch 205, Training Loss: 0.6642652750015259\n",
            "Epoch 1, Batch 206, Training Loss: 0.7222500642140707\n",
            "Epoch 1, Batch 207, Training Loss: 0.3811989625295003\n",
            "Epoch 1, Batch 208, Training Loss: 0.4582764705022176\n",
            "Epoch 1, Batch 209, Training Loss: 0.9083828131357828\n",
            "Epoch 1, Batch 210, Training Loss: 0.6433592637379965\n",
            "Epoch 1, Batch 211, Training Loss: 0.26116790374120075\n",
            "Epoch 1, Batch 212, Training Loss: 1.052210013071696\n",
            "Epoch 1, Batch 213, Training Loss: 0.48315378030141193\n",
            "Epoch 1, Batch 214, Training Loss: 0.5421363910039266\n",
            "Epoch 1, Batch 215, Training Loss: 0.4682825009028117\n",
            "Epoch 1, Batch 216, Training Loss: 0.5351282358169556\n",
            "Epoch 1, Batch 217, Training Loss: 0.8440926869710287\n",
            "Epoch 1, Batch 218, Training Loss: 0.5444349050521851\n",
            "Epoch 1, Batch 219, Training Loss: 0.4445836941401164\n",
            "Epoch 1, Batch 220, Training Loss: 0.6163594722747803\n",
            "Epoch 1, Batch 221, Training Loss: 0.8491595586140951\n",
            "Epoch 1, Batch 222, Training Loss: 0.7681669394175211\n",
            "Epoch 1, Batch 223, Training Loss: 0.6374757687250773\n",
            "Epoch 1, Batch 224, Training Loss: 0.30015474557876587\n",
            "Epoch 1, Batch 225, Training Loss: 0.715699831644694\n",
            "Epoch 1, Batch 226, Training Loss: 0.5804075797398885\n",
            "Epoch 1, Batch 227, Training Loss: 0.6327978372573853\n",
            "Epoch 1, Batch 228, Training Loss: 0.7132784525553385\n",
            "Epoch 1, Batch 229, Training Loss: 0.47194528579711914\n",
            "Epoch 1, Batch 230, Training Loss: 0.6512380043665568\n",
            "Epoch 1, Batch 231, Training Loss: 0.554835319519043\n",
            "Epoch 1, Batch 232, Training Loss: 0.8976331551869711\n",
            "Epoch 1, Batch 233, Training Loss: 0.6424942016601562\n",
            "Epoch 1, Batch 234, Training Loss: 0.796610434850057\n",
            "Epoch 1, Batch 235, Training Loss: 0.8315359751383463\n",
            "Epoch 1, Batch 236, Training Loss: 0.8887090682983398\n",
            "Epoch 1, Batch 237, Training Loss: 0.48354486624399823\n",
            "Epoch 1, Batch 238, Training Loss: 1.0870333512624104\n",
            "Epoch 1, Batch 239, Training Loss: 0.7707460721333822\n",
            "Epoch 1, Batch 240, Training Loss: 0.62883992989858\n",
            "Epoch 1, Batch 241, Training Loss: 0.4389639695485433\n",
            "Epoch 1, Batch 242, Training Loss: 0.7195307413736979\n",
            "Epoch 1, Batch 243, Training Loss: 0.8456536134084066\n",
            "Epoch 1, Batch 244, Training Loss: 0.33717767397562665\n",
            "Epoch 1, Batch 245, Training Loss: 0.8249115149180094\n",
            "Epoch 1, Batch 246, Training Loss: 0.5880222320556641\n",
            "Epoch 1, Batch 247, Training Loss: 0.943686326344808\n",
            "Epoch 1, Batch 248, Training Loss: 1.1738481521606445\n",
            "Epoch 1, Batch 249, Training Loss: 0.6076142390569051\n",
            "Epoch 1, Batch 250, Training Loss: 0.6826354662577311\n",
            "Epoch 1, Batch 251, Training Loss: 0.5009684165318807\n",
            "Epoch 1, Batch 252, Training Loss: 0.8335631688435873\n",
            "Epoch 1, Batch 253, Training Loss: 0.5667775869369507\n",
            "Epoch 1, Batch 254, Training Loss: 0.6999185085296631\n",
            "Epoch 1, Batch 255, Training Loss: 0.700420618057251\n",
            "Epoch 1, Batch 256, Training Loss: 0.5667567253112793\n",
            "Epoch 1, Batch 257, Training Loss: 0.6921230951944987\n",
            "Epoch 1, Batch 258, Training Loss: 0.5778141021728516\n",
            "Epoch 1, Batch 259, Training Loss: 0.4328552484512329\n",
            "Epoch 1, Batch 260, Training Loss: 0.5433702866236368\n",
            "Epoch 1, Batch 261, Training Loss: 0.5347906748453776\n",
            "Epoch 1, Batch 262, Training Loss: 0.7160758972167969\n",
            "Epoch 1, Batch 263, Training Loss: 0.6237179835637411\n",
            "Epoch 1, Batch 264, Training Loss: 0.4258314371109009\n",
            "Epoch 1, Batch 265, Training Loss: 0.3192574779192607\n",
            "Epoch 1, Batch 266, Training Loss: 0.3852360248565674\n",
            "Epoch 1, Batch 267, Training Loss: 0.5311520497004191\n",
            "Epoch 1 finished. Average Training Loss: 1.8920766916614347\n",
            "Epoch 2, Batch 1, Training Loss: 0.42611873149871826\n",
            "Epoch 2, Batch 2, Training Loss: 0.39164984226226807\n",
            "Epoch 2, Batch 3, Training Loss: 0.2414598266283671\n",
            "Epoch 2, Batch 4, Training Loss: 0.3582100073496501\n",
            "Epoch 2, Batch 5, Training Loss: 0.5276718934377035\n",
            "Epoch 2, Batch 6, Training Loss: 0.2859819730122884\n",
            "Epoch 2, Batch 7, Training Loss: 0.22969035307566324\n",
            "Epoch 2, Batch 8, Training Loss: 0.5604308843612671\n",
            "Epoch 2, Batch 9, Training Loss: 0.31426576773325604\n",
            "Epoch 2, Batch 10, Training Loss: 0.5292166868845621\n",
            "Epoch 2, Batch 11, Training Loss: 0.46240981419881183\n",
            "Epoch 2, Batch 12, Training Loss: 0.4224526087443034\n",
            "Epoch 2, Batch 13, Training Loss: 0.433039387067159\n",
            "Epoch 2, Batch 14, Training Loss: 0.5478790203730265\n",
            "Epoch 2, Batch 15, Training Loss: 0.2564111550649007\n",
            "Epoch 2, Batch 16, Training Loss: 0.6032467683156332\n",
            "Epoch 2, Batch 17, Training Loss: 0.2549131512641907\n",
            "Epoch 2, Batch 18, Training Loss: 0.48074738184611004\n",
            "Epoch 2, Batch 19, Training Loss: 0.24989038705825806\n",
            "Epoch 2, Batch 20, Training Loss: 0.5720376571019491\n",
            "Epoch 2, Batch 21, Training Loss: 0.7305076122283936\n",
            "Epoch 2, Batch 22, Training Loss: 0.2535730799039205\n",
            "Epoch 2, Batch 23, Training Loss: 0.4744573434193929\n",
            "Epoch 2, Batch 24, Training Loss: 0.36259130636850995\n",
            "Epoch 2, Batch 25, Training Loss: 0.399699330329895\n",
            "Epoch 2, Batch 26, Training Loss: 0.505124568939209\n",
            "Epoch 2, Batch 27, Training Loss: 0.5376280148824056\n",
            "Epoch 2, Batch 28, Training Loss: 0.3034750819206238\n",
            "Epoch 2, Batch 29, Training Loss: 0.286834458510081\n",
            "Epoch 2, Batch 30, Training Loss: 0.718186616897583\n",
            "Epoch 2, Batch 31, Training Loss: 0.1600112517674764\n",
            "Epoch 2, Batch 32, Training Loss: 0.2743045886357625\n",
            "Epoch 2, Batch 33, Training Loss: 0.37681488196055096\n",
            "Epoch 2, Batch 34, Training Loss: 0.3497609297434489\n",
            "Epoch 2, Batch 35, Training Loss: 0.2509849468866984\n",
            "Epoch 2, Batch 36, Training Loss: 1.3026361465454102\n",
            "Epoch 2, Batch 37, Training Loss: 0.21910880009333292\n",
            "Epoch 2, Batch 38, Training Loss: 0.32839345932006836\n",
            "Epoch 2, Batch 39, Training Loss: 0.48296503225962323\n",
            "Epoch 2, Batch 40, Training Loss: 0.31922300656636554\n",
            "Epoch 2, Batch 41, Training Loss: 0.2834256887435913\n",
            "Epoch 2, Batch 42, Training Loss: 0.2441858450571696\n",
            "Epoch 2, Batch 43, Training Loss: 0.26740843057632446\n",
            "Epoch 2, Batch 44, Training Loss: 0.10155949989954631\n",
            "Epoch 2, Batch 45, Training Loss: 0.40122950077056885\n",
            "Epoch 2, Batch 46, Training Loss: 0.22917803128560385\n",
            "Epoch 2, Batch 47, Training Loss: 0.37544000148773193\n",
            "Epoch 2, Batch 48, Training Loss: 0.1669743855794271\n",
            "Epoch 2, Batch 49, Training Loss: 0.19673752784729004\n",
            "Epoch 2, Batch 50, Training Loss: 0.33129974206288654\n",
            "Epoch 2, Batch 51, Training Loss: 0.2439578970273336\n",
            "Epoch 2, Batch 52, Training Loss: 0.4092678626378377\n",
            "Epoch 2, Batch 53, Training Loss: 0.4708215792973836\n",
            "Epoch 2, Batch 54, Training Loss: 0.3990699052810669\n",
            "Epoch 2, Batch 55, Training Loss: 0.38119439284006756\n",
            "Epoch 2, Batch 56, Training Loss: 0.6647992134094238\n",
            "Epoch 2, Batch 57, Training Loss: 0.529290239016215\n",
            "Epoch 2, Batch 58, Training Loss: 0.3590642213821411\n",
            "Epoch 2, Batch 59, Training Loss: 0.46327050526936847\n",
            "Epoch 2, Batch 60, Training Loss: 0.3047738273938497\n",
            "Epoch 2, Batch 61, Training Loss: 0.43278268973032635\n",
            "Epoch 2, Batch 62, Training Loss: 0.2771916389465332\n",
            "Epoch 2, Batch 63, Training Loss: 0.16987272103627524\n",
            "Epoch 2, Batch 64, Training Loss: 0.2522241671880086\n",
            "Epoch 2, Batch 65, Training Loss: 0.33607439200083417\n",
            "Epoch 2, Batch 66, Training Loss: 0.32408905029296875\n",
            "Epoch 2, Batch 67, Training Loss: 0.5152202049891154\n",
            "Epoch 2, Batch 68, Training Loss: 0.5563672383626302\n",
            "Epoch 2, Batch 69, Training Loss: 0.0895610253016154\n",
            "Epoch 2, Batch 70, Training Loss: 1.3167898654937744\n",
            "Epoch 2, Batch 71, Training Loss: 0.35443615913391113\n",
            "Epoch 2, Batch 72, Training Loss: 0.6247760852177938\n",
            "Epoch 2, Batch 73, Training Loss: 0.3632914622624715\n",
            "Epoch 2, Batch 74, Training Loss: 0.40450167655944824\n",
            "Epoch 2, Batch 75, Training Loss: 0.5679512023925781\n",
            "Epoch 2, Batch 76, Training Loss: 0.3339812358220418\n",
            "Epoch 2, Batch 77, Training Loss: 0.40300726890563965\n",
            "Epoch 2, Batch 78, Training Loss: 0.4228068987528483\n",
            "Epoch 2, Batch 79, Training Loss: 0.42970383167266846\n",
            "Epoch 2, Batch 80, Training Loss: 0.6356141169865926\n",
            "Epoch 2, Batch 81, Training Loss: 0.36204151312510174\n",
            "Epoch 2, Batch 82, Training Loss: 0.3081449468930562\n",
            "Epoch 2, Batch 83, Training Loss: 0.4861263036727905\n",
            "Epoch 2, Batch 84, Training Loss: 0.3845583200454712\n",
            "Epoch 2, Batch 85, Training Loss: 0.41558953126271564\n",
            "Epoch 2, Batch 86, Training Loss: 0.2882416248321533\n",
            "Epoch 2, Batch 87, Training Loss: 0.5575282971064249\n",
            "Epoch 2, Batch 88, Training Loss: 0.3560907046000163\n",
            "Epoch 2, Batch 89, Training Loss: 0.4717034498850505\n",
            "Epoch 2, Batch 90, Training Loss: 0.44679327805836994\n",
            "Epoch 2, Batch 91, Training Loss: 0.6506789525349935\n",
            "Epoch 2, Batch 92, Training Loss: 0.23328926165898642\n",
            "Epoch 2, Batch 93, Training Loss: 0.3017765283584595\n",
            "Epoch 2, Batch 94, Training Loss: 0.4206383228302002\n",
            "Epoch 2, Batch 95, Training Loss: 0.41785144805908203\n",
            "Epoch 2, Batch 96, Training Loss: 0.3329179883003235\n",
            "Epoch 2, Batch 97, Training Loss: 0.31361162662506104\n",
            "Epoch 2, Batch 98, Training Loss: 0.4576253890991211\n",
            "Epoch 2, Batch 99, Training Loss: 0.5665358702341715\n",
            "Epoch 2, Batch 100, Training Loss: 0.21385286251703897\n",
            "Epoch 2, Batch 101, Training Loss: 1.3303918838500977\n",
            "Epoch 2, Batch 102, Training Loss: 0.475095272064209\n",
            "Epoch 2, Batch 103, Training Loss: 0.5669714609781901\n",
            "Epoch 2, Batch 104, Training Loss: 0.35295534133911133\n",
            "Epoch 2, Batch 105, Training Loss: 0.654079794883728\n",
            "Epoch 2, Batch 106, Training Loss: 0.28962576389312744\n",
            "Epoch 2, Batch 107, Training Loss: 0.4448189338048299\n",
            "Epoch 2, Batch 108, Training Loss: 0.280850609143575\n",
            "Epoch 2, Batch 109, Training Loss: 0.23280592759450278\n",
            "Epoch 2, Batch 110, Training Loss: 0.36439887682596844\n",
            "Epoch 2, Batch 111, Training Loss: 0.5846920808156332\n",
            "Epoch 2, Batch 112, Training Loss: 0.2780334949493408\n",
            "Epoch 2, Batch 113, Training Loss: 0.39189807573954266\n",
            "Epoch 2, Batch 114, Training Loss: 0.2251947522163391\n",
            "Epoch 2, Batch 115, Training Loss: 0.292844295501709\n",
            "Epoch 2, Batch 116, Training Loss: 0.6237220764160156\n",
            "Epoch 2, Batch 117, Training Loss: 0.279998779296875\n",
            "Epoch 2, Batch 118, Training Loss: 0.3622865279515584\n",
            "Epoch 2, Batch 119, Training Loss: 0.20906172196070352\n",
            "Epoch 2, Batch 120, Training Loss: 0.3485814730326335\n",
            "Epoch 2, Batch 121, Training Loss: 0.31767354408899945\n",
            "Epoch 2, Batch 122, Training Loss: 0.7832670211791992\n",
            "Epoch 2, Batch 123, Training Loss: 0.4668084383010864\n",
            "Epoch 2, Batch 124, Training Loss: 0.5152636766433716\n",
            "Epoch 2, Batch 125, Training Loss: 0.671943187713623\n",
            "Epoch 2, Batch 126, Training Loss: 0.32750968138376874\n",
            "Epoch 2, Batch 127, Training Loss: 0.6403245528539022\n",
            "Epoch 2, Batch 128, Training Loss: 0.5018047491709391\n",
            "Epoch 2, Batch 129, Training Loss: 0.487377405166626\n",
            "Epoch 2, Batch 130, Training Loss: 0.21049831310908\n",
            "Epoch 2, Batch 131, Training Loss: 0.39378050963083905\n",
            "Epoch 2, Batch 132, Training Loss: 0.9058608214060465\n",
            "Epoch 2, Batch 133, Training Loss: 0.7127438386281332\n",
            "Epoch 2, Batch 134, Training Loss: 0.5232789913813273\n",
            "Epoch 2, Batch 135, Training Loss: 1.3725045522054036\n",
            "Epoch 2, Batch 136, Training Loss: 0.4835645357767741\n",
            "Epoch 2, Batch 137, Training Loss: 0.3691137234369914\n",
            "Epoch 2, Batch 138, Training Loss: 0.4208351771036784\n",
            "Epoch 2, Batch 139, Training Loss: 0.4153624375661214\n",
            "Epoch 2, Batch 140, Training Loss: 0.5540611743927002\n",
            "Epoch 2, Batch 141, Training Loss: 0.5564249356587728\n",
            "Epoch 2, Batch 142, Training Loss: 0.5643751621246338\n",
            "Epoch 2, Batch 143, Training Loss: 0.41994742552439374\n",
            "Epoch 2, Batch 144, Training Loss: 0.5775170723597208\n",
            "Epoch 2, Batch 145, Training Loss: 0.5226849714914957\n",
            "Epoch 2, Batch 146, Training Loss: 0.46927158037821454\n",
            "Epoch 2, Batch 147, Training Loss: 0.5236101547876993\n",
            "Epoch 2, Batch 148, Training Loss: 0.5414774417877197\n",
            "Epoch 2, Batch 149, Training Loss: 0.6003932952880859\n",
            "Epoch 2, Batch 150, Training Loss: 0.7875044345855713\n",
            "Epoch 2, Batch 151, Training Loss: 0.7197268803914388\n",
            "Epoch 2, Batch 152, Training Loss: 0.14823347330093384\n",
            "Epoch 2, Batch 153, Training Loss: 0.7505232493082682\n",
            "Epoch 2, Batch 154, Training Loss: 0.5222581624984741\n",
            "Epoch 2, Batch 155, Training Loss: 0.4275530179341634\n",
            "Epoch 2, Batch 156, Training Loss: 0.5534247557322184\n",
            "Epoch 2, Batch 157, Training Loss: 0.4084240992863973\n",
            "Epoch 2, Batch 158, Training Loss: 0.20087979237238565\n",
            "Epoch 2, Batch 159, Training Loss: 0.4639859199523926\n",
            "Epoch 2, Batch 160, Training Loss: 0.41697537899017334\n",
            "Epoch 2, Batch 161, Training Loss: 0.4729594786961873\n",
            "Epoch 2, Batch 162, Training Loss: 0.35932040214538574\n",
            "Epoch 2, Batch 163, Training Loss: 0.38584717114766437\n",
            "Epoch 2, Batch 164, Training Loss: 0.5846192439397176\n",
            "Epoch 2, Batch 165, Training Loss: 0.5200424194335938\n",
            "Epoch 2, Batch 166, Training Loss: 0.4493054151535034\n",
            "Epoch 2, Batch 167, Training Loss: 0.6278493801752726\n",
            "Epoch 2, Batch 168, Training Loss: 0.2709541916847229\n",
            "Epoch 2, Batch 169, Training Loss: 0.14035823941230774\n",
            "Epoch 2, Batch 170, Training Loss: 0.44028520584106445\n",
            "Epoch 2, Batch 171, Training Loss: 0.49872978528340656\n",
            "Epoch 2, Batch 172, Training Loss: 0.6565765142440796\n",
            "Epoch 2, Batch 173, Training Loss: 0.37225552399953205\n",
            "Epoch 2, Batch 174, Training Loss: 0.41187850634257\n",
            "Epoch 2, Batch 175, Training Loss: 0.24054020643234253\n",
            "Epoch 2, Batch 176, Training Loss: 0.6435679992039999\n",
            "Epoch 2, Batch 177, Training Loss: 0.40441858768463135\n",
            "Epoch 2, Batch 178, Training Loss: 0.8430221080780029\n",
            "Epoch 2, Batch 179, Training Loss: 0.36151599884033203\n",
            "Epoch 2, Batch 180, Training Loss: 0.2799205183982849\n",
            "Epoch 2, Batch 181, Training Loss: 0.4583807786305745\n",
            "Epoch 2, Batch 182, Training Loss: 0.5166021982828776\n",
            "Epoch 2, Batch 183, Training Loss: 0.37614238262176514\n",
            "Epoch 2, Batch 184, Training Loss: 0.34402211507161456\n",
            "Epoch 2, Batch 185, Training Loss: 0.3384537696838379\n",
            "Epoch 2, Batch 186, Training Loss: 0.42321693897247314\n",
            "Epoch 2, Batch 187, Training Loss: 0.3735256592432658\n",
            "Epoch 2, Batch 188, Training Loss: 0.339744766553243\n",
            "Epoch 2, Batch 189, Training Loss: 0.6002324422200521\n",
            "Epoch 2, Batch 190, Training Loss: 0.27116058270136517\n",
            "Epoch 2, Batch 191, Training Loss: 0.3014352321624756\n",
            "Epoch 2, Batch 192, Training Loss: 0.6943411827087402\n",
            "Epoch 2, Batch 193, Training Loss: 0.556290070215861\n",
            "Epoch 2, Batch 194, Training Loss: 0.37053338686625165\n",
            "Epoch 2, Batch 195, Training Loss: 0.4322398900985718\n",
            "Epoch 2, Batch 196, Training Loss: 0.7890363534291586\n",
            "Epoch 2, Batch 197, Training Loss: 0.3066158890724182\n",
            "Epoch 2, Batch 198, Training Loss: 0.39170436064402264\n",
            "Epoch 2, Batch 199, Training Loss: 0.332014520963033\n",
            "Epoch 2, Batch 200, Training Loss: 0.35707708199818927\n",
            "Epoch 2, Batch 201, Training Loss: 0.21427100896835327\n",
            "Epoch 2, Batch 202, Training Loss: 0.3903158903121948\n",
            "Epoch 2, Batch 203, Training Loss: 0.5582569440205892\n",
            "Epoch 2, Batch 204, Training Loss: 0.6048402786254883\n",
            "Epoch 2, Batch 205, Training Loss: 0.7434806823730469\n",
            "Epoch 2, Batch 206, Training Loss: 0.38000913461049396\n",
            "Epoch 2, Batch 207, Training Loss: 0.6963938077290853\n",
            "Epoch 2, Batch 208, Training Loss: 0.2575172781944275\n",
            "Epoch 2, Batch 209, Training Loss: 0.4227278232574463\n",
            "Epoch 2, Batch 210, Training Loss: 0.2493647336959839\n",
            "Epoch 2, Batch 211, Training Loss: 0.24040899674097696\n",
            "Epoch 2, Batch 212, Training Loss: 0.6241716941197714\n",
            "Epoch 2, Batch 213, Training Loss: 0.63069220383962\n",
            "Epoch 2, Batch 214, Training Loss: 0.25856663783391315\n",
            "Epoch 2, Batch 215, Training Loss: 0.5193148851394653\n",
            "Epoch 2, Batch 216, Training Loss: 0.46117115020751953\n",
            "Epoch 2, Batch 217, Training Loss: 0.5523434480031332\n",
            "Epoch 2, Batch 218, Training Loss: 0.8194578488667806\n",
            "Epoch 2, Batch 219, Training Loss: 0.42037185033162433\n",
            "Epoch 2, Batch 220, Training Loss: 0.34668739636739093\n",
            "Epoch 2, Batch 221, Training Loss: 0.3852858543395996\n",
            "Epoch 2, Batch 222, Training Loss: 0.5888169606526693\n",
            "Epoch 2, Batch 223, Training Loss: 0.5899796088536581\n",
            "Epoch 2, Batch 224, Training Loss: 0.4991857210795085\n",
            "Epoch 2, Batch 225, Training Loss: 0.40377068519592285\n",
            "Epoch 2, Batch 226, Training Loss: 0.4021163781483968\n",
            "Epoch 2, Batch 227, Training Loss: 0.5370330015818278\n",
            "Epoch 2, Batch 228, Training Loss: 0.1928238868713379\n",
            "Epoch 2, Batch 229, Training Loss: 0.3271573781967163\n",
            "Epoch 2, Batch 230, Training Loss: 0.45144585768381756\n",
            "Epoch 2, Batch 231, Training Loss: 0.31465937693913776\n",
            "Epoch 2, Batch 232, Training Loss: 0.5610737403233846\n",
            "Epoch 2, Batch 233, Training Loss: 0.4692240556081136\n",
            "Epoch 2, Batch 234, Training Loss: 0.44534043471018475\n",
            "Epoch 2, Batch 235, Training Loss: 0.47391780217488605\n",
            "Epoch 2, Batch 236, Training Loss: 0.3824665943781535\n",
            "Epoch 2, Batch 237, Training Loss: 0.4061397711435954\n",
            "Epoch 2, Batch 238, Training Loss: 0.4058973789215088\n",
            "Epoch 2, Batch 239, Training Loss: 0.3633843660354614\n",
            "Epoch 2, Batch 240, Training Loss: 0.37549249331156415\n",
            "Epoch 2, Batch 241, Training Loss: 0.20629793405532837\n",
            "Epoch 2, Batch 242, Training Loss: 0.5107681751251221\n",
            "Epoch 2, Batch 243, Training Loss: 0.6447637478510538\n",
            "Epoch 2, Batch 244, Training Loss: 0.4888466993967692\n",
            "Epoch 2, Batch 245, Training Loss: 0.5270022948582967\n",
            "Epoch 2, Batch 246, Training Loss: 0.2076709270477295\n",
            "Epoch 2, Batch 247, Training Loss: 0.3554907242457072\n",
            "Epoch 2, Batch 248, Training Loss: 0.36747690041859943\n",
            "Epoch 2, Batch 249, Training Loss: 0.23106898864110312\n",
            "Epoch 2, Batch 250, Training Loss: 0.3051651318868001\n",
            "Epoch 2, Batch 251, Training Loss: 0.30177738269170123\n",
            "Epoch 2, Batch 252, Training Loss: 0.504584789276123\n",
            "Epoch 2, Batch 253, Training Loss: 0.27464181184768677\n",
            "Epoch 2, Batch 254, Training Loss: 0.45775675773620605\n",
            "Epoch 2, Batch 255, Training Loss: 0.22058902184168497\n",
            "Epoch 2, Batch 256, Training Loss: 0.63491157690684\n",
            "Epoch 2, Batch 257, Training Loss: 0.4952651262283325\n",
            "Epoch 2, Batch 258, Training Loss: 0.37577656904856366\n",
            "Epoch 2, Batch 259, Training Loss: 0.58201003074646\n",
            "Epoch 2, Batch 260, Training Loss: 0.24046361446380615\n",
            "Epoch 2, Batch 261, Training Loss: 0.34866897265116376\n",
            "Epoch 2, Batch 262, Training Loss: 0.6928719679514567\n",
            "Epoch 2, Batch 263, Training Loss: 0.3665991226832072\n",
            "Epoch 2, Batch 264, Training Loss: 0.5559564828872681\n",
            "Epoch 2, Batch 265, Training Loss: 0.484794815381368\n",
            "Epoch 2, Batch 266, Training Loss: 0.37416823705037433\n",
            "Epoch 2, Batch 267, Training Loss: 0.3920449415842692\n",
            "Epoch 2 finished. Average Training Loss: 1.3133664063076849\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from bert_score import score as bert_score\n",
        "\n",
        "# load the dataset\n",
        "df = pd.read_csv('cnbc_news_datase.csv')\n",
        "df_clean = df.dropna(subset=['description', 'title'])\n",
        "train_df, test_df = train_test_split(df_clean, test_size=0.1, random_state=42)#90% for train and 10% for test\n",
        "\n",
        "class CNBCNewsDataset(Dataset):#input as the description and output as the title\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text = row['description']\n",
        "        summary = row['title']\n",
        "\n",
        "        inputs = self.tokenizer(text, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        outputs = self.tokenizer(summary, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].squeeze()\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
        "        labels = outputs[\"input_ids\"].squeeze()\n",
        "        labels[labels==self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "# load the BartTokenizer and BartForConditionalGeneration\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')\n",
        "\n",
        "# split the data set\n",
        "train_dataset = CNBCNewsDataset(train_df, tokenizer)\n",
        "test_dataset = CNBCNewsDataset(test_df, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)# I believe the smaller the batch size have better train effect by link in https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# set to cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "# prepare the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "\n",
        "\n",
        "# train the modle\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # print each loss\n",
        "        print(f\"Epoch {epoch}, Batch {batch_idx+1}, Training Loss: {loss.item() / len(batch)}\")\n",
        "\n",
        "    # print ave loss\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} finished. Average Training Loss: {avg_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSBfORB6tY9N",
        "outputId": "facfcc5a-05f8-444e-de2e-53e0c8b6072b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-6a2c41b01ec4>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average BLEU Score: 5.756827972857284\n",
            "Average ROUGE Score: {'rouge1': 28.15994734943647, 'rouge2': 8.308689553194197, 'rougeL': 25.075551540165673, 'rougeLsum': 25.075551540165673}\n"
          ]
        }
      ],
      "source": [
        "# load the bleu and rouge\n",
        "bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n",
        "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n",
        "\n",
        "\n",
        "# model eval and print the bleu and rouge\n",
        "bleu_scores = []\n",
        "rouge_scores = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    with torch.no_grad():\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "\n",
        "\n",
        "        preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in outputs]\n",
        "        labels = []\n",
        "        for l in batch['labels'].cpu().numpy():\n",
        "            # Filter out tag IDs with value -100 and then decode\n",
        "            filtered_l = [token for token in l if token != -100]\n",
        "            decoded_label = tokenizer.decode(filtered_l, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "            labels.append([decoded_label])\n",
        "\n",
        "        bleu_scores.append(bleu_metric.compute(predictions=preds, references=labels)['score'])#this value is time 100 which in the range of the 0 to 1.\n",
        "        rouge_output = rouge_metric.compute(predictions=preds, references=[label[0] for label in labels])\n",
        "        rouge_scores.append({key: value.mid.fmeasure * 100 for key, value in rouge_output.items()})#this value is time 100 which in the range of the 0 to 1.\n",
        "\n",
        "avg_bleu = np.mean(bleu_scores)\n",
        "avg_rouge = {key: np.mean([dic[key] for dic in rouge_scores]) for key in rouge_scores[0]}\n",
        "\n",
        "print(\"Average BLEU Score:\", avg_bleu)\n",
        "print(\"Average ROUGE Score:\", avg_rouge)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from bert_score import score as bert_score\n",
        "\n",
        "# load the dataset\n",
        "df = pd.read_csv('cnbc_news_datase.csv')\n",
        "df_clean = df.dropna(subset=['description', 'title'])\n",
        "train_df, test_df = train_test_split(df_clean, test_size=0.1, random_state=42)#90% for train and 10% for test\n",
        "\n",
        "class CNBCNewsDataset(Dataset):#input as the description and output as the title\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        text = row['description']\n",
        "        summary = row['title']\n",
        "\n",
        "        inputs = self.tokenizer(text, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        outputs = self.tokenizer(summary, max_length=self.max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].squeeze()\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
        "        labels = outputs[\"input_ids\"].squeeze()\n",
        "        labels[labels==self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "# load the BartTokenizer and BartForConditionalGeneration\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base', legacy=False)\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "\n",
        "# split the data set\n",
        "train_dataset = CNBCNewsDataset(train_df, tokenizer)\n",
        "test_dataset = CNBCNewsDataset(test_df, tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)# I believe the smaller the batch size have better train effect by link in https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# set to cuda\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "# prepare the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "\n",
        "\n",
        "# train the modle\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # print each loss\n",
        "        print(f\"Epoch {epoch}, Batch {batch_idx+1}, Training Loss: {loss.item() / len(batch)}\")\n",
        "\n",
        "    # print ave loss\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch} finished. Average Training Loss: {avg_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a69e34c7cbf4f5d8e1d914b8881f8b3",
            "6aebfa04cb3b47dc8a9243570b67e646",
            "dae2497d547a4b439afccf11f063fb88",
            "fdc5ee5da76c4c558746578590e10577",
            "f4d0d6e9fe46404c9090b80c4dcabbd3",
            "7559d64c7df34a8596c33ef97485134a",
            "6071db0721014387998fef2fc0d6ff41",
            "95740b3cb24240c79e7ca4919427e6af",
            "62038b6d59584697acc1ab3a8bd75999",
            "2e9d53ebd22e4ee0820d909c2b163768",
            "372155ad00e74fea88ed6b04204628a2",
            "940459e26c5b4bf895ae1a54ff2d21c4",
            "f39ae3052caa44e9a0ec250aa8dec990",
            "05a0fad472d74f38845d639df60d4de8",
            "626f31c9bb2440a9b2f79c601422440d",
            "79bc5ac5ebbc445fb01b6d5bf2149f57",
            "37a122f4de184f358cc1740177dfceb1",
            "59471dd26b244ea2937c420034ca082b",
            "b9fef884fd934ce4ad04011b4e9404c9",
            "b28396fd66cf46b2b719fc139dd3d740",
            "2895202a80734263861ac43211a04f2c",
            "fd143b5f4909474cb172b6ff8708561a",
            "ff1d7e8b0f974e3ba5c2942f2a83cbc3",
            "850733fcb1bc4f0bbe850de21f3ba51b",
            "f5b9157d5ff248019b580bbb2e14963d",
            "a615c1e52bdb47ed9480e37d71211c6c",
            "08bea2dd96ea4149bc54691d7e82efc8",
            "2d94263330bc4848a12062a8e456b798",
            "94253cfc1a8c46d1b9501c9cdd6cc4c6",
            "32dd82714cbd491e9c7e9f99f1177e98",
            "75c5c524b6e149898abdbb3de462af39",
            "55d5f9660cda4933817d02eb55ace9f8",
            "3f15d55cc2e94f6cb2e51eeb48f980b8",
            "3246158eeabb495eb03ab726b08a28e2",
            "9c3e966ed288469d9249c0a5b5965864",
            "781f4e4446954495a227623e7ae0e63b",
            "f6153b6501aa4ece983929549ab8a7cb",
            "1db14b46179d4ce8a807a1a322566756",
            "d5ea65a7b7384016943ce600c1f7b2e5",
            "c173562be86a435cb46fbd0b3eb3ddfa",
            "da41f4c9a948497f8215b565a923b0dd",
            "224b33ceb62f40e78e62fdeecdc57ff3",
            "c4fb57d8fe534059884524d8b64f2893",
            "208df350b8ee4ba18e4e2f3adf85eda0",
            "d3bbe5a1439e4ec3b5405b3a9ec553f9",
            "7b9bb453c1c14bc7867c5b703516dd19",
            "a53f95d7c07641a4abc457e1a62e0f9a",
            "ed4cae6ee2ad407da777030f0040ea1d",
            "833514ac814e40a3ab9ae6411fd2bdf6",
            "bed49475f6584e04a8c3b253d19ccb0b",
            "45c9386787f14bb68057bdb054f49e8b",
            "7f8357cb35f445efafb2c79a0ffb48c1",
            "2c188d89670a4a408abc29417c86f300",
            "ce907a6bc6834b40b58dce3815b71ef0",
            "836b5f3f1f164e0b9623148458c4bc44"
          ]
        },
        "id": "n0mWO4uvfCmx",
        "outputId": "be30b3e4-fae1-424e-8947-e21854ae0f93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a69e34c7cbf4f5d8e1d914b8881f8b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "940459e26c5b4bf895ae1a54ff2d21c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff1d7e8b0f974e3ba5c2942f2a83cbc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3246158eeabb495eb03ab726b08a28e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3bbe5a1439e4ec3b5405b3a9ec553f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch 0, Batch 1, Training Loss: 1.1555355389912922\n",
            "Epoch 0, Batch 2, Training Loss: 1.6438581148783367\n",
            "Epoch 0, Batch 3, Training Loss: 1.6666887601216633\n",
            "Epoch 0, Batch 4, Training Loss: 1.210358460744222\n",
            "Epoch 0, Batch 5, Training Loss: 1.527410666147868\n",
            "Epoch 0, Batch 6, Training Loss: 1.4613176981608074\n",
            "Epoch 0, Batch 7, Training Loss: 1.8603076934814453\n",
            "Epoch 0, Batch 8, Training Loss: 1.2178192138671875\n",
            "Epoch 0, Batch 9, Training Loss: 1.0753154754638672\n",
            "Epoch 0, Batch 10, Training Loss: 1.6661262512207031\n",
            "Epoch 0, Batch 11, Training Loss: 1.4443011283874512\n",
            "Epoch 0, Batch 12, Training Loss: 1.4918015797932942\n",
            "Epoch 0, Batch 13, Training Loss: 0.9699459075927734\n",
            "Epoch 0, Batch 14, Training Loss: 1.0805042584737141\n",
            "Epoch 0, Batch 15, Training Loss: 0.8750290075937907\n",
            "Epoch 0, Batch 16, Training Loss: 1.05624254544576\n",
            "Epoch 0, Batch 17, Training Loss: 1.1248141129811604\n",
            "Epoch 0, Batch 18, Training Loss: 1.3607673645019531\n",
            "Epoch 0, Batch 19, Training Loss: 1.3409345944722493\n",
            "Epoch 0, Batch 20, Training Loss: 0.7111834685007731\n",
            "Epoch 0, Batch 21, Training Loss: 1.1872272491455078\n",
            "Epoch 0, Batch 22, Training Loss: 0.8947875499725342\n",
            "Epoch 0, Batch 23, Training Loss: 1.5632920265197754\n",
            "Epoch 0, Batch 24, Training Loss: 0.9963072935740153\n",
            "Epoch 0, Batch 25, Training Loss: 1.0475749969482422\n",
            "Epoch 0, Batch 26, Training Loss: 1.1157947381337483\n",
            "Epoch 0, Batch 27, Training Loss: 1.31932799021403\n",
            "Epoch 0, Batch 28, Training Loss: 1.3838764826456706\n",
            "Epoch 0, Batch 29, Training Loss: 1.1609664758046467\n",
            "Epoch 0, Batch 30, Training Loss: 0.8542653719584147\n",
            "Epoch 0, Batch 31, Training Loss: 0.8465933005015055\n",
            "Epoch 0, Batch 32, Training Loss: 1.0252116521199544\n",
            "Epoch 0, Batch 33, Training Loss: 1.045917272567749\n",
            "Epoch 0, Batch 34, Training Loss: 1.6573559443155925\n",
            "Epoch 0, Batch 35, Training Loss: 1.2698739369710286\n",
            "Epoch 0, Batch 36, Training Loss: 0.8330156008402506\n",
            "Epoch 0, Batch 37, Training Loss: 1.287774642308553\n",
            "Epoch 0, Batch 38, Training Loss: 0.9181613922119141\n",
            "Epoch 0, Batch 39, Training Loss: 1.0235075950622559\n",
            "Epoch 0, Batch 40, Training Loss: 0.7049075762430826\n",
            "Epoch 0, Batch 41, Training Loss: 0.9979621569315592\n",
            "Epoch 0, Batch 42, Training Loss: 1.5129090944925945\n",
            "Epoch 0, Batch 43, Training Loss: 0.8380706310272217\n",
            "Epoch 0, Batch 44, Training Loss: 0.949687639872233\n",
            "Epoch 0, Batch 45, Training Loss: 1.0222548643747966\n",
            "Epoch 0, Batch 46, Training Loss: 1.158581813176473\n",
            "Epoch 0, Batch 47, Training Loss: 0.8945667743682861\n",
            "Epoch 0, Batch 48, Training Loss: 0.8443923791249593\n",
            "Epoch 0, Batch 49, Training Loss: 1.1241693496704102\n",
            "Epoch 0, Batch 50, Training Loss: 1.255367676417033\n",
            "Epoch 0, Batch 51, Training Loss: 1.1348686218261719\n",
            "Epoch 0, Batch 52, Training Loss: 1.10138996442159\n",
            "Epoch 0, Batch 53, Training Loss: 0.45932169755299884\n",
            "Epoch 0, Batch 54, Training Loss: 1.10249924659729\n",
            "Epoch 0, Batch 55, Training Loss: 1.1393375396728516\n",
            "Epoch 0, Batch 56, Training Loss: 1.2417132059733074\n",
            "Epoch 0, Batch 57, Training Loss: 1.24097736676534\n",
            "Epoch 0, Batch 58, Training Loss: 1.1326587994893391\n",
            "Epoch 0, Batch 59, Training Loss: 1.3532336552937825\n",
            "Epoch 0, Batch 60, Training Loss: 1.062591314315796\n",
            "Epoch 0, Batch 61, Training Loss: 0.9314537048339844\n",
            "Epoch 0, Batch 62, Training Loss: 0.5181314945220947\n",
            "Epoch 0, Batch 63, Training Loss: 0.8676536083221436\n",
            "Epoch 0, Batch 64, Training Loss: 0.7702473004659017\n",
            "Epoch 0, Batch 65, Training Loss: 1.227436860402425\n",
            "Epoch 0, Batch 66, Training Loss: 1.3263196150461833\n",
            "Epoch 0, Batch 67, Training Loss: 0.7609521547953287\n",
            "Epoch 0, Batch 68, Training Loss: 0.9840944608052572\n",
            "Epoch 0, Batch 69, Training Loss: 0.8720191319783529\n",
            "Epoch 0, Batch 70, Training Loss: 1.0868014494578044\n",
            "Epoch 0, Batch 71, Training Loss: 0.9530095259348551\n",
            "Epoch 0, Batch 72, Training Loss: 1.145603895187378\n",
            "Epoch 0, Batch 73, Training Loss: 1.0244451363881428\n",
            "Epoch 0, Batch 74, Training Loss: 1.1023571491241455\n",
            "Epoch 0, Batch 75, Training Loss: 0.6228127082188925\n",
            "Epoch 0, Batch 76, Training Loss: 1.3886597951253254\n",
            "Epoch 0, Batch 77, Training Loss: 0.8203421433766683\n",
            "Epoch 0, Batch 78, Training Loss: 0.7850640614827474\n",
            "Epoch 0, Batch 79, Training Loss: 1.0723953247070312\n",
            "Epoch 0, Batch 80, Training Loss: 1.1520593166351318\n",
            "Epoch 0, Batch 81, Training Loss: 0.9541427294413248\n",
            "Epoch 0, Batch 82, Training Loss: 0.5836756626764933\n",
            "Epoch 0, Batch 83, Training Loss: 0.860852320988973\n",
            "Epoch 0, Batch 84, Training Loss: 1.0114187399546306\n",
            "Epoch 0, Batch 85, Training Loss: 0.923118511835734\n",
            "Epoch 0, Batch 86, Training Loss: 0.9218246142069498\n",
            "Epoch 0, Batch 87, Training Loss: 1.2260487079620361\n",
            "Epoch 0, Batch 88, Training Loss: 0.5443669954935709\n",
            "Epoch 0, Batch 89, Training Loss: 0.49352435270945233\n",
            "Epoch 0, Batch 90, Training Loss: 0.9652801354726156\n",
            "Epoch 0, Batch 91, Training Loss: 0.5382494529088339\n",
            "Epoch 0, Batch 92, Training Loss: 1.0278127193450928\n",
            "Epoch 0, Batch 93, Training Loss: 1.1981230576833088\n",
            "Epoch 0, Batch 94, Training Loss: 0.9918664296468099\n",
            "Epoch 0, Batch 95, Training Loss: 1.4056871732076008\n",
            "Epoch 0, Batch 96, Training Loss: 0.8452412287394205\n",
            "Epoch 0, Batch 97, Training Loss: 0.9017285505930582\n",
            "Epoch 0, Batch 98, Training Loss: 0.8895451227823893\n",
            "Epoch 0, Batch 99, Training Loss: 0.8871812025705973\n",
            "Epoch 0, Batch 100, Training Loss: 0.6696706612904867\n",
            "Epoch 0, Batch 101, Training Loss: 0.855113665262858\n",
            "Epoch 0, Batch 102, Training Loss: 1.182039499282837\n",
            "Epoch 0, Batch 103, Training Loss: 0.5275493065516154\n",
            "Epoch 0, Batch 104, Training Loss: 0.9136881033579508\n",
            "Epoch 0, Batch 105, Training Loss: 1.5160350799560547\n",
            "Epoch 0, Batch 106, Training Loss: 1.052219311396281\n",
            "Epoch 0, Batch 107, Training Loss: 0.777179479598999\n",
            "Epoch 0, Batch 108, Training Loss: 0.6020028193791708\n",
            "Epoch 0, Batch 109, Training Loss: 0.7276403903961182\n",
            "Epoch 0, Batch 110, Training Loss: 1.039607286453247\n",
            "Epoch 0, Batch 111, Training Loss: 0.9585146903991699\n",
            "Epoch 0, Batch 112, Training Loss: 0.9118496576944987\n",
            "Epoch 0, Batch 113, Training Loss: 0.9833779335021973\n",
            "Epoch 0, Batch 114, Training Loss: 1.154815912246704\n",
            "Epoch 0, Batch 115, Training Loss: 0.9071511427561442\n",
            "Epoch 0, Batch 116, Training Loss: 0.8001486460367838\n",
            "Epoch 0, Batch 117, Training Loss: 0.6528796354929606\n",
            "Epoch 0, Batch 118, Training Loss: 0.8843193054199219\n",
            "Epoch 0, Batch 119, Training Loss: 1.0865952173868816\n",
            "Epoch 0, Batch 120, Training Loss: 1.123003323872884\n",
            "Epoch 0, Batch 121, Training Loss: 1.1614280541737874\n",
            "Epoch 0, Batch 122, Training Loss: 0.9965147177378336\n",
            "Epoch 0, Batch 123, Training Loss: 0.9384146531422933\n",
            "Epoch 0, Batch 124, Training Loss: 0.857668399810791\n",
            "Epoch 0, Batch 125, Training Loss: 0.8097408612569174\n",
            "Epoch 0, Batch 126, Training Loss: 1.2010908126831055\n",
            "Epoch 0, Batch 127, Training Loss: 1.1195651690165203\n",
            "Epoch 0, Batch 128, Training Loss: 0.9108704725901285\n",
            "Epoch 0, Batch 129, Training Loss: 1.2731833457946777\n",
            "Epoch 0, Batch 130, Training Loss: 1.2126383781433105\n",
            "Epoch 0, Batch 131, Training Loss: 0.7318569819132487\n",
            "Epoch 0, Batch 132, Training Loss: 1.057434320449829\n",
            "Epoch 0, Batch 133, Training Loss: 0.5468099117279053\n",
            "Epoch 0, Batch 134, Training Loss: 0.8762190341949463\n",
            "Epoch 0, Batch 135, Training Loss: 0.696501096089681\n",
            "Epoch 0, Batch 136, Training Loss: 0.7612276871999105\n",
            "Epoch 0, Batch 137, Training Loss: 0.7321193218231201\n",
            "Epoch 0, Batch 138, Training Loss: 0.7674256960550944\n",
            "Epoch 0, Batch 139, Training Loss: 1.2836389541625977\n",
            "Epoch 0, Batch 140, Training Loss: 0.7501078446706136\n",
            "Epoch 0, Batch 141, Training Loss: 1.1410105228424072\n",
            "Epoch 0, Batch 142, Training Loss: 0.937751293182373\n",
            "Epoch 0, Batch 143, Training Loss: 0.8037989139556885\n",
            "Epoch 0, Batch 144, Training Loss: 0.9944961071014404\n",
            "Epoch 0, Batch 145, Training Loss: 1.0047547817230225\n",
            "Epoch 0, Batch 146, Training Loss: 0.5299668709437052\n",
            "Epoch 0, Batch 147, Training Loss: 1.4287700653076172\n",
            "Epoch 0, Batch 148, Training Loss: 1.0549911657969158\n",
            "Epoch 0, Batch 149, Training Loss: 0.9946518739064535\n",
            "Epoch 0, Batch 150, Training Loss: 1.1819699605305989\n",
            "Epoch 0, Batch 151, Training Loss: 0.7378144264221191\n",
            "Epoch 0, Batch 152, Training Loss: 0.8405819733937582\n",
            "Epoch 0, Batch 153, Training Loss: 1.0864872932434082\n",
            "Epoch 0, Batch 154, Training Loss: 0.7675682703653971\n",
            "Epoch 0, Batch 155, Training Loss: 0.8456969261169434\n",
            "Epoch 0, Batch 156, Training Loss: 1.009220838546753\n",
            "Epoch 0, Batch 157, Training Loss: 0.6436915000279745\n",
            "Epoch 0, Batch 158, Training Loss: 1.278038740158081\n",
            "Epoch 0, Batch 159, Training Loss: 1.266361951828003\n",
            "Epoch 0, Batch 160, Training Loss: 0.8546855449676514\n",
            "Epoch 0, Batch 161, Training Loss: 0.4516902764638265\n",
            "Epoch 0, Batch 162, Training Loss: 1.6056928634643555\n",
            "Epoch 0, Batch 163, Training Loss: 0.8897345066070557\n",
            "Epoch 0, Batch 164, Training Loss: 0.6919384797414144\n",
            "Epoch 0, Batch 165, Training Loss: 1.422666072845459\n",
            "Epoch 0, Batch 166, Training Loss: 0.8257001241048177\n",
            "Epoch 0, Batch 167, Training Loss: 0.8043954372406006\n",
            "Epoch 0, Batch 168, Training Loss: 1.0633282661437988\n",
            "Epoch 0, Batch 169, Training Loss: 1.3974345525105794\n",
            "Epoch 0, Batch 170, Training Loss: 0.8900434176127116\n",
            "Epoch 0, Batch 171, Training Loss: 0.5126905043919882\n",
            "Epoch 0, Batch 172, Training Loss: 1.1862050692240398\n",
            "Epoch 0, Batch 173, Training Loss: 0.4917451540629069\n",
            "Epoch 0, Batch 174, Training Loss: 0.9057732423146566\n",
            "Epoch 0, Batch 175, Training Loss: 1.310085376103719\n",
            "Epoch 0, Batch 176, Training Loss: 0.7296019395192465\n",
            "Epoch 0, Batch 177, Training Loss: 1.0216398239135742\n",
            "Epoch 0, Batch 178, Training Loss: 0.9871542453765869\n",
            "Epoch 0, Batch 179, Training Loss: 1.1446506977081299\n",
            "Epoch 0, Batch 180, Training Loss: 1.199002981185913\n",
            "Epoch 0, Batch 181, Training Loss: 1.1311163107554119\n",
            "Epoch 0, Batch 182, Training Loss: 0.8680131435394287\n",
            "Epoch 0, Batch 183, Training Loss: 0.6864778995513916\n",
            "Epoch 0, Batch 184, Training Loss: 1.3857803344726562\n",
            "Epoch 0, Batch 185, Training Loss: 0.984113613764445\n",
            "Epoch 0, Batch 186, Training Loss: 0.4897054036458333\n",
            "Epoch 0, Batch 187, Training Loss: 1.0338391462961833\n",
            "Epoch 0, Batch 188, Training Loss: 0.7709758281707764\n",
            "Epoch 0, Batch 189, Training Loss: 0.9014840920766195\n",
            "Epoch 0, Batch 190, Training Loss: 1.1255395412445068\n",
            "Epoch 0, Batch 191, Training Loss: 0.9664848645528158\n",
            "Epoch 0, Batch 192, Training Loss: 0.929701010386149\n",
            "Epoch 0, Batch 193, Training Loss: 0.8214172522226969\n",
            "Epoch 0, Batch 194, Training Loss: 0.3098153273264567\n",
            "Epoch 0, Batch 195, Training Loss: 0.9639126459757487\n",
            "Epoch 0, Batch 196, Training Loss: 1.0610671043395996\n",
            "Epoch 0, Batch 197, Training Loss: 0.7436131636301676\n",
            "Epoch 0, Batch 198, Training Loss: 0.6859773000081381\n",
            "Epoch 0, Batch 199, Training Loss: 0.7634507020314535\n",
            "Epoch 0, Batch 200, Training Loss: 0.7639602025349935\n",
            "Epoch 0, Batch 201, Training Loss: 0.8806519508361816\n",
            "Epoch 0, Batch 202, Training Loss: 0.6293438275655111\n",
            "Epoch 0, Batch 203, Training Loss: 1.3651914596557617\n",
            "Epoch 0, Batch 204, Training Loss: 0.9981573422749838\n",
            "Epoch 0, Batch 205, Training Loss: 0.8217456340789795\n",
            "Epoch 0, Batch 206, Training Loss: 0.8433417479197184\n",
            "Epoch 0, Batch 207, Training Loss: 0.6557251612345377\n",
            "Epoch 0, Batch 208, Training Loss: 0.6958321730295817\n",
            "Epoch 0, Batch 209, Training Loss: 0.8416439692179362\n",
            "Epoch 0, Batch 210, Training Loss: 0.6705032189687093\n",
            "Epoch 0, Batch 211, Training Loss: 0.9630192915598551\n",
            "Epoch 0, Batch 212, Training Loss: 0.6739733219146729\n",
            "Epoch 0, Batch 213, Training Loss: 0.8599375089009603\n",
            "Epoch 0, Batch 214, Training Loss: 0.9900717735290527\n",
            "Epoch 0, Batch 215, Training Loss: 1.145690679550171\n",
            "Epoch 0, Batch 216, Training Loss: 0.6956353982289633\n",
            "Epoch 0, Batch 217, Training Loss: 0.9864524205525717\n",
            "Epoch 0, Batch 218, Training Loss: 0.7341573238372803\n",
            "Epoch 0, Batch 219, Training Loss: 0.8262793223063151\n",
            "Epoch 0, Batch 220, Training Loss: 0.9765873750050863\n",
            "Epoch 0, Batch 221, Training Loss: 0.6966744263966879\n",
            "Epoch 0, Batch 222, Training Loss: 1.1328290303548176\n",
            "Epoch 0, Batch 223, Training Loss: 0.6873080730438232\n",
            "Epoch 0, Batch 224, Training Loss: 1.1914292176564534\n",
            "Epoch 0, Batch 225, Training Loss: 0.7456652323404948\n",
            "Epoch 0, Batch 226, Training Loss: 0.7798966566721598\n",
            "Epoch 0, Batch 227, Training Loss: 1.0705679257710774\n",
            "Epoch 0, Batch 228, Training Loss: 0.8741233348846436\n",
            "Epoch 0, Batch 229, Training Loss: 0.7672976652781168\n",
            "Epoch 0, Batch 230, Training Loss: 0.989813486735026\n",
            "Epoch 0, Batch 231, Training Loss: 0.6721813678741455\n",
            "Epoch 0, Batch 232, Training Loss: 0.7300750414530436\n",
            "Epoch 0, Batch 233, Training Loss: 1.0667479038238525\n",
            "Epoch 0, Batch 234, Training Loss: 1.0155058701833088\n",
            "Epoch 0, Batch 235, Training Loss: 0.9712138970692953\n",
            "Epoch 0, Batch 236, Training Loss: 0.9606830279032389\n",
            "Epoch 0, Batch 237, Training Loss: 0.9692029158274332\n",
            "Epoch 0, Batch 238, Training Loss: 0.8033840656280518\n",
            "Epoch 0, Batch 239, Training Loss: 0.9516463279724121\n",
            "Epoch 0, Batch 240, Training Loss: 0.7341289520263672\n",
            "Epoch 0, Batch 241, Training Loss: 1.1850128968556721\n",
            "Epoch 0, Batch 242, Training Loss: 0.5893826882044474\n",
            "Epoch 0, Batch 243, Training Loss: 0.6432663202285767\n",
            "Epoch 0, Batch 244, Training Loss: 1.3058874607086182\n",
            "Epoch 0, Batch 245, Training Loss: 0.29749282201131183\n",
            "Epoch 0, Batch 246, Training Loss: 0.7163777351379395\n",
            "Epoch 0, Batch 247, Training Loss: 1.1931575934092205\n",
            "Epoch 0, Batch 248, Training Loss: 0.6702121098836263\n",
            "Epoch 0, Batch 249, Training Loss: 0.9971593221028646\n",
            "Epoch 0, Batch 250, Training Loss: 1.1833397547403972\n",
            "Epoch 0, Batch 251, Training Loss: 0.8536650339762369\n",
            "Epoch 0, Batch 252, Training Loss: 0.9080172379811605\n",
            "Epoch 0, Batch 253, Training Loss: 0.7554922103881836\n",
            "Epoch 0, Batch 254, Training Loss: 1.2767784595489502\n",
            "Epoch 0, Batch 255, Training Loss: 0.9597084522247314\n",
            "Epoch 0, Batch 256, Training Loss: 0.8424235184987386\n",
            "Epoch 0, Batch 257, Training Loss: 0.9458034038543701\n",
            "Epoch 0, Batch 258, Training Loss: 0.811896006266276\n",
            "Epoch 0, Batch 259, Training Loss: 1.4377527236938477\n",
            "Epoch 0, Batch 260, Training Loss: 0.6604360739390055\n",
            "Epoch 0, Batch 261, Training Loss: 0.7195475896199545\n",
            "Epoch 0, Batch 262, Training Loss: 1.0803627967834473\n",
            "Epoch 0, Batch 263, Training Loss: 1.0661617120107014\n",
            "Epoch 0, Batch 264, Training Loss: 0.9892717202504476\n",
            "Epoch 0, Batch 265, Training Loss: 1.078188419342041\n",
            "Epoch 0, Batch 266, Training Loss: 1.1302194595336914\n",
            "Epoch 0, Batch 267, Training Loss: 1.175147533416748\n",
            "Epoch 0 finished. Average Training Loss: 2.9335995658060137\n",
            "Epoch 1, Batch 1, Training Loss: 0.5601268212000529\n",
            "Epoch 1, Batch 2, Training Loss: 1.0626602967580159\n",
            "Epoch 1, Batch 3, Training Loss: 0.5749114354451498\n",
            "Epoch 1, Batch 4, Training Loss: 1.3260993162790935\n",
            "Epoch 1, Batch 5, Training Loss: 0.36384642124176025\n",
            "Epoch 1, Batch 6, Training Loss: 0.57164466381073\n",
            "Epoch 1, Batch 7, Training Loss: 1.184801975886027\n",
            "Epoch 1, Batch 8, Training Loss: 0.800407330195109\n",
            "Epoch 1, Batch 9, Training Loss: 0.6659825642903646\n",
            "Epoch 1, Batch 10, Training Loss: 0.6824181079864502\n",
            "Epoch 1, Batch 11, Training Loss: 0.8570894400278727\n",
            "Epoch 1, Batch 12, Training Loss: 0.6492887338002523\n",
            "Epoch 1, Batch 13, Training Loss: 0.5771677494049072\n",
            "Epoch 1, Batch 14, Training Loss: 0.7703290780385336\n",
            "Epoch 1, Batch 15, Training Loss: 0.7312689622243246\n",
            "Epoch 1, Batch 16, Training Loss: 0.9050394694010416\n",
            "Epoch 1, Batch 17, Training Loss: 0.7001428604125977\n",
            "Epoch 1, Batch 18, Training Loss: 0.31644288698832196\n",
            "Epoch 1, Batch 19, Training Loss: 0.793165365854899\n",
            "Epoch 1, Batch 20, Training Loss: 0.5616165002187093\n",
            "Epoch 1, Batch 21, Training Loss: 1.056104262669881\n",
            "Epoch 1, Batch 22, Training Loss: 0.6980121930440267\n",
            "Epoch 1, Batch 23, Training Loss: 0.7441645463307699\n",
            "Epoch 1, Batch 24, Training Loss: 0.6755248705546061\n",
            "Epoch 1, Batch 25, Training Loss: 0.7644320329030355\n",
            "Epoch 1, Batch 26, Training Loss: 0.5407043298085531\n",
            "Epoch 1, Batch 27, Training Loss: 0.7951119740804037\n",
            "Epoch 1, Batch 28, Training Loss: 0.7264534632364908\n",
            "Epoch 1, Batch 29, Training Loss: 0.9718840916951498\n",
            "Epoch 1, Batch 30, Training Loss: 0.6876842180887858\n",
            "Epoch 1, Batch 31, Training Loss: 0.373246709505717\n",
            "Epoch 1, Batch 32, Training Loss: 0.8422612349192301\n",
            "Epoch 1, Batch 33, Training Loss: 0.6417838335037231\n",
            "Epoch 1, Batch 34, Training Loss: 0.6164756615956625\n",
            "Epoch 1, Batch 35, Training Loss: 0.6531572341918945\n",
            "Epoch 1, Batch 36, Training Loss: 0.6510863701502482\n",
            "Epoch 1, Batch 37, Training Loss: 0.3877358039220174\n",
            "Epoch 1, Batch 38, Training Loss: 0.6814201672871908\n",
            "Epoch 1, Batch 39, Training Loss: 0.6714978218078613\n",
            "Epoch 1, Batch 40, Training Loss: 0.8854698340098063\n",
            "Epoch 1, Batch 41, Training Loss: 0.9882755279541016\n",
            "Epoch 1, Batch 42, Training Loss: 0.7236697673797607\n",
            "Epoch 1, Batch 43, Training Loss: 0.709907054901123\n",
            "Epoch 1, Batch 44, Training Loss: 1.1193585395812988\n",
            "Epoch 1, Batch 45, Training Loss: 0.7473829587300619\n",
            "Epoch 1, Batch 46, Training Loss: 1.1392401059468586\n",
            "Epoch 1, Batch 47, Training Loss: 1.051301638285319\n",
            "Epoch 1, Batch 48, Training Loss: 0.5428305864334106\n",
            "Epoch 1, Batch 49, Training Loss: 0.7117532889048258\n",
            "Epoch 1, Batch 50, Training Loss: 0.7415324052174886\n",
            "Epoch 1, Batch 51, Training Loss: 0.6377071142196655\n",
            "Epoch 1, Batch 52, Training Loss: 0.5905094544092814\n",
            "Epoch 1, Batch 53, Training Loss: 0.8627619743347168\n",
            "Epoch 1, Batch 54, Training Loss: 0.499064564704895\n",
            "Epoch 1, Batch 55, Training Loss: 0.750225305557251\n",
            "Epoch 1, Batch 56, Training Loss: 0.8574023246765137\n",
            "Epoch 1, Batch 57, Training Loss: 1.2939659754435222\n",
            "Epoch 1, Batch 58, Training Loss: 0.609183152516683\n",
            "Epoch 1, Batch 59, Training Loss: 1.1395243803660076\n",
            "Epoch 1, Batch 60, Training Loss: 0.9179550806681315\n",
            "Epoch 1, Batch 61, Training Loss: 0.7703433831532797\n",
            "Epoch 1, Batch 62, Training Loss: 0.6353822946548462\n",
            "Epoch 1, Batch 63, Training Loss: 0.7665634950002035\n",
            "Epoch 1, Batch 64, Training Loss: 0.9141849676767985\n",
            "Epoch 1, Batch 65, Training Loss: 0.671192487080892\n",
            "Epoch 1, Batch 66, Training Loss: 1.0242717266082764\n",
            "Epoch 1, Batch 67, Training Loss: 0.5317941109339396\n",
            "Epoch 1, Batch 68, Training Loss: 1.1582932472229004\n",
            "Epoch 1, Batch 69, Training Loss: 0.7397497495015463\n",
            "Epoch 1, Batch 70, Training Loss: 0.48943233489990234\n",
            "Epoch 1, Batch 71, Training Loss: 0.7008978525797526\n",
            "Epoch 1, Batch 72, Training Loss: 0.7973798910776774\n",
            "Epoch 1, Batch 73, Training Loss: 0.8481779098510742\n",
            "Epoch 1, Batch 74, Training Loss: 0.7213861147562662\n",
            "Epoch 1, Batch 75, Training Loss: 0.8517932891845703\n",
            "Epoch 1, Batch 76, Training Loss: 0.8818843364715576\n",
            "Epoch 1, Batch 77, Training Loss: 1.0018258094787598\n",
            "Epoch 1, Batch 78, Training Loss: 0.9036588668823242\n",
            "Epoch 1, Batch 79, Training Loss: 0.8979276816050211\n",
            "Epoch 1, Batch 80, Training Loss: 0.6644692818323771\n",
            "Epoch 1, Batch 81, Training Loss: 0.6337938706080118\n",
            "Epoch 1, Batch 82, Training Loss: 0.6712250709533691\n",
            "Epoch 1, Batch 83, Training Loss: 1.000094731648763\n",
            "Epoch 1, Batch 84, Training Loss: 0.6634789307912191\n",
            "Epoch 1, Batch 85, Training Loss: 1.0409388542175293\n",
            "Epoch 1, Batch 86, Training Loss: 0.7403159141540527\n",
            "Epoch 1, Batch 87, Training Loss: 0.847099781036377\n",
            "Epoch 1, Batch 88, Training Loss: 0.5143532752990723\n",
            "Epoch 1, Batch 89, Training Loss: 0.6941293080647787\n",
            "Epoch 1, Batch 90, Training Loss: 0.3855908314387004\n",
            "Epoch 1, Batch 91, Training Loss: 0.5995470682779948\n",
            "Epoch 1, Batch 92, Training Loss: 0.8686913649241129\n",
            "Epoch 1, Batch 93, Training Loss: 0.9586288134256998\n",
            "Epoch 1, Batch 94, Training Loss: 0.8494406541188558\n",
            "Epoch 1, Batch 95, Training Loss: 0.8462870915730795\n",
            "Epoch 1, Batch 96, Training Loss: 0.8825554052988688\n",
            "Epoch 1, Batch 97, Training Loss: 0.6639596621195475\n",
            "Epoch 1, Batch 98, Training Loss: 1.2447702089945476\n",
            "Epoch 1, Batch 99, Training Loss: 0.5749894777933756\n",
            "Epoch 1, Batch 100, Training Loss: 0.5766718784968058\n",
            "Epoch 1, Batch 101, Training Loss: 0.6560702721277872\n",
            "Epoch 1, Batch 102, Training Loss: 1.1212845643361409\n",
            "Epoch 1, Batch 103, Training Loss: 0.5477070808410645\n",
            "Epoch 1, Batch 104, Training Loss: 0.646806557973226\n",
            "Epoch 1, Batch 105, Training Loss: 0.635893185933431\n",
            "Epoch 1, Batch 106, Training Loss: 0.7055367628733317\n",
            "Epoch 1, Batch 107, Training Loss: 0.876826286315918\n",
            "Epoch 1, Batch 108, Training Loss: 1.090881109237671\n",
            "Epoch 1, Batch 109, Training Loss: 0.5492331584294637\n",
            "Epoch 1, Batch 110, Training Loss: 0.7889342308044434\n",
            "Epoch 1, Batch 111, Training Loss: 1.3023752371470134\n",
            "Epoch 1, Batch 112, Training Loss: 0.48715507984161377\n",
            "Epoch 1, Batch 113, Training Loss: 0.9690399169921875\n",
            "Epoch 1, Batch 114, Training Loss: 0.915292501449585\n",
            "Epoch 1, Batch 115, Training Loss: 0.746214230855306\n",
            "Epoch 1, Batch 116, Training Loss: 0.33954254786173504\n",
            "Epoch 1, Batch 117, Training Loss: 0.3629992405573527\n",
            "Epoch 1, Batch 118, Training Loss: 0.8795152505238851\n",
            "Epoch 1, Batch 119, Training Loss: 0.6864591439565023\n",
            "Epoch 1, Batch 120, Training Loss: 0.45354342460632324\n",
            "Epoch 1, Batch 121, Training Loss: 0.9270475705464681\n",
            "Epoch 1, Batch 122, Training Loss: 0.7054182688395182\n",
            "Epoch 1, Batch 123, Training Loss: 0.8819012641906738\n",
            "Epoch 1, Batch 124, Training Loss: 0.7852576573689779\n",
            "Epoch 1, Batch 125, Training Loss: 0.39294564723968506\n",
            "Epoch 1, Batch 126, Training Loss: 1.0479498704274495\n",
            "Epoch 1, Batch 127, Training Loss: 0.5208324193954468\n",
            "Epoch 1, Batch 128, Training Loss: 0.7804629802703857\n",
            "Epoch 1, Batch 129, Training Loss: 0.7696687380472819\n",
            "Epoch 1, Batch 130, Training Loss: 0.6270662546157837\n",
            "Epoch 1, Batch 131, Training Loss: 0.5174622933069865\n",
            "Epoch 1, Batch 132, Training Loss: 0.4836176633834839\n",
            "Epoch 1, Batch 133, Training Loss: 0.70186448097229\n",
            "Epoch 1, Batch 134, Training Loss: 0.5169152021408081\n",
            "Epoch 1, Batch 135, Training Loss: 0.7616326014200846\n",
            "Epoch 1, Batch 136, Training Loss: 0.652444084485372\n",
            "Epoch 1, Batch 137, Training Loss: 0.4897277355194092\n",
            "Epoch 1, Batch 138, Training Loss: 0.8909527460734049\n",
            "Epoch 1, Batch 139, Training Loss: 0.42596252759297687\n",
            "Epoch 1, Batch 140, Training Loss: 0.5514366626739502\n",
            "Epoch 1, Batch 141, Training Loss: 1.0599219004313152\n",
            "Epoch 1, Batch 142, Training Loss: 0.9109973907470703\n",
            "Epoch 1, Batch 143, Training Loss: 0.763891855875651\n",
            "Epoch 1, Batch 144, Training Loss: 0.7120649814605713\n",
            "Epoch 1, Batch 145, Training Loss: 0.6352128585179647\n",
            "Epoch 1, Batch 146, Training Loss: 0.7864976723988851\n",
            "Epoch 1, Batch 147, Training Loss: 0.9803876082102457\n",
            "Epoch 1, Batch 148, Training Loss: 0.8857298692067465\n",
            "Epoch 1, Batch 149, Training Loss: 0.5445453723271688\n",
            "Epoch 1, Batch 150, Training Loss: 0.6574035485585531\n",
            "Epoch 1, Batch 151, Training Loss: 0.8399639924367269\n",
            "Epoch 1, Batch 152, Training Loss: 0.8382915655771891\n",
            "Epoch 1, Batch 153, Training Loss: 0.7704586187998453\n",
            "Epoch 1, Batch 154, Training Loss: 0.5997370084126791\n",
            "Epoch 1, Batch 155, Training Loss: 0.7273948192596436\n",
            "Epoch 1, Batch 156, Training Loss: 0.8641518751780192\n",
            "Epoch 1, Batch 157, Training Loss: 0.3165365258852641\n",
            "Epoch 1, Batch 158, Training Loss: 0.6677150726318359\n",
            "Epoch 1, Batch 159, Training Loss: 0.587266763051351\n",
            "Epoch 1, Batch 160, Training Loss: 0.46462007363637287\n",
            "Epoch 1, Batch 161, Training Loss: 1.043956200281779\n",
            "Epoch 1, Batch 162, Training Loss: 0.5462236007054647\n",
            "Epoch 1, Batch 163, Training Loss: 0.6624633073806763\n",
            "Epoch 1, Batch 164, Training Loss: 1.109173059463501\n",
            "Epoch 1, Batch 165, Training Loss: 0.7841403484344482\n",
            "Epoch 1, Batch 166, Training Loss: 0.5966634353001913\n",
            "Epoch 1, Batch 167, Training Loss: 0.6798845926920573\n",
            "Epoch 1, Batch 168, Training Loss: 0.48193371295928955\n",
            "Epoch 1, Batch 169, Training Loss: 0.9396022955576578\n",
            "Epoch 1, Batch 170, Training Loss: 0.48158081372578937\n",
            "Epoch 1, Batch 171, Training Loss: 0.9533669153849283\n",
            "Epoch 1, Batch 172, Training Loss: 0.614798386891683\n",
            "Epoch 1, Batch 173, Training Loss: 1.1715806325276692\n",
            "Epoch 1, Batch 174, Training Loss: 0.7590844631195068\n",
            "Epoch 1, Batch 175, Training Loss: 0.4376547336578369\n",
            "Epoch 1, Batch 176, Training Loss: 0.7864398956298828\n",
            "Epoch 1, Batch 177, Training Loss: 0.6277715762456259\n",
            "Epoch 1, Batch 178, Training Loss: 0.9469030698140463\n",
            "Epoch 1, Batch 179, Training Loss: 0.2851519783337911\n",
            "Epoch 1, Batch 180, Training Loss: 1.0592131614685059\n",
            "Epoch 1, Batch 181, Training Loss: 0.7638499736785889\n",
            "Epoch 1, Batch 182, Training Loss: 0.7150376637776693\n",
            "Epoch 1, Batch 183, Training Loss: 0.3218352794647217\n",
            "Epoch 1, Batch 184, Training Loss: 0.39667805035909015\n",
            "Epoch 1, Batch 185, Training Loss: 0.6343024969100952\n",
            "Epoch 1, Batch 186, Training Loss: 0.6421781380971273\n",
            "Epoch 1, Batch 187, Training Loss: 0.716278076171875\n",
            "Epoch 1, Batch 188, Training Loss: 0.7981991767883301\n",
            "Epoch 1, Batch 189, Training Loss: 0.9493397871653239\n",
            "Epoch 1, Batch 190, Training Loss: 0.588851809501648\n",
            "Epoch 1, Batch 191, Training Loss: 0.6670479774475098\n",
            "Epoch 1, Batch 192, Training Loss: 0.9054375489552816\n",
            "Epoch 1, Batch 193, Training Loss: 0.867927630742391\n",
            "Epoch 1, Batch 194, Training Loss: 0.586569587389628\n",
            "Epoch 1, Batch 195, Training Loss: 0.8649937311808268\n",
            "Epoch 1, Batch 196, Training Loss: 1.0261273384094238\n",
            "Epoch 1, Batch 197, Training Loss: 0.7944305737813314\n",
            "Epoch 1, Batch 198, Training Loss: 0.9742750326792399\n",
            "Epoch 1, Batch 199, Training Loss: 0.8207593758900961\n",
            "Epoch 1, Batch 200, Training Loss: 0.602658748626709\n",
            "Epoch 1, Batch 201, Training Loss: 0.743309497833252\n",
            "Epoch 1, Batch 202, Training Loss: 1.0074704488118489\n",
            "Epoch 1, Batch 203, Training Loss: 0.6836869716644287\n",
            "Epoch 1, Batch 204, Training Loss: 1.198473294576009\n",
            "Epoch 1, Batch 205, Training Loss: 0.5572490692138672\n",
            "Epoch 1, Batch 206, Training Loss: 0.8159266312917074\n",
            "Epoch 1, Batch 207, Training Loss: 0.5622135003407797\n",
            "Epoch 1, Batch 208, Training Loss: 0.9058109919230143\n",
            "Epoch 1, Batch 209, Training Loss: 0.5891772508621216\n",
            "Epoch 1, Batch 210, Training Loss: 0.9050705432891846\n",
            "Epoch 1, Batch 211, Training Loss: 0.8680782318115234\n",
            "Epoch 1, Batch 212, Training Loss: 0.7501075267791748\n",
            "Epoch 1, Batch 213, Training Loss: 0.7021957238515218\n",
            "Epoch 1, Batch 214, Training Loss: 0.8937117258707682\n",
            "Epoch 1, Batch 215, Training Loss: 0.9580075740814209\n",
            "Epoch 1, Batch 216, Training Loss: 0.70772918065389\n",
            "Epoch 1, Batch 217, Training Loss: 0.8582464059193929\n",
            "Epoch 1, Batch 218, Training Loss: 0.5497658252716064\n",
            "Epoch 1, Batch 219, Training Loss: 0.729525645573934\n",
            "Epoch 1, Batch 220, Training Loss: 0.6090776522954305\n",
            "Epoch 1, Batch 221, Training Loss: 0.5672459999720255\n",
            "Epoch 1, Batch 222, Training Loss: 0.5231849352518717\n",
            "Epoch 1, Batch 223, Training Loss: 0.5397746960322062\n",
            "Epoch 1, Batch 224, Training Loss: 0.9356931845347086\n",
            "Epoch 1, Batch 225, Training Loss: 0.5445054769515991\n",
            "Epoch 1, Batch 226, Training Loss: 1.3170746167500813\n",
            "Epoch 1, Batch 227, Training Loss: 0.6738731066385905\n",
            "Epoch 1, Batch 228, Training Loss: 0.580341617266337\n",
            "Epoch 1, Batch 229, Training Loss: 1.0960383415222168\n",
            "Epoch 1, Batch 230, Training Loss: 0.724664052327474\n",
            "Epoch 1, Batch 231, Training Loss: 0.6441906690597534\n",
            "Epoch 1, Batch 232, Training Loss: 1.04690416653951\n",
            "Epoch 1, Batch 233, Training Loss: 0.7892524401346842\n",
            "Epoch 1, Batch 234, Training Loss: 0.35631895065307617\n",
            "Epoch 1, Batch 235, Training Loss: 1.0094684759775798\n",
            "Epoch 1, Batch 236, Training Loss: 1.0449817975362141\n",
            "Epoch 1, Batch 237, Training Loss: 0.5798201958338419\n",
            "Epoch 1, Batch 238, Training Loss: 1.0654661655426025\n",
            "Epoch 1, Batch 239, Training Loss: 0.6079943180084229\n",
            "Epoch 1, Batch 240, Training Loss: 1.0048182010650635\n",
            "Epoch 1, Batch 241, Training Loss: 0.7736353079477946\n",
            "Epoch 1, Batch 242, Training Loss: 1.0450433890024822\n",
            "Epoch 1, Batch 243, Training Loss: 0.9385383129119873\n",
            "Epoch 1, Batch 244, Training Loss: 0.6724251906077067\n",
            "Epoch 1, Batch 245, Training Loss: 1.0728805859883626\n",
            "Epoch 1, Batch 246, Training Loss: 0.7118999163309733\n",
            "Epoch 1, Batch 247, Training Loss: 0.6393096844355265\n",
            "Epoch 1, Batch 248, Training Loss: 0.739209254582723\n",
            "Epoch 1, Batch 249, Training Loss: 0.7366271018981934\n",
            "Epoch 1, Batch 250, Training Loss: 0.4741770029067993\n",
            "Epoch 1, Batch 251, Training Loss: 0.6288703282674154\n",
            "Epoch 1, Batch 252, Training Loss: 0.889304002126058\n",
            "Epoch 1, Batch 253, Training Loss: 0.5004212458928426\n",
            "Epoch 1, Batch 254, Training Loss: 0.7485288778940836\n",
            "Epoch 1, Batch 255, Training Loss: 0.6037470897038778\n",
            "Epoch 1, Batch 256, Training Loss: 0.7976214090983073\n",
            "Epoch 1, Batch 257, Training Loss: 0.6111872593561808\n",
            "Epoch 1, Batch 258, Training Loss: 0.8516372044881185\n",
            "Epoch 1, Batch 259, Training Loss: 0.352938453356425\n",
            "Epoch 1, Batch 260, Training Loss: 0.8296120166778564\n",
            "Epoch 1, Batch 261, Training Loss: 1.008087952931722\n",
            "Epoch 1, Batch 262, Training Loss: 0.6897151470184326\n",
            "Epoch 1, Batch 263, Training Loss: 0.6916027863820394\n",
            "Epoch 1, Batch 264, Training Loss: 0.9456018606821696\n",
            "Epoch 1, Batch 265, Training Loss: 0.9592130978902181\n",
            "Epoch 1, Batch 266, Training Loss: 0.6204206148783366\n",
            "Epoch 1, Batch 267, Training Loss: 0.5785744984944662\n",
            "Epoch 1 finished. Average Training Loss: 2.251075140992354\n",
            "Epoch 2, Batch 1, Training Loss: 0.8693865140279134\n",
            "Epoch 2, Batch 2, Training Loss: 0.42476868629455566\n",
            "Epoch 2, Batch 3, Training Loss: 0.5999741554260254\n",
            "Epoch 2, Batch 4, Training Loss: 0.37484268347422284\n",
            "Epoch 2, Batch 5, Training Loss: 0.7245039939880371\n",
            "Epoch 2, Batch 6, Training Loss: 0.5949163834253947\n",
            "Epoch 2, Batch 7, Training Loss: 0.4699943463007609\n",
            "Epoch 2, Batch 8, Training Loss: 0.7959072589874268\n",
            "Epoch 2, Batch 9, Training Loss: 0.7707463900248209\n",
            "Epoch 2, Batch 10, Training Loss: 0.8409912586212158\n",
            "Epoch 2, Batch 11, Training Loss: 0.461746613184611\n",
            "Epoch 2, Batch 12, Training Loss: 0.8680229187011719\n",
            "Epoch 2, Batch 13, Training Loss: 0.4626278479894002\n",
            "Epoch 2, Batch 14, Training Loss: 0.7026112874348959\n",
            "Epoch 2, Batch 15, Training Loss: 1.1462031205495198\n",
            "Epoch 2, Batch 16, Training Loss: 0.6237812836964926\n",
            "Epoch 2, Batch 17, Training Loss: 0.6036186218261719\n",
            "Epoch 2, Batch 18, Training Loss: 0.8480010827382406\n",
            "Epoch 2, Batch 19, Training Loss: 0.6904795169830322\n",
            "Epoch 2, Batch 20, Training Loss: 0.6680575211842855\n",
            "Epoch 2, Batch 21, Training Loss: 0.6439199844996134\n",
            "Epoch 2, Batch 22, Training Loss: 0.42478187878926593\n",
            "Epoch 2, Batch 23, Training Loss: 0.5956663290659586\n",
            "Epoch 2, Batch 24, Training Loss: 0.7713082631429037\n",
            "Epoch 2, Batch 25, Training Loss: 0.6372893253962199\n",
            "Epoch 2, Batch 26, Training Loss: 0.5290184418360392\n",
            "Epoch 2, Batch 27, Training Loss: 0.2535383900006612\n",
            "Epoch 2, Batch 28, Training Loss: 0.6010682582855225\n",
            "Epoch 2, Batch 29, Training Loss: 0.7592156728108724\n",
            "Epoch 2, Batch 30, Training Loss: 1.0475101470947266\n",
            "Epoch 2, Batch 31, Training Loss: 0.39174437522888184\n",
            "Epoch 2, Batch 32, Training Loss: 0.6719049612681071\n",
            "Epoch 2, Batch 33, Training Loss: 0.7625088691711426\n",
            "Epoch 2, Batch 34, Training Loss: 0.6927961508433024\n",
            "Epoch 2, Batch 35, Training Loss: 0.5527955293655396\n",
            "Epoch 2, Batch 36, Training Loss: 0.8767942587534586\n",
            "Epoch 2, Batch 37, Training Loss: 0.7063430150349935\n",
            "Epoch 2, Batch 38, Training Loss: 0.6431879997253418\n",
            "Epoch 2, Batch 39, Training Loss: 0.8167619705200195\n",
            "Epoch 2, Batch 40, Training Loss: 1.1083598136901855\n",
            "Epoch 2, Batch 41, Training Loss: 0.30684419473012287\n",
            "Epoch 2, Batch 42, Training Loss: 0.614990750948588\n",
            "Epoch 2, Batch 43, Training Loss: 0.22292868296305338\n",
            "Epoch 2, Batch 44, Training Loss: 0.5746655464172363\n",
            "Epoch 2, Batch 45, Training Loss: 0.5808216333389282\n",
            "Epoch 2, Batch 46, Training Loss: 0.9171071847279867\n",
            "Epoch 2, Batch 47, Training Loss: 0.4564102490743001\n",
            "Epoch 2, Batch 48, Training Loss: 0.70869247118632\n",
            "Epoch 2, Batch 49, Training Loss: 0.6718026796976725\n",
            "Epoch 2, Batch 50, Training Loss: 0.8348940213521322\n",
            "Epoch 2, Batch 51, Training Loss: 0.7319561640421549\n",
            "Epoch 2, Batch 52, Training Loss: 0.4259962240854899\n",
            "Epoch 2, Batch 53, Training Loss: 0.6675792535146078\n",
            "Epoch 2, Batch 54, Training Loss: 0.6599460442860922\n",
            "Epoch 2, Batch 55, Training Loss: 0.339807391166687\n",
            "Epoch 2, Batch 56, Training Loss: 0.7635069688161215\n",
            "Epoch 2, Batch 57, Training Loss: 0.532711942990621\n",
            "Epoch 2, Batch 58, Training Loss: 0.9053030808766683\n",
            "Epoch 2, Batch 59, Training Loss: 0.5569790999094645\n",
            "Epoch 2, Batch 60, Training Loss: 0.7738918463389078\n",
            "Epoch 2, Batch 61, Training Loss: 0.4156896273295085\n",
            "Epoch 2, Batch 62, Training Loss: 0.8003691037495931\n",
            "Epoch 2, Batch 63, Training Loss: 0.457054336865743\n",
            "Epoch 2, Batch 64, Training Loss: 0.6729838053385416\n",
            "Epoch 2, Batch 65, Training Loss: 0.6094496250152588\n",
            "Epoch 2, Batch 66, Training Loss: 0.48786433537801105\n",
            "Epoch 2, Batch 67, Training Loss: 0.5111902157465616\n",
            "Epoch 2, Batch 68, Training Loss: 0.7016892433166504\n",
            "Epoch 2, Batch 69, Training Loss: 0.6856275399525961\n",
            "Epoch 2, Batch 70, Training Loss: 0.5228151082992554\n",
            "Epoch 2, Batch 71, Training Loss: 0.7145746548970541\n",
            "Epoch 2, Batch 72, Training Loss: 0.47226981321970624\n",
            "Epoch 2, Batch 73, Training Loss: 1.0771888891855876\n",
            "Epoch 2, Batch 74, Training Loss: 0.8027229309082031\n",
            "Epoch 2, Batch 75, Training Loss: 0.4780728816986084\n",
            "Epoch 2, Batch 76, Training Loss: 0.975764274597168\n",
            "Epoch 2, Batch 77, Training Loss: 0.7024004459381104\n",
            "Epoch 2, Batch 78, Training Loss: 0.968911329905192\n",
            "Epoch 2, Batch 79, Training Loss: 0.8324457804361979\n",
            "Epoch 2, Batch 80, Training Loss: 0.5711424748102824\n",
            "Epoch 2, Batch 81, Training Loss: 0.7690659364064535\n",
            "Epoch 2, Batch 82, Training Loss: 0.37960779666900635\n",
            "Epoch 2, Batch 83, Training Loss: 0.4369572401046753\n",
            "Epoch 2, Batch 84, Training Loss: 0.7803229490915934\n",
            "Epoch 2, Batch 85, Training Loss: 0.48197221755981445\n",
            "Epoch 2, Batch 86, Training Loss: 0.6176831324895223\n",
            "Epoch 2, Batch 87, Training Loss: 0.7440844376881918\n",
            "Epoch 2, Batch 88, Training Loss: 0.7591648101806641\n",
            "Epoch 2, Batch 89, Training Loss: 0.30025237798690796\n",
            "Epoch 2, Batch 90, Training Loss: 0.7235785325368246\n",
            "Epoch 2, Batch 91, Training Loss: 0.5667004187901815\n",
            "Epoch 2, Batch 92, Training Loss: 0.5476835171381632\n",
            "Epoch 2, Batch 93, Training Loss: 0.514728307723999\n",
            "Epoch 2, Batch 94, Training Loss: 0.7791621685028076\n",
            "Epoch 2, Batch 95, Training Loss: 0.6952291329701742\n",
            "Epoch 2, Batch 96, Training Loss: 0.6458206574122111\n",
            "Epoch 2, Batch 97, Training Loss: 0.5594363609949747\n",
            "Epoch 2, Batch 98, Training Loss: 0.7374893029530843\n",
            "Epoch 2, Batch 99, Training Loss: 0.5834477742513021\n",
            "Epoch 2, Batch 100, Training Loss: 0.7985215981801351\n",
            "Epoch 2, Batch 101, Training Loss: 0.7825992902119955\n",
            "Epoch 2, Batch 102, Training Loss: 0.4730755885442098\n",
            "Epoch 2, Batch 103, Training Loss: 0.6452827453613281\n",
            "Epoch 2, Batch 104, Training Loss: 0.29673399527867633\n",
            "Epoch 2, Batch 105, Training Loss: 0.39576931794484455\n",
            "Epoch 2, Batch 106, Training Loss: 0.58638596534729\n",
            "Epoch 2, Batch 107, Training Loss: 0.7258961200714111\n",
            "Epoch 2, Batch 108, Training Loss: 0.39240272839864093\n",
            "Epoch 2, Batch 109, Training Loss: 0.7846729755401611\n",
            "Epoch 2, Batch 110, Training Loss: 0.7084549268086752\n",
            "Epoch 2, Batch 111, Training Loss: 0.3527573347091675\n",
            "Epoch 2, Batch 112, Training Loss: 0.9299062887827555\n",
            "Epoch 2, Batch 113, Training Loss: 0.5652521451314291\n",
            "Epoch 2, Batch 114, Training Loss: 0.6329812208811442\n",
            "Epoch 2, Batch 115, Training Loss: 0.3230288028717041\n",
            "Epoch 2, Batch 116, Training Loss: 0.41017770767211914\n",
            "Epoch 2, Batch 117, Training Loss: 0.6173506180445353\n",
            "Epoch 2, Batch 118, Training Loss: 0.5363516012827555\n",
            "Epoch 2, Batch 119, Training Loss: 0.6695593992869059\n",
            "Epoch 2, Batch 120, Training Loss: 0.9350449244181315\n",
            "Epoch 2, Batch 121, Training Loss: 0.6367983023325602\n",
            "Epoch 2, Batch 122, Training Loss: 0.623840848604838\n",
            "Epoch 2, Batch 123, Training Loss: 0.5510440270105997\n",
            "Epoch 2, Batch 124, Training Loss: 0.5975600878397623\n",
            "Epoch 2, Batch 125, Training Loss: 0.6535914738972982\n",
            "Epoch 2, Batch 126, Training Loss: 0.8510576089223226\n",
            "Epoch 2, Batch 127, Training Loss: 0.8821330865224203\n",
            "Epoch 2, Batch 128, Training Loss: 0.995939572652181\n",
            "Epoch 2, Batch 129, Training Loss: 0.659521222114563\n",
            "Epoch 2, Batch 130, Training Loss: 0.36131779352823895\n",
            "Epoch 2, Batch 131, Training Loss: 0.7045607566833496\n",
            "Epoch 2, Batch 132, Training Loss: 0.4834386905034383\n",
            "Epoch 2, Batch 133, Training Loss: 0.34341323375701904\n",
            "Epoch 2, Batch 134, Training Loss: 0.690446694691976\n",
            "Epoch 2, Batch 135, Training Loss: 0.6268384059270223\n",
            "Epoch 2, Batch 136, Training Loss: 0.6178084214528402\n",
            "Epoch 2, Batch 137, Training Loss: 0.4714823563893636\n",
            "Epoch 2, Batch 138, Training Loss: 0.8832732836405436\n",
            "Epoch 2, Batch 139, Training Loss: 0.6003412008285522\n",
            "Epoch 2, Batch 140, Training Loss: 0.42875854174296063\n",
            "Epoch 2, Batch 141, Training Loss: 0.4384853045145671\n",
            "Epoch 2, Batch 142, Training Loss: 0.47301773230234784\n",
            "Epoch 2, Batch 143, Training Loss: 1.0279672145843506\n",
            "Epoch 2, Batch 144, Training Loss: 0.5871260166168213\n",
            "Epoch 2, Batch 145, Training Loss: 0.8409443696339926\n",
            "Epoch 2, Batch 146, Training Loss: 0.7590126196543375\n",
            "Epoch 2, Batch 147, Training Loss: 0.8568419615427653\n",
            "Epoch 2, Batch 148, Training Loss: 0.7423241138458252\n",
            "Epoch 2, Batch 149, Training Loss: 0.5210031668345133\n",
            "Epoch 2, Batch 150, Training Loss: 0.5721534093221029\n",
            "Epoch 2, Batch 151, Training Loss: 0.46617281436920166\n",
            "Epoch 2, Batch 152, Training Loss: 0.4684587319691976\n",
            "Epoch 2, Batch 153, Training Loss: 0.548400362332662\n",
            "Epoch 2, Batch 154, Training Loss: 0.5651364326477051\n",
            "Epoch 2, Batch 155, Training Loss: 0.9089074929555258\n",
            "Epoch 2, Batch 156, Training Loss: 0.40577423572540283\n",
            "Epoch 2, Batch 157, Training Loss: 0.5245587031046549\n",
            "Epoch 2, Batch 158, Training Loss: 0.9145938555399576\n",
            "Epoch 2, Batch 159, Training Loss: 0.7144343058268229\n",
            "Epoch 2, Batch 160, Training Loss: 0.6208562056223551\n",
            "Epoch 2, Batch 161, Training Loss: 0.512931227684021\n",
            "Epoch 2, Batch 162, Training Loss: 0.5614188114802042\n",
            "Epoch 2, Batch 163, Training Loss: 1.009860595067342\n",
            "Epoch 2, Batch 164, Training Loss: 0.9413359959920248\n",
            "Epoch 2, Batch 165, Training Loss: 0.5440911054611206\n",
            "Epoch 2, Batch 166, Training Loss: 0.2957300345102946\n",
            "Epoch 2, Batch 167, Training Loss: 0.4432646830876668\n",
            "Epoch 2, Batch 168, Training Loss: 0.39610334237416583\n",
            "Epoch 2, Batch 169, Training Loss: 0.4529321591059367\n",
            "Epoch 2, Batch 170, Training Loss: 0.5843168099721273\n",
            "Epoch 2, Batch 171, Training Loss: 0.5125213464101156\n",
            "Epoch 2, Batch 172, Training Loss: 0.3718196551005046\n",
            "Epoch 2, Batch 173, Training Loss: 0.4381701548894246\n",
            "Epoch 2, Batch 174, Training Loss: 0.5312714179356893\n",
            "Epoch 2, Batch 175, Training Loss: 0.7219101587931315\n",
            "Epoch 2, Batch 176, Training Loss: 0.6441034078598022\n",
            "Epoch 2, Batch 177, Training Loss: 0.7786327997843424\n",
            "Epoch 2, Batch 178, Training Loss: 0.5064521630605062\n",
            "Epoch 2, Batch 179, Training Loss: 0.38604100545247394\n",
            "Epoch 2, Batch 180, Training Loss: 0.6518277327219645\n",
            "Epoch 2, Batch 181, Training Loss: 0.3454974095026652\n",
            "Epoch 2, Batch 182, Training Loss: 0.6693689028422037\n",
            "Epoch 2, Batch 183, Training Loss: 0.6127698024113973\n",
            "Epoch 2, Batch 184, Training Loss: 0.7843865553538004\n",
            "Epoch 2, Batch 185, Training Loss: 0.2686532537142436\n",
            "Epoch 2, Batch 186, Training Loss: 0.6295303901036581\n",
            "Epoch 2, Batch 187, Training Loss: 0.5452069044113159\n",
            "Epoch 2, Batch 188, Training Loss: 0.5450078248977661\n",
            "Epoch 2, Batch 189, Training Loss: 0.5423572063446045\n",
            "Epoch 2, Batch 190, Training Loss: 0.6763688723246256\n",
            "Epoch 2, Batch 191, Training Loss: 0.704560915629069\n",
            "Epoch 2, Batch 192, Training Loss: 1.329376220703125\n",
            "Epoch 2, Batch 193, Training Loss: 0.27566003799438477\n",
            "Epoch 2, Batch 194, Training Loss: 0.4680124918619792\n",
            "Epoch 2, Batch 195, Training Loss: 0.6299187739690145\n",
            "Epoch 2, Batch 196, Training Loss: 0.4339338541030884\n",
            "Epoch 2, Batch 197, Training Loss: 0.4769241412480672\n",
            "Epoch 2, Batch 198, Training Loss: 0.3978734811147054\n",
            "Epoch 2, Batch 199, Training Loss: 0.5786415735880533\n",
            "Epoch 2, Batch 200, Training Loss: 0.6194072564442953\n",
            "Epoch 2, Batch 201, Training Loss: 0.7695418198903402\n",
            "Epoch 2, Batch 202, Training Loss: 0.586923082669576\n",
            "Epoch 2, Batch 203, Training Loss: 0.8630150953928629\n",
            "Epoch 2, Batch 204, Training Loss: 0.5053828159968058\n",
            "Epoch 2, Batch 205, Training Loss: 0.8122735818227133\n",
            "Epoch 2, Batch 206, Training Loss: 0.7549766699473063\n",
            "Epoch 2, Batch 207, Training Loss: 0.281601349512736\n",
            "Epoch 2, Batch 208, Training Loss: 0.609403133392334\n",
            "Epoch 2, Batch 209, Training Loss: 0.4162282943725586\n",
            "Epoch 2, Batch 210, Training Loss: 0.44149116675059\n",
            "Epoch 2, Batch 211, Training Loss: 0.5707797606786092\n",
            "Epoch 2, Batch 212, Training Loss: 0.5566189686457316\n",
            "Epoch 2, Batch 213, Training Loss: 0.7567344506581625\n",
            "Epoch 2, Batch 214, Training Loss: 0.6890552838643392\n",
            "Epoch 2, Batch 215, Training Loss: 0.5296069780985514\n",
            "Epoch 2, Batch 216, Training Loss: 0.5240349769592285\n",
            "Epoch 2, Batch 217, Training Loss: 1.179200251897176\n",
            "Epoch 2, Batch 218, Training Loss: 0.9470984141031901\n",
            "Epoch 2, Batch 219, Training Loss: 0.7845457394917806\n",
            "Epoch 2, Batch 220, Training Loss: 0.5582987467447916\n",
            "Epoch 2, Batch 221, Training Loss: 0.660996158917745\n",
            "Epoch 2, Batch 222, Training Loss: 0.5999568303426107\n",
            "Epoch 2, Batch 223, Training Loss: 0.522777279218038\n",
            "Epoch 2, Batch 224, Training Loss: 0.40813958644866943\n",
            "Epoch 2, Batch 225, Training Loss: 0.45759673913319904\n",
            "Epoch 2, Batch 226, Training Loss: 0.4404621918996175\n",
            "Epoch 2, Batch 227, Training Loss: 0.6378064155578613\n",
            "Epoch 2, Batch 228, Training Loss: 0.31441450119018555\n",
            "Epoch 2, Batch 229, Training Loss: 0.7313978672027588\n",
            "Epoch 2, Batch 230, Training Loss: 0.4875560204188029\n",
            "Epoch 2, Batch 231, Training Loss: 0.7255597114562988\n",
            "Epoch 2, Batch 232, Training Loss: 0.7598236401875814\n",
            "Epoch 2, Batch 233, Training Loss: 0.6117086013158163\n",
            "Epoch 2, Batch 234, Training Loss: 0.728919267654419\n",
            "Epoch 2, Batch 235, Training Loss: 0.9330916404724121\n",
            "Epoch 2, Batch 236, Training Loss: 0.5795439879099528\n",
            "Epoch 2, Batch 237, Training Loss: 0.4093708594640096\n",
            "Epoch 2, Batch 238, Training Loss: 0.9499141375223795\n",
            "Epoch 2, Batch 239, Training Loss: 0.6392982006072998\n",
            "Epoch 2, Batch 240, Training Loss: 0.49348922570546466\n",
            "Epoch 2, Batch 241, Training Loss: 0.651141087214152\n",
            "Epoch 2, Batch 242, Training Loss: 0.7580105463663737\n",
            "Epoch 2, Batch 243, Training Loss: 0.7930603822072347\n",
            "Epoch 2, Batch 244, Training Loss: 0.5208624203999838\n",
            "Epoch 2, Batch 245, Training Loss: 0.25420238574345905\n",
            "Epoch 2, Batch 246, Training Loss: 0.6231859922409058\n",
            "Epoch 2, Batch 247, Training Loss: 0.7123366196950277\n",
            "Epoch 2, Batch 248, Training Loss: 0.5068658987681071\n",
            "Epoch 2, Batch 249, Training Loss: 0.5165188709894816\n",
            "Epoch 2, Batch 250, Training Loss: 0.9760134220123291\n",
            "Epoch 2, Batch 251, Training Loss: 0.7258045673370361\n",
            "Epoch 2, Batch 252, Training Loss: 0.5441950956980387\n",
            "Epoch 2, Batch 253, Training Loss: 0.6630614201227824\n",
            "Epoch 2, Batch 254, Training Loss: 0.7848834991455078\n",
            "Epoch 2, Batch 255, Training Loss: 0.8172240257263184\n",
            "Epoch 2, Batch 256, Training Loss: 0.36653685569763184\n",
            "Epoch 2, Batch 257, Training Loss: 0.4539244969685872\n",
            "Epoch 2, Batch 258, Training Loss: 1.3785943984985352\n",
            "Epoch 2, Batch 259, Training Loss: 0.5073126554489136\n",
            "Epoch 2, Batch 260, Training Loss: 0.6068377097447714\n",
            "Epoch 2, Batch 261, Training Loss: 0.48071181774139404\n",
            "Epoch 2, Batch 262, Training Loss: 0.7583522796630859\n",
            "Epoch 2, Batch 263, Training Loss: 0.36739611625671387\n",
            "Epoch 2, Batch 264, Training Loss: 0.41866592566172284\n",
            "Epoch 2, Batch 265, Training Loss: 0.7483365535736084\n",
            "Epoch 2, Batch 266, Training Loss: 0.5807861089706421\n",
            "Epoch 2, Batch 267, Training Loss: 0.3918314377466838\n",
            "Epoch 2 finished. Average Training Loss: 1.8819343876302912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the bleu and rouge\n",
        "bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n",
        "rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n",
        "\n",
        "\n",
        "# model eval and print the bleu and rouge\n",
        "bleu_scores = []\n",
        "rouge_scores = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    with torch.no_grad():\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "\n",
        "\n",
        "        preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in outputs]\n",
        "        labels = []\n",
        "        for l in batch['labels'].cpu().numpy():\n",
        "            # Filter out tag IDs with value -100 and then decode\n",
        "            filtered_l = [token for token in l if token != -100]\n",
        "            decoded_label = tokenizer.decode(filtered_l, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "            labels.append([decoded_label])\n",
        "\n",
        "        bleu_scores.append(bleu_metric.compute(predictions=preds, references=labels)['score'])#this value is time 100 which in the range of the 0 to 1.\n",
        "        rouge_output = rouge_metric.compute(predictions=preds, references=[label[0] for label in labels])\n",
        "        rouge_scores.append({key: value.mid.fmeasure * 100 for key, value in rouge_output.items()})#this value is time 100 which in the range of the 0 to 1.\n",
        "\n",
        "avg_bleu = np.mean(bleu_scores)\n",
        "avg_rouge = {key: np.mean([dic[key] for dic in rouge_scores]) for key in rouge_scores[0]}\n",
        "\n",
        "print(\"Average BLEU Score:\", avg_bleu)\n",
        "print(\"Average ROUGE Score:\", avg_rouge)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuYge_8A92JN",
        "outputId": "a024f53d-962c-4b9c-b203-13ec9dd0a78e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e8e3b00bf09c>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  bleu_metric = load_metric(\"sacrebleu\", trust_remote_code=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU Score: 5.417613756534506\n",
            "Average ROUGE Score: {'rouge1': 25.765577559172048, 'rouge2': 8.953644316342418, 'rougeL': 23.337903241916866, 'rougeLsum': 23.337903241916866}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7SnN_OF3-FU"
      },
      "source": [
        "https://huggingface.co/spaces/evaluate-metric/sacrebleu\n",
        "\n",
        "This is show that the sacrebleu is rang from 0 to 100. The reason to choose the batch size from 1 to 4 is because the computiion limit.\n",
        "\n",
        "\n",
        "integration of BLEU and ROUGE scores is important, particularly if going further into the analysis of model performance, which a text summarization task like this one on the CNBCNews dataset would warrant.\n",
        "\n",
        "BLEU and ROUGE Scores Analysis\n",
        "That would be possible: the very metrics to take into consideration in measuring the influence of batch size on model performance would indeed have to appropriately reflect the quality of the summary.\n",
        "\n",
        "With this aim, one uses BLEU (Bilingual Evaluation Understudy) and ROUGE (Recall-Oriented Understudy for Gisting Evaluation) metrics. The metrics BLEU and ROUGE provide quantitative measures that are representative of the quality of similarity between the produced text and reference texts in the case of machine output. BLEU captures aspects of precision, recall, and semantic similarity.\n",
        "\n",
        "Impact of Batch Size on BLEU Scores:\n",
        "Observation: Actually, the experiment bore some very positive results in the sense that when the batch size was reduced from 3 to 2, the average BLEU score had increased from 2.40 to 5.76.\n",
        "\n",
        "- Analysis: Mainly, the BLEU scores are measures of the accuracy of the generated summaries; attention is brought out concerning the comparison of n-gram overlaps of the generated and reference texts. Such improvement in BLEU scores with a decreasing batch size could signify that they allow more frequent updates of gradients (due to smaller batch sizes), which in return helps in learning the finer aspects of language, hence providing summaries closer in wording and formation of sentences to the original texts.\n",
        "\n",
        "\n",
        "Impact of Batch Size on ROUGE Scores:\n",
        "Observation: Setting the batch size at 2 produces better ROUGE scores of ROUGE-1 (28.16% > 21.74%), ROUGE-2 (8.31% > 7.1%), and ROUGE-L:( 25.08% >17.10%).\n",
        "\n",
        "- Analysis: From this approach, the ROUGE scores are considered an overlap of n-grams (ROUGE-N) and the longest common subsequences (ROUGE-L) between the generated and reference summaries. Therefore, it was an approach that showed both precision and recall. The improvement of ROUGE scores with decreasing batch size is indicative of the fact that the summaries were not only more concise but covered a greater dimension of information from the reference texts.\n",
        "This improvement would be a result of the model being able to adjust more finely to the training data because it reaps the benefits from the noise and variability introduced by smaller batches.\n",
        "\n",
        "Conclusion and Recommendations\n",
        "\n",
        "While digging further into the context of batch size hyperparameter tuning for BART model training over the CNBCNews dataset in headline prediction, we observe a few key results against the BLEU and ROUGE scores and according to https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa state the smaller batch size have better ability generlization.\n",
        "\n",
        "\n",
        "- Finer Learning with Smaller Batches: An increase in the BLEU and ROUGE scores with a decrease in the batch size reflects that the current configuration allows the summarizer to learn finer linguistic patterns and content details, which would bear fruit in terms of higher quality summaries.\n",
        "\n",
        "- Trade-off Between Efficiency and Quality: While large batches improve training efficiency and stability, they might compromise the quality of the produced summaries.A larger batch size showed a direct relationship to a decrease in BLEU and ROUGE scores and exactly this trade-off.\n",
        "\n",
        "- Optimization Strategy: The strategy of optimization would be to start with a smaller size of the batch, which will even allow for direct comparison of the scores of the quality of the generated summaries with BLEU and ROUGE metrics. Thereafter, when computational efficiency is at stake, the batch size can be increased, monitoring the performance. The illustration is to show how it is important to consider efficiency and quality alongside the fine-tuning of NLP models and give special focus to the batch size adjustment to get a balance in quality and efficiency.\n",
        "\n",
        "As the result to use different model (T5 normal) train the data from the CNBC new have the simliar result with the Bart model on the bleu and rouge score which this is indicate theat the batch size have the important effect on the model learing rate. Another thing is the quality of the data which the score is relative low on the bleu score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-XrBTqBtY9Q"
      },
      "source": [
        "Task 2(25 points): We discussed how we can formulate RL problems as an MDP. Describe any\n",
        "real-world application that can be formulated as an MDP. Describe the state space, action\n",
        "space, transition model, and rewards for that problem. You do not need to be precise in the\n",
        "description of the transition model and reward (no formula is needed). Qualitative description\n",
        "is enough"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGHy0NsctY9Q"
      },
      "source": [
        "Real-world Application Example: Health Care Management for Chronic Diseases\n",
        "\n",
        "The leading models describing this as a Markov Decision Process (MDP) in the domain of health care, this is the very field that conceptualizes personalized plans for people with chronic diseases (like diabetes or hypertension).\n",
        "\n",
        "1. State Space. In this context, the state space includes a wide array of patient-specific variables, such as current health indicators (e.g., blood sugar level for diabetes, blood pressure for hypertension), treatment history, lifestyle factors (e.g., diet, physical activity), and potentially genetic predisposition.Each state encapsulates a comprehensive snapshot of a patient's health at any given time.\n",
        "\n",
        "2. Action Space: Actions represent the potential intervention or treatment decisions that may be taken by the healthcare provider. The scope of potential actions could be from the change of doses of medications, dietary recommendations, or even prescribing physical exercises to even decisions to monitor the patient without immediate intervention.\n",
        "\n",
        "3. Transition Model: The transition model considered this as the way in which a patient's health state is expected to change from one health state to another given a specified action. Generally, this is turning out to become a complex interchange of biological responses within human beings occurring in a reaction to treatments and changing lifestyles. This model has to take very fact: that the health outcomes are to be probabilistic in nature, and in many cases, there is uncertainty about how varied patients would respond to similar treatments.\n",
        "\n",
        "4. Reward: The reward function is designed to optimize patient health outcomes over time.\n",
        "Rewards can be positive when one obtains or retains some health metrics, e.g., keeping blood sugar in targeted levels for diabetic patients, and negative when they lead to negative health events such as hospitalizations or change of the health indicators to worse significantly.\n",
        "This will most likely contribute to the patient having the best quality of life and the least long-term risks, in terms of the complications from chronic disease.\n",
        "\n",
        "In this application:\n",
        "\n",
        "The state space should represent the actual nature of manifoldly the patient's health status and how it changes with time. The action space highlights such a broad range of treatment options given to healthcare providers that they really have to draw individualized care plans. The transition model is intrinsically complicated, for it is called to forecast health outcomes on the basis of biological responses to the treatments, and among patients, these may be largely different. The reward function must be crafted very wisely, ensuring that it is carefully balanced with short-term gains in health and long-term management of chronic diseases, taking side effects from treatments and the general well-being of the patient into perspective. This will enable modeling the problem of chronic disease management as an MDP and provide the applications of reinforcement learning techniques toward the hopeful avenue in the optimization of a personalized treatment strategy that may offer better health outcomes and reduce the overall burden on health resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDN5yzuutY9R"
      },
      "source": [
        "Task 3(25 points): RL is used in various sectors - Healthcare, recommender systems and trading\n",
        "are a few of those. Pick one of the three areas. Explain one of the problems in any of these\n",
        "domains that can be more effectively solved by reinforcement learning. Find an open-source\n",
        "project (if any) that has addressed this problem. Explain this project in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zx-t3DHtY9S"
      },
      "source": [
        "From that history of years of work and code refinement, TradeMaster is born today: one of the most powerful open-source deep reinforcement learning frameworks, and one of the big players in this domain. Being developed by a research team from Nanyang Technological University (NTU), TradeMaster is being developed to use the dynamism factor of reinforcement learning (RL) while making adaptations in trade strategies from the base of this complex challenge of markets' volatility and unpredictability of conditions.\n",
        "\n",
        "Challenge in Algorithmic Trading: This perfect duo was very useful for traditional algorithmic trading strategies, in the sense of static rules and historical data analysis. However, in turn, they do not provide enough flexibility to properly adapt to the current changes that are being produced in the market. This means that it can result in opportunities being missed or more risk being taken on than necessary, calling for adaptive strategies to such circumstances.\n",
        "Reinforcement Learning (RL) steps into this arena with its inherent capability of learning and refining strategies, given continuous feedback from the market, offering a potential solution for dynamically managing the risk and reaping the benefits.\n",
        "\n",
        "TradeMaster's Solution:\n",
        "\n",
        "Few characteristics of TradeMaster result in uniqueness in the sense of meeting the needs of algorithmic trading with RL:\n",
        "\n",
        "Modular Design: Its architecture for customization is very friendly and flexible, such that a trader can easily experiment with different financial instruments, markets, and RL algorithms. Its design philosophy includes flexibility, smoothly changing from one strategy to another, and at the same time, when there are fluctuating market conditions.\n",
        "\n",
        "Integrated Environment: The framework will include an environment simulator to closely represent the real market conditions. This will help in training and testing the RL agents' training against conditions that closely represent actual scenarios of trading.\n",
        "\n",
        "Reinforcement Learning (RL) Algorithm Support: TradeMaster prides itself on state-of-the-art deep RL algorithms like Proximal Policy Optimization (PPO) and Deep Deterministic Policy Gradient (DDPG). These cutting-edge algorithms represent relatively new findings within the realm of RL research and extend from discrete to continuous action spaces that are a norm in trading.\n",
        "\n",
        "Performance Evaluation: Trading Master provides complete facilities for the analysis of strategies, including ROI and risk management metrics with comparisons to benchmarks. This will help a great deal in gauging the performance and success of the developed trading strategies within the environment provided by TradeMaster.\n",
        "\n",
        "Impact on Trading Strategy Optimization: The application of RL in algorithmic trading by TradeMaster is definitely a step closer toward trading strategies that would be adaptive, and, I would say, intelligent.\n",
        "This, in other words, means that the agent learned from market interaction continually developed within TradeMaster will be able to find profitable trading opportunities or even adapt to market regime changes way ahead of traditional algorithms or human traders. The TradeMaster supports an option in the balanced development of the strategy, whereby the reward functions can be customized in such a manner that they look for maximum returns not only per trade but in relation to the consideration of risk management and capital preservation. This is very important for the sustainability of trading, as the purpose is not just to make maximum profitability in a short period, but also to make sure long-term capital growth with managed risk levels.\n",
        "\n",
        "Conclusion: TradeMaster exemplifies how AI, primarily reinforcement learning, integrated with financial trading, has the potential to solve some of the problems posed in the optimization of algorithmic trading strategies. It will be open-sourced, representing a platform for collaborative innovation that brings further development to the discipline. Where TradeMaster offers very robust, flexible software to develop, test, and evaluate RL-based trading strategies, it assists in the evolution of trading algorithms that dynamically adapt to the complexities of the financial markets and hence can potentially outperform traditional methods."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4(100 points): Implement the game of tic-tac-toe (write a class that implements an agent\n",
        "playing Tic Tac Toe and learning its Q function) using the Q-learning technique (see the\n",
        "resources/links provided in class for more details). Clearly describe your evaluation metric and\n",
        "demonstrate a few runs. You might need to use some online resources to proceed with this. Do\n",
        "not forget to cite those."
      ],
      "metadata": {
        "id": "7QN2uUDeYr-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LHcb2L9utY9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e9c780-6eb0-4c4e-e583-d841164f0917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of 100 games, the agent won 98 times, drew 0 times, and lost 2 times.\n",
            "Out of 100 games, the agent won 95 times, drew 0 times, and lost 5 times.\n",
            "Out of 100 games, the agent won 93 times, drew 0 times, and lost 7 times.\n",
            "Out of 100 games, the agent won 92 times, drew 0 times, and lost 8 times.\n",
            "Out of 100 games, the agent won 91 times, drew 1 times, and lost 8 times.\n",
            "Out of 100 games, the agent won 90 times, drew 1 times, and lost 9 times.\n",
            "Out of 100 games, the agent won 94 times, drew 1 times, and lost 5 times.\n",
            "Out of 100 games, the agent won 92 times, drew 1 times, and lost 7 times.\n",
            "Out of 100 games, the agent won 92 times, drew 0 times, and lost 8 times.\n",
            "Out of 100 games, the agent won 97 times, drew 0 times, and lost 3 times.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = np.zeros((3,3), dtype=int)\n",
        "        self.game_over = False\n",
        "        self.winner = None\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((3,3), dtype=int)\n",
        "        self.game_over = False\n",
        "        self.winner = None\n",
        "        return self.board.flatten()\n",
        "\n",
        "    def step(self, action, player):\n",
        "        row, col = divmod(action, 3)\n",
        "        if self.board[row, col] == 0:\n",
        "            self.board[row, col] = player\n",
        "            self.check_game_over(player)\n",
        "            return self.board.flatten(), self.game_over, self.winner\n",
        "        return self.board.flatten(), False, None\n",
        "\n",
        "    def check_game_over(self, player):\n",
        "        for i in range(3):\n",
        "            if np.all(self.board[i,:] == player) or np.all(self.board[:,i] == player):\n",
        "                self.game_over = True\n",
        "                self.winner = player\n",
        "                return\n",
        "        if np.all(np.diag(self.board) == player) or np.all(np.diag(np.fliplr(self.board)) == player):\n",
        "            self.game_over = True\n",
        "            self.winner = player\n",
        "            return\n",
        "        if not 0 in self.board:\n",
        "            self.game_over = True\n",
        "            self.winner = 0 # Draw\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.95, epsilon=0.1):\n",
        "        self.Q = {}\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_Q(self, state, action):\n",
        "        return self.Q.get((state, action), 0.0)\n",
        "\n",
        "    def choose_action(self, state, available_actions):\n",
        "        if random.uniform(0, 1) < self.epsilon:\n",
        "            return random.choice(available_actions)\n",
        "        qs = [self.get_Q(state, a) for a in available_actions]\n",
        "        maxQ = max(qs)\n",
        "        if qs.count(maxQ) > 1:\n",
        "            best_actions = [available_actions[i] for i in range(len(available_actions)) if qs[i] == maxQ]\n",
        "            action = random.choice(best_actions)\n",
        "        else:\n",
        "            action = available_actions[qs.index(maxQ)]\n",
        "        return action\n",
        "\n",
        "    def update_Q(self, state, action, reward, next_state, next_available_actions):\n",
        "        future_rewards = [self.get_Q(next_state, a) for a in next_available_actions]\n",
        "        max_future_reward = max(future_rewards) if future_rewards else 0.0\n",
        "        self.Q[(state, action)] = self.get_Q(state, action) + \\\n",
        "                                  self.alpha * (reward + self.gamma * max_future_reward - self.get_Q(state, action))\n",
        "\n",
        "def play_game(agent, env):\n",
        "    state = env.reset()\n",
        "    available_actions = list(range(9))\n",
        "    player = 1\n",
        "\n",
        "    while True:\n",
        "        state_str = str(state)\n",
        "        action = agent.choose_action(state_str, available_actions)\n",
        "        next_state, game_over, winner = env.step(action, player)\n",
        "        next_state_str = str(next_state)\n",
        "\n",
        "        if game_over:\n",
        "            reward = 1 if winner == player else -1 if winner != 0 else 0\n",
        "            agent.update_Q(state_str, action, reward, next_state_str, [])\n",
        "            break\n",
        "        else:\n",
        "            next_available_actions = [a for a in available_actions if a != action]\n",
        "            reward = 0\n",
        "            agent.update_Q(state_str, action, reward, next_state_str, next_available_actions)\n",
        "\n",
        "        state = next_state\n",
        "        available_actions = next_available_actions\n",
        "        player = -player # Switch player\n",
        "\n",
        "    return winner\n",
        "\n",
        "def evaluate_agent(agent, env, num_games=100):\n",
        "    results = {'win': 0, 'draw': 0, 'loss': 0}\n",
        "    for _ in range(num_games):\n",
        "        winner = play_game(agent, env)\n",
        "        if winner == 1:\n",
        "            results['win'] += 1\n",
        "        elif winner == -1:\n",
        "            results['loss'] += 1\n",
        "        else:\n",
        "            results['draw'] += 1\n",
        "    env.reset()  # Reset the environment after evaluation\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "agent = QLearningAgent()\n",
        "env = TicTacToe()\n",
        "\n",
        "for i in range(10):\n",
        "  for _ in range(10000):  # Number of games for training\n",
        "      play_game(agent, env)\n",
        "\n",
        "  # Evaluate the agent\n",
        "  evaluation_results = evaluate_agent(agent, env, num_games=100)\n",
        "  print(f\"Out of 100 games, the agent won {evaluation_results['win']} times, \"\n",
        "        f\"drew {evaluation_results['draw']} times, and \"\n",
        "        f\"lost {evaluation_results['loss']} times.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation Steps for the Q-Learning Agent\n",
        "\n",
        "Initialization: Create a Tic-Tac-Toe environment TicTacToe and a Q-learning agent QLearningAgent. The environment is responsible for maintaining the state of the board, executing actions, and checking if the game is over. The agent is responsible for choosing actions based on the current state and updating its Q values through learning.\n",
        "\n",
        "Learning Process:\n",
        "\n",
        "At the start, the agent either randomly chooses actions or selects the best action based on the current learned Q values.\n",
        "Update the environment state based on the chosen action.\n",
        "Update the Q value based on the new state and possible rewards.\n",
        "Repeat this process until the game ends, then reset the environment and start a new game.\n",
        "Evaluation Metric:\n",
        "\n",
        "After several rounds of games, evaluate the agent's performance by counting the number of wins, losses, and draws. This data provides insights into the progress and effectiveness of the agent's learning.\n",
        "\n",
        "Code Explanation\n",
        "\n",
        "The TicTacToe class implements the Tic-Tac-Toe game environment. It can reset the game state, execute actions, and check if the game is over.\n",
        "The QLearningAgent class implements the Q-learning algorithm. It includes a dictionary to store Q values and methods to choose actions and update Q values.\n",
        "The play_game function is a training loop where the agent continuously interacts with the environment, learning how to win at Tic-Tac-Toe.\n",
        "The evaluate_agent function assesses the agent's performance by calculating the win/loss/draw rate over a set number of games.\n",
        "Results and Analysis\n",
        "After multiple rounds of training, the agent significantly improves its performance, gradually winning more games. This indicates that the agent has successfully learned effective strategies. Although there are minor fluctuations in the win rate, the overall trend is positive. These fluctuations might be due to the agent occasionally exploring less optimal strategies during the exploration process.\n",
        "\n",
        "Evaluation\n",
        "This experiment shows that the Q-learning algorithm is highly effective for applying in the Tic-Tac-Toe game. The agent can self-learn by interacting with the environment, continually optimizing its strategy to eventually win in most games.\n",
        "\n",
        "References\n",
        "Watkins, C.J.C.H. & Dayan, P. (1992). Q-learning. Machine Learning, 8(3-4), 279-292.\n",
        "Sutton, R.S. & Barto, A.G. (2018). Reinforcement Learning: An Introduction. MIT Press."
      ],
      "metadata": {
        "id": "ZSUdnSUMbAoO"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d5571c1a5b74244bd5c9cd8e61e1d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f42ccfa78b934d4f9b22114d4772290c",
              "IPY_MODEL_6905d89e1d6d4c639ad43889165d21fd",
              "IPY_MODEL_27f0208ff9e04086b50a2996fb80beee"
            ],
            "layout": "IPY_MODEL_13b5325aac9e4efe8027059fbd4e41e8"
          }
        },
        "f42ccfa78b934d4f9b22114d4772290c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4209cbb3a9484b73a932d16513f4bc1d",
            "placeholder": "​",
            "style": "IPY_MODEL_420a3b9ac2844284b6eab56f79cd2883",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6905d89e1d6d4c639ad43889165d21fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a1645acbde4297a3b604d90b7114ba",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5c0c1329e3144cbbbb81dcd65b4166e",
            "value": 26
          }
        },
        "27f0208ff9e04086b50a2996fb80beee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec7f4754175f43f1a2f1ff78b572e873",
            "placeholder": "​",
            "style": "IPY_MODEL_bfda78e5a645489180c83372a0c05618",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.20kB/s]"
          }
        },
        "13b5325aac9e4efe8027059fbd4e41e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4209cbb3a9484b73a932d16513f4bc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420a3b9ac2844284b6eab56f79cd2883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4a1645acbde4297a3b604d90b7114ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5c0c1329e3144cbbbb81dcd65b4166e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec7f4754175f43f1a2f1ff78b572e873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfda78e5a645489180c83372a0c05618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f282da7eaec4173ae73402b4b0cc45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89b9db604403487c9e4ebfb5cf34cc53",
              "IPY_MODEL_255dec4026044f79a0414312f7386f1d",
              "IPY_MODEL_5d55c76ebeea4f45b7eb714d3b7139bc"
            ],
            "layout": "IPY_MODEL_dcf35ac15a6b46389a4b903b6315b6f5"
          }
        },
        "89b9db604403487c9e4ebfb5cf34cc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d2ce238b514bd8a19ab1a95f645701",
            "placeholder": "​",
            "style": "IPY_MODEL_675c9412034f48d08f9ee8a91b22f762",
            "value": "vocab.json: 100%"
          }
        },
        "255dec4026044f79a0414312f7386f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff85cce77de4f9ab8c752db3a5b7bf1",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5afaf1fee82f4b2e93fac9b4c1cbaf4a",
            "value": 898822
          }
        },
        "5d55c76ebeea4f45b7eb714d3b7139bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466b8a79ad5d4e0880f060d1f6d09d97",
            "placeholder": "​",
            "style": "IPY_MODEL_f3ddce3a16654b3b9e34fd5af7e367a6",
            "value": " 899k/899k [00:00&lt;00:00, 1.81MB/s]"
          }
        },
        "dcf35ac15a6b46389a4b903b6315b6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d2ce238b514bd8a19ab1a95f645701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675c9412034f48d08f9ee8a91b22f762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ff85cce77de4f9ab8c752db3a5b7bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5afaf1fee82f4b2e93fac9b4c1cbaf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "466b8a79ad5d4e0880f060d1f6d09d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ddce3a16654b3b9e34fd5af7e367a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f3ae43aceb4c469d3ccb966c7283ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c30cba11ec84ec0acb2b1cb2a887df7",
              "IPY_MODEL_d3f2b8685c5f4363b8fd5c74ce8f2646",
              "IPY_MODEL_ea2ec47016c747c6b2726a9adc98aa92"
            ],
            "layout": "IPY_MODEL_7ae128a67cb5463abc5eefc168b683b9"
          }
        },
        "9c30cba11ec84ec0acb2b1cb2a887df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46cd5ccd38fb46c8927b426353b17480",
            "placeholder": "​",
            "style": "IPY_MODEL_2a041e80df6d4cca8b91b251ee6812dc",
            "value": "merges.txt: 100%"
          }
        },
        "d3f2b8685c5f4363b8fd5c74ce8f2646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e473e9393a4a17869c6e4933277afe",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59e2fa3f40ee4ba390e8eb4f100c9cab",
            "value": 456318
          }
        },
        "ea2ec47016c747c6b2726a9adc98aa92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ef84df751a4e3686da921802173277",
            "placeholder": "​",
            "style": "IPY_MODEL_36b2c718b8444e3aaf79bc1f2945996f",
            "value": " 456k/456k [00:00&lt;00:00, 1.51MB/s]"
          }
        },
        "7ae128a67cb5463abc5eefc168b683b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46cd5ccd38fb46c8927b426353b17480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a041e80df6d4cca8b91b251ee6812dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e473e9393a4a17869c6e4933277afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e2fa3f40ee4ba390e8eb4f100c9cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8ef84df751a4e3686da921802173277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b2c718b8444e3aaf79bc1f2945996f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4be8c214f84ed09d19361014bdf439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0901aceece914e6bb5504fcfd8c71ca8",
              "IPY_MODEL_9e0fdd3d05314a28bad407a686743a85",
              "IPY_MODEL_3a03ba6607dd4af190302524959c6984"
            ],
            "layout": "IPY_MODEL_fcf1f9a729b740e7a0a2928e43851c34"
          }
        },
        "0901aceece914e6bb5504fcfd8c71ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d500b6d7be994c398809081baef2d796",
            "placeholder": "​",
            "style": "IPY_MODEL_4906e9f45c00401d8037548f28263d6a",
            "value": "tokenizer.json: 100%"
          }
        },
        "9e0fdd3d05314a28bad407a686743a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcaba1f9f80444f08d08f97b7a82e0f3",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99f9b55777e54417a0b74e32660b0442",
            "value": 1355863
          }
        },
        "3a03ba6607dd4af190302524959c6984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed392d18abfd40218cbef0f19ad864dd",
            "placeholder": "​",
            "style": "IPY_MODEL_7f173cda6a454f7db9d39b0920a4b2ba",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.35MB/s]"
          }
        },
        "fcf1f9a729b740e7a0a2928e43851c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d500b6d7be994c398809081baef2d796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4906e9f45c00401d8037548f28263d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcaba1f9f80444f08d08f97b7a82e0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f9b55777e54417a0b74e32660b0442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed392d18abfd40218cbef0f19ad864dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f173cda6a454f7db9d39b0920a4b2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c75c5009c66440b59cdd114c7ef5c245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8f47945cc1f4bea9a92b2ea41ad18e5",
              "IPY_MODEL_6327918043e04981964f0331f48ea9fa",
              "IPY_MODEL_0ebb5c97174f433bb98f3f80c6c6ac9e"
            ],
            "layout": "IPY_MODEL_f4105e6d8ab14e7d82f03bee62d97830"
          }
        },
        "e8f47945cc1f4bea9a92b2ea41ad18e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6605c3cdd0d0484d85416aeb87d05b9a",
            "placeholder": "​",
            "style": "IPY_MODEL_2a8414e056cf4278b2a4ab96efca30c3",
            "value": "config.json: 100%"
          }
        },
        "6327918043e04981964f0331f48ea9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be99ecd87ec4cceba009e1124014156",
            "max": 1628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b47d808947947d7bb7f18f40f2f9f50",
            "value": 1628
          }
        },
        "0ebb5c97174f433bb98f3f80c6c6ac9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d35e8e5c5f434393d7da63cb52f49a",
            "placeholder": "​",
            "style": "IPY_MODEL_e24389a6deb5423882a8e359a95584d9",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 35.1kB/s]"
          }
        },
        "f4105e6d8ab14e7d82f03bee62d97830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6605c3cdd0d0484d85416aeb87d05b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a8414e056cf4278b2a4ab96efca30c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4be99ecd87ec4cceba009e1124014156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b47d808947947d7bb7f18f40f2f9f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76d35e8e5c5f434393d7da63cb52f49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24389a6deb5423882a8e359a95584d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f386af9e27d24825b2124598ce435c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1318db18841d40e78f16ef5272f74ab3",
              "IPY_MODEL_a5df2aa0305c4e6bbb137aca36b86076",
              "IPY_MODEL_6efd99a468c84187ad27eb00ec9c6975"
            ],
            "layout": "IPY_MODEL_3fb298b84d604131897294cbac1ecfee"
          }
        },
        "1318db18841d40e78f16ef5272f74ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8411d9374bd34b0a969d87b9ba6d693d",
            "placeholder": "​",
            "style": "IPY_MODEL_71e86dc35bc64eb6974fd96140182ac0",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "a5df2aa0305c4e6bbb137aca36b86076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32902515ee3946729b21db776dc1e400",
            "max": 1018571383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4858df6f73a8415fa1a670162d74692f",
            "value": 1018571383
          }
        },
        "6efd99a468c84187ad27eb00ec9c6975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_805abcb4fd334c439c4b55c39e8410f9",
            "placeholder": "​",
            "style": "IPY_MODEL_00a7364f13dc407aa6911da5cdfbb13c",
            "value": " 1.02G/1.02G [00:04&lt;00:00, 223MB/s]"
          }
        },
        "3fb298b84d604131897294cbac1ecfee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8411d9374bd34b0a969d87b9ba6d693d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e86dc35bc64eb6974fd96140182ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32902515ee3946729b21db776dc1e400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4858df6f73a8415fa1a670162d74692f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "805abcb4fd334c439c4b55c39e8410f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a7364f13dc407aa6911da5cdfbb13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b47863077d9744a4a6def859deceb68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb8af65579f545bf8311b6adfcdd2b85",
              "IPY_MODEL_727542793c854715971017ab5ba9318d",
              "IPY_MODEL_b881797553e44228b38716481032e1de"
            ],
            "layout": "IPY_MODEL_2db4ed3871864293900efbd3a5f075f4"
          }
        },
        "fb8af65579f545bf8311b6adfcdd2b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31901f9e18f145cd946569d804ff2548",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e5f69d99034b76b1dc6676cb079d80",
            "value": "Downloading builder script: "
          }
        },
        "727542793c854715971017ab5ba9318d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12589c527ad94ab398297a2ea51fd92b",
            "max": 2849,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a43a7721d8cb431384ea90b6e606c151",
            "value": 2849
          }
        },
        "b881797553e44228b38716481032e1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01e8d5551f1a4ad1a32b8d8bb94adfa2",
            "placeholder": "​",
            "style": "IPY_MODEL_c1dd7feea9224c4da45112de85c230b7",
            "value": " 7.65k/? [00:00&lt;00:00, 431kB/s]"
          }
        },
        "2db4ed3871864293900efbd3a5f075f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31901f9e18f145cd946569d804ff2548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e5f69d99034b76b1dc6676cb079d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12589c527ad94ab398297a2ea51fd92b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43a7721d8cb431384ea90b6e606c151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01e8d5551f1a4ad1a32b8d8bb94adfa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1dd7feea9224c4da45112de85c230b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f38084c246c4950ac7baab0ddf5ae2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_090f8a3a091c4615b8c4a4bbc52c79b9",
              "IPY_MODEL_521527ed5bc84dce98bcfc9acab3fa7f",
              "IPY_MODEL_80f5a5e318f4422f8568d49398852d3a"
            ],
            "layout": "IPY_MODEL_ddf723287f4d4a6e9c24ac61e931c1eb"
          }
        },
        "090f8a3a091c4615b8c4a4bbc52c79b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_360a0d9b30f842ab92d7c53d96f6dcc3",
            "placeholder": "​",
            "style": "IPY_MODEL_48425595079542b6b2ae3f4bb5bbdf70",
            "value": "Downloading builder script: "
          }
        },
        "521527ed5bc84dce98bcfc9acab3fa7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0afb488ed6e4423dbd4d145c3bd4e665",
            "max": 2169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5768d4c219f3414aa53c0c9d88f975bd",
            "value": 2169
          }
        },
        "80f5a5e318f4422f8568d49398852d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_089e890676b540b4b1fae936bd9af1ac",
            "placeholder": "​",
            "style": "IPY_MODEL_3918b2690be944979fdf6d6fcbb7dd47",
            "value": " 5.65k/? [00:00&lt;00:00, 189kB/s]"
          }
        },
        "ddf723287f4d4a6e9c24ac61e931c1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360a0d9b30f842ab92d7c53d96f6dcc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48425595079542b6b2ae3f4bb5bbdf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0afb488ed6e4423dbd4d145c3bd4e665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5768d4c219f3414aa53c0c9d88f975bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "089e890676b540b4b1fae936bd9af1ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3918b2690be944979fdf6d6fcbb7dd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a69e34c7cbf4f5d8e1d914b8881f8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aebfa04cb3b47dc8a9243570b67e646",
              "IPY_MODEL_dae2497d547a4b439afccf11f063fb88",
              "IPY_MODEL_fdc5ee5da76c4c558746578590e10577"
            ],
            "layout": "IPY_MODEL_f4d0d6e9fe46404c9090b80c4dcabbd3"
          }
        },
        "6aebfa04cb3b47dc8a9243570b67e646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7559d64c7df34a8596c33ef97485134a",
            "placeholder": "​",
            "style": "IPY_MODEL_6071db0721014387998fef2fc0d6ff41",
            "value": "spiece.model: 100%"
          }
        },
        "dae2497d547a4b439afccf11f063fb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95740b3cb24240c79e7ca4919427e6af",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62038b6d59584697acc1ab3a8bd75999",
            "value": 791656
          }
        },
        "fdc5ee5da76c4c558746578590e10577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e9d53ebd22e4ee0820d909c2b163768",
            "placeholder": "​",
            "style": "IPY_MODEL_372155ad00e74fea88ed6b04204628a2",
            "value": " 792k/792k [00:00&lt;00:00, 4.77MB/s]"
          }
        },
        "f4d0d6e9fe46404c9090b80c4dcabbd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7559d64c7df34a8596c33ef97485134a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6071db0721014387998fef2fc0d6ff41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95740b3cb24240c79e7ca4919427e6af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62038b6d59584697acc1ab3a8bd75999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e9d53ebd22e4ee0820d909c2b163768": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "372155ad00e74fea88ed6b04204628a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "940459e26c5b4bf895ae1a54ff2d21c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f39ae3052caa44e9a0ec250aa8dec990",
              "IPY_MODEL_05a0fad472d74f38845d639df60d4de8",
              "IPY_MODEL_626f31c9bb2440a9b2f79c601422440d"
            ],
            "layout": "IPY_MODEL_79bc5ac5ebbc445fb01b6d5bf2149f57"
          }
        },
        "f39ae3052caa44e9a0ec250aa8dec990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a122f4de184f358cc1740177dfceb1",
            "placeholder": "​",
            "style": "IPY_MODEL_59471dd26b244ea2937c420034ca082b",
            "value": "tokenizer.json: 100%"
          }
        },
        "05a0fad472d74f38845d639df60d4de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9fef884fd934ce4ad04011b4e9404c9",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b28396fd66cf46b2b719fc139dd3d740",
            "value": 1389353
          }
        },
        "626f31c9bb2440a9b2f79c601422440d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2895202a80734263861ac43211a04f2c",
            "placeholder": "​",
            "style": "IPY_MODEL_fd143b5f4909474cb172b6ff8708561a",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 1.87MB/s]"
          }
        },
        "79bc5ac5ebbc445fb01b6d5bf2149f57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a122f4de184f358cc1740177dfceb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59471dd26b244ea2937c420034ca082b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9fef884fd934ce4ad04011b4e9404c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28396fd66cf46b2b719fc139dd3d740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2895202a80734263861ac43211a04f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd143b5f4909474cb172b6ff8708561a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff1d7e8b0f974e3ba5c2942f2a83cbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_850733fcb1bc4f0bbe850de21f3ba51b",
              "IPY_MODEL_f5b9157d5ff248019b580bbb2e14963d",
              "IPY_MODEL_a615c1e52bdb47ed9480e37d71211c6c"
            ],
            "layout": "IPY_MODEL_08bea2dd96ea4149bc54691d7e82efc8"
          }
        },
        "850733fcb1bc4f0bbe850de21f3ba51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d94263330bc4848a12062a8e456b798",
            "placeholder": "​",
            "style": "IPY_MODEL_94253cfc1a8c46d1b9501c9cdd6cc4c6",
            "value": "config.json: 100%"
          }
        },
        "f5b9157d5ff248019b580bbb2e14963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32dd82714cbd491e9c7e9f99f1177e98",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75c5c524b6e149898abdbb3de462af39",
            "value": 1208
          }
        },
        "a615c1e52bdb47ed9480e37d71211c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d5f9660cda4933817d02eb55ace9f8",
            "placeholder": "​",
            "style": "IPY_MODEL_3f15d55cc2e94f6cb2e51eeb48f980b8",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 18.9kB/s]"
          }
        },
        "08bea2dd96ea4149bc54691d7e82efc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d94263330bc4848a12062a8e456b798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94253cfc1a8c46d1b9501c9cdd6cc4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32dd82714cbd491e9c7e9f99f1177e98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c5c524b6e149898abdbb3de462af39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55d5f9660cda4933817d02eb55ace9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f15d55cc2e94f6cb2e51eeb48f980b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3246158eeabb495eb03ab726b08a28e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c3e966ed288469d9249c0a5b5965864",
              "IPY_MODEL_781f4e4446954495a227623e7ae0e63b",
              "IPY_MODEL_f6153b6501aa4ece983929549ab8a7cb"
            ],
            "layout": "IPY_MODEL_1db14b46179d4ce8a807a1a322566756"
          }
        },
        "9c3e966ed288469d9249c0a5b5965864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5ea65a7b7384016943ce600c1f7b2e5",
            "placeholder": "​",
            "style": "IPY_MODEL_c173562be86a435cb46fbd0b3eb3ddfa",
            "value": "model.safetensors: 100%"
          }
        },
        "781f4e4446954495a227623e7ae0e63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da41f4c9a948497f8215b565a923b0dd",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_224b33ceb62f40e78e62fdeecdc57ff3",
            "value": 891646390
          }
        },
        "f6153b6501aa4ece983929549ab8a7cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4fb57d8fe534059884524d8b64f2893",
            "placeholder": "​",
            "style": "IPY_MODEL_208df350b8ee4ba18e4e2f3adf85eda0",
            "value": " 892M/892M [00:03&lt;00:00, 260MB/s]"
          }
        },
        "1db14b46179d4ce8a807a1a322566756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ea65a7b7384016943ce600c1f7b2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c173562be86a435cb46fbd0b3eb3ddfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da41f4c9a948497f8215b565a923b0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224b33ceb62f40e78e62fdeecdc57ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4fb57d8fe534059884524d8b64f2893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "208df350b8ee4ba18e4e2f3adf85eda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3bbe5a1439e4ec3b5405b3a9ec553f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b9bb453c1c14bc7867c5b703516dd19",
              "IPY_MODEL_a53f95d7c07641a4abc457e1a62e0f9a",
              "IPY_MODEL_ed4cae6ee2ad407da777030f0040ea1d"
            ],
            "layout": "IPY_MODEL_833514ac814e40a3ab9ae6411fd2bdf6"
          }
        },
        "7b9bb453c1c14bc7867c5b703516dd19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed49475f6584e04a8c3b253d19ccb0b",
            "placeholder": "​",
            "style": "IPY_MODEL_45c9386787f14bb68057bdb054f49e8b",
            "value": "generation_config.json: 100%"
          }
        },
        "a53f95d7c07641a4abc457e1a62e0f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f8357cb35f445efafb2c79a0ffb48c1",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c188d89670a4a408abc29417c86f300",
            "value": 147
          }
        },
        "ed4cae6ee2ad407da777030f0040ea1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce907a6bc6834b40b58dce3815b71ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_836b5f3f1f164e0b9623148458c4bc44",
            "value": " 147/147 [00:00&lt;00:00, 11.1kB/s]"
          }
        },
        "833514ac814e40a3ab9ae6411fd2bdf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed49475f6584e04a8c3b253d19ccb0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c9386787f14bb68057bdb054f49e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f8357cb35f445efafb2c79a0ffb48c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c188d89670a4a408abc29417c86f300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce907a6bc6834b40b58dce3815b71ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836b5f3f1f164e0b9623148458c4bc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}